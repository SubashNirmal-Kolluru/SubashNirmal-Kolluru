{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0451,
     "end_time": "2020-11-29T06:50:19.212098",
     "exception": false,
     "start_time": "2020-11-29T06:50:19.166998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T06:50:19.305825Z",
     "iopub.status.busy": "2020-11-29T06:50:19.305005Z",
     "iopub.status.idle": "2020-11-29T06:50:57.101279Z",
     "shell.execute_reply": "2020-11-29T06:50:57.100569Z"
    },
    "papermill": {
     "duration": 37.84632,
     "end_time": "2020-11-29T06:50:57.101398",
     "exception": false,
     "start_time": "2020-11-29T06:50:19.255078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (0.23.2)\r\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.4.1)\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.45.0)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.18.5)\r\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.6.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (0.14.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.18.2)\r\n",
      "Installing collected packages: pytorch-tabnet\r\n",
      "Successfully installed pytorch-tabnet-2.0.0\r\n",
      "Processing /kaggle/input/iterative-stratification/iterative-stratification-master\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (1.18.5)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (1.4.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (0.23.2)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.6) (0.14.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.6) (2.1.0)\r\n",
      "Building wheels for collected packages: iterative-stratification\r\n",
      "  Building wheel for iterative-stratification (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for iterative-stratification: filename=iterative_stratification-0.1.6-py3-none-any.whl size=8401 sha256=19969bdd28129a73a9948619b67dc4eb5350eb5f2995b94571c53988e1b2c7e9\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/47/3f/eb4af42d124f37d23d6f13a4c8bbc32c1d70140e6e1cecb4aa\r\n",
      "Successfully built iterative-stratification\r\n",
      "Installing collected packages: iterative-stratification\r\n",
      "Successfully installed iterative-stratification-0.1.6\r\n"
     ]
    }
   ],
   "source": [
    "# TabNet\n",
    "!pip install --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl pytorch-tabnet\n",
    "# Iterative Stratification\n",
    "!pip install /kaggle/input/iterative-stratification/iterative-stratification-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-29T06:50:57.230636Z",
     "iopub.status.busy": "2020-11-29T06:50:57.229738Z",
     "iopub.status.idle": "2020-11-29T06:50:59.782675Z",
     "shell.execute_reply": "2020-11-29T06:50:59.781812Z"
    },
    "papermill": {
     "duration": 2.630028,
     "end_time": "2020-11-29T06:50:59.782793",
     "exception": false,
     "start_time": "2020-11-29T06:50:57.152765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "from scipy import stats\n",
    "import sys\n",
    "import json\n",
    "import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SKLEARN\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix,log_loss,roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import QuantileTransformer, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "\n",
    "#torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Tabnet \n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "# Gauss Rank Scalar\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.special import erf, erfinv\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import FLOAT_DTYPES, check_array, check_is_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049222,
     "end_time": "2020-11-29T06:50:59.881569",
     "exception": false,
     "start_time": "2020-11-29T06:50:59.832347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gauss Rank Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T06:51:00.004684Z",
     "iopub.status.busy": "2020-11-29T06:50:59.993667Z",
     "iopub.status.idle": "2020-11-29T06:51:00.012865Z",
     "shell.execute_reply": "2020-11-29T06:51:00.012357Z"
    },
    "papermill": {
     "duration": 0.082225,
     "end_time": "2020-11-29T06:51:00.012972",
     "exception": false,
     "start_time": "2020-11-29T06:50:59.930747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GaussRankScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transform features by scaling each feature to a normal distribution.\n",
    "    Parameters\n",
    "        ----------\n",
    "        epsilon : float, optional, default 1e-4\n",
    "            A small amount added to the lower bound or subtracted\n",
    "            from the upper bound. This value prevents infinite number\n",
    "            from occurring when applying the inverse error function.\n",
    "        copy : boolean, optional, default True\n",
    "            If False, try to avoid a copy and do inplace scaling instead.\n",
    "            This is not guaranteed to always work inplace; e.g. if the data is\n",
    "            not a NumPy array, a copy may still be returned.\n",
    "        n_jobs : int or None, optional, default None\n",
    "            Number of jobs to run in parallel.\n",
    "            ``None`` means 1 and ``-1`` means using all processors.\n",
    "        interp_kind : str or int, optional, default 'linear'\n",
    "           Specifies the kind of interpolation as a string\n",
    "            ('linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
    "            'previous', 'next', where 'zero', 'slinear', 'quadratic' and 'cubic'\n",
    "            refer to a spline interpolation of zeroth, first, second or third\n",
    "            order; 'previous' and 'next' simply return the previous or next value\n",
    "            of the point) or as an integer specifying the order of the spline\n",
    "            interpolator to use.\n",
    "        interp_copy : bool, optional, default False\n",
    "            If True, the interpolation function makes internal copies of x and y.\n",
    "            If False, references to `x` and `y` are used.\n",
    "        Attributes\n",
    "        ----------\n",
    "        interp_func_ : list\n",
    "            The interpolation function for each feature in the training set.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon=1e-4, copy=True, n_jobs=None, interp_kind='linear', interp_copy=False):\n",
    "        self.epsilon = epsilon\n",
    "        self.copy = copy\n",
    "        self.interp_kind = interp_kind\n",
    "        self.interp_copy = interp_copy\n",
    "        self.fill_value = 'extrapolate'\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit interpolation function to link rank with original data for future scaling\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The data used to fit interpolation function for later scaling along the features axis.\n",
    "        y\n",
    "            Ignored\n",
    "        \"\"\"\n",
    "        X = check_array(X, copy=self.copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        self.interp_func_ = Parallel(n_jobs=self.n_jobs)(delayed(self._fit)(x) for x in X.T)\n",
    "        return self\n",
    "\n",
    "    def _fit(self, x):\n",
    "        x = self.drop_duplicates(x)\n",
    "        rank = np.argsort(np.argsort(x))\n",
    "        bound = 1.0 - self.epsilon\n",
    "        factor = np.max(rank) / 2.0 * bound\n",
    "        scaled_rank = np.clip(rank / factor - bound, -bound, bound)\n",
    "        return interp1d(\n",
    "            x, scaled_rank, kind=self.interp_kind, copy=self.interp_copy, fill_value=self.fill_value)\n",
    "\n",
    "    def transform(self, X, copy=None):\n",
    "        \"\"\"Scale the data with the Gauss Rank algorithm\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The data used to scale along the features axis.\n",
    "        copy : bool, optional (default: None)\n",
    "            Copy the input X or not.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "\n",
    "        copy = copy if copy is not None else self.copy\n",
    "        X = check_array(X, copy=copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "        return X\n",
    "\n",
    "    def _transform(self, i, x):\n",
    "        return erfinv(self.interp_func_[i](x))\n",
    "\n",
    "    def inverse_transform(self, X, copy=None):\n",
    "        \"\"\"Scale back the data to the original representation\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data used to scale along the features axis.\n",
    "        copy : bool, optional (default: None)\n",
    "            Copy the input X or not.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "\n",
    "        copy = copy if copy is not None else self.copy\n",
    "        X = check_array(X, copy=copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._inverse_transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "        return X\n",
    "\n",
    "    def _inverse_transform(self, i, x):\n",
    "        inv_interp_func = interp1d(self.interp_func_[i].y, self.interp_func_[i].x, kind=self.interp_kind,\n",
    "                                   copy=self.interp_copy, fill_value=self.fill_value)\n",
    "        return inv_interp_func(erf(x))\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_duplicates(x):\n",
    "        is_unique = np.zeros_like(x, dtype=bool)\n",
    "        is_unique[np.unique(x, return_index=True)[1]] = True\n",
    "        return x[is_unique]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049709,
     "end_time": "2020-11-29T06:51:00.111982",
     "exception": false,
     "start_time": "2020-11-29T06:51:00.062273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# M13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T06:51:00.247760Z",
     "iopub.status.busy": "2020-11-29T06:51:00.237312Z",
     "iopub.status.idle": "2020-11-29T06:52:01.307080Z",
     "shell.execute_reply": "2020-11-29T06:52:01.306479Z"
    },
    "papermill": {
     "duration": 61.144125,
     "end_time": "2020-11-29T06:52:01.307205",
     "exception": false,
     "start_time": "2020-11-29T06:51:00.163080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENES: ['g-0', 'g-1', 'g-2', 'g-3', 'g-4', 'g-5', 'g-6', 'g-7', 'g-8', 'g-9']\n",
      "CELLS: ['c-0', 'c-1', 'c-2', 'c-3', 'c-4', 'c-5', 'c-6', 'c-7', 'c-8', 'c-9']\n",
      "Processing /kaggle/input/iterative-stratification/iterative-stratification-master\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (1.18.5)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (1.4.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.6) (0.23.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.6) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.6) (0.14.1)\r\n",
      "Building wheels for collected packages: iterative-stratification\r\n",
      "  Building wheel for iterative-stratification (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for iterative-stratification: filename=iterative_stratification-0.1.6-py3-none-any.whl size=8401 sha256=aea080930efc7e4b692ddf0cd12f2f433a4de771907d47e818f36fc12fdcd184\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/47/3f/eb4af42d124f37d23d6f13a4c8bbc32c1d70140e6e1cecb4aa\r\n",
      "Successfully built iterative-stratification\r\n",
      "Installing collected packages: iterative-stratification\r\n",
      "  Attempting uninstall: iterative-stratification\r\n",
      "    Found existing installation: iterative-stratification 0.1.6\r\n",
      "    Uninstalling iterative-stratification-0.1.6:\r\n",
      "      Successfully uninstalled iterative-stratification-0.1.6\r\n",
      "Successfully installed iterative-stratification-0.1.6\r\n",
      "train_features: (23814, 1476)\n",
      "test_features: (3982, 1476)\n",
      "train_features: (23814, 1526)\n",
      "test_features: (3982, 1526)\n",
      "train_features: (23814, 1040)\n",
      "test_features: (3982, 1040)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    " \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.decomposition import PCA\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    " \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "data_dir = '../input/lish-moa/'\n",
    "os.listdir(data_dir)\n",
    "\n",
    "train_features = pd.read_csv(data_dir + 'train_features.csv')\n",
    "train_targets_scored = pd.read_csv(data_dir + 'train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv(data_dir + 'train_targets_nonscored.csv')\n",
    "train_drug = pd.read_csv(data_dir + 'train_drug.csv')\n",
    "test_features = pd.read_csv(data_dir + 'test_features.csv')\n",
    "sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n",
    "\n",
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "\n",
    "print('GENES: {}'.format(GENES[:10]))\n",
    "print('CELLS: {}'.format(CELLS[:10]))\n",
    "\n",
    "!pip install /kaggle/input/iterative-stratification/iterative-stratification-master/\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "for col in (GENES + CELLS):\n",
    "    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = train_features[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]\n",
    "    \n",
    "SEED_VALUE = 42\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=SEED_VALUE)\n",
    "\n",
    "# GENES\n",
    "n_comp = 600\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=SEED_VALUE).fit_transform(data[GENES]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)\n",
    "\n",
    "print('train_features: {}'.format(train_features.shape))\n",
    "print('test_features: {}'.format(test_features.shape))\n",
    "\n",
    "# CELLS\n",
    "n_comp = 50\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=SEED_VALUE).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)\n",
    "\n",
    "print('train_features: {}'.format(train_features.shape))\n",
    "print('test_features: {}'.format(test_features.shape))\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "var_thresh = VarianceThreshold(0.8)\n",
    "data = train_features.append(test_features)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "print('train_features: {}'.format(train_features.shape))\n",
    "print('test_features: {}'.format(test_features.shape))\n",
    "\n",
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train.merge(train_targets_nonscored, on='sig_id')\n",
    "train = train.merge(train_drug, on='sig_id')\n",
    "train = train[train['cp_type'] != 'ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type'] != 'ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)\n",
    "\n",
    "target_cols = [x for x in train_targets_scored.columns if x != 'sig_id']\n",
    "aux_target_cols = [x for x in train_targets_nonscored.columns if x != 'sig_id']\n",
    "all_target_cols = target_cols + aux_target_cols\n",
    "\n",
    "num_targets = len(target_cols)\n",
    "num_aux_targets = len(aux_target_cols)\n",
    "num_all_targets = len(all_target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T06:52:01.481124Z",
     "iopub.status.busy": "2020-11-29T06:52:01.438443Z",
     "iopub.status.idle": "2020-11-29T07:22:56.680855Z",
     "shell.execute_reply": "2020-11-29T07:22:56.681940Z"
    },
    "papermill": {
     "duration": 1855.319254,
     "end_time": "2020-11-29T07:22:56.682154",
     "exception": false,
     "start_time": "2020-11-29T06:52:01.362900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 0, train_loss: 0.483469, valid_loss: 0.020142\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 1, train_loss: 0.015283, valid_loss: 0.010561\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 2, train_loss: 0.013374, valid_loss: 0.009936\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 3, train_loss: 0.013292, valid_loss: 0.009860\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 4, train_loss: 0.012894, valid_loss: 0.009807\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 5, train_loss: 0.012865, valid_loss: 0.011492\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 6, train_loss: 0.012843, valid_loss: 0.009940\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 7, train_loss: 0.012813, valid_loss: 0.009774\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 8, train_loss: 0.012842, valid_loss: 0.009853\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 9, train_loss: 0.012835, valid_loss: 0.009788\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 10, train_loss: 0.012829, valid_loss: 0.009803\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 11, train_loss: 0.012816, valid_loss: 0.009741\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 12, train_loss: 0.012759, valid_loss: 0.009752\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 13, train_loss: 0.012768, valid_loss: 0.009847\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 14, train_loss: 0.012701, valid_loss: 0.009690\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 15, train_loss: 0.012676, valid_loss: 0.009818\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 16, train_loss: 0.012618, valid_loss: 0.009640\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 17, train_loss: 0.012541, valid_loss: 0.009633\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 18, train_loss: 0.012463, valid_loss: 0.009544\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 19, train_loss: 0.012372, valid_loss: 0.009486\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 20, train_loss: 0.012272, valid_loss: 0.009428\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 21, train_loss: 0.012154, valid_loss: 0.009389\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 22, train_loss: 0.012061, valid_loss: 0.009381\n",
      "SEED: 0, FOLD: 0, ALL_TARGETS, EPOCH: 23, train_loss: 0.012018, valid_loss: 0.009366\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 0, train_loss: 0.630018, valid_loss: 0.223508\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 1, train_loss: 0.051945, valid_loss: 0.020040\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 2, train_loss: 0.020839, valid_loss: 0.018192\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 3, train_loss: 0.020013, valid_loss: 0.017969\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 4, train_loss: 0.022512, valid_loss: 0.017832\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 5, train_loss: 0.019817, valid_loss: 0.017927\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 6, train_loss: 0.019625, valid_loss: 0.017841\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 7, train_loss: 0.019573, valid_loss: 0.017845\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 8, train_loss: 0.019794, valid_loss: 0.018116\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 9, train_loss: 0.019633, valid_loss: 0.017751\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 10, train_loss: 0.019451, valid_loss: 0.017848\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 11, train_loss: 0.019386, valid_loss: 0.017785\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 12, train_loss: 0.019593, valid_loss: 0.017875\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 13, train_loss: 0.019383, valid_loss: 0.017885\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 14, train_loss: 0.019276, valid_loss: 0.017814\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 15, train_loss: 0.019046, valid_loss: 0.017854\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 16, train_loss: 0.019314, valid_loss: 0.018060\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 17, train_loss: 0.018980, valid_loss: 0.017717\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 18, train_loss: 0.018616, valid_loss: 0.017805\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 19, train_loss: 0.018318, valid_loss: 0.017766\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 20, train_loss: 0.018002, valid_loss: 0.017779\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 21, train_loss: 0.017773, valid_loss: 0.017779\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 22, train_loss: 0.017655, valid_loss: 0.017784\n",
      "SEED: 0, FOLD: 0, SCORED_ONLY, EPOCH: 23, train_loss: 0.017553, valid_loss: 0.017812\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 0, train_loss: 0.483433, valid_loss: 0.020905\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 1, train_loss: 0.015294, valid_loss: 0.010332\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 2, train_loss: 0.013457, valid_loss: 0.012472\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 3, train_loss: 0.013009, valid_loss: 0.009713\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 4, train_loss: 0.013414, valid_loss: 0.009764\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 5, train_loss: 0.012928, valid_loss: 0.009662\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 6, train_loss: 0.012829, valid_loss: 0.010141\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 7, train_loss: 0.012893, valid_loss: 0.009764\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 8, train_loss: 0.012819, valid_loss: 0.009629\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 9, train_loss: 0.012871, valid_loss: 0.009701\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 10, train_loss: 0.012843, valid_loss: 0.009556\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 11, train_loss: 0.012848, valid_loss: 0.009780\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 12, train_loss: 0.012835, valid_loss: 0.009728\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 13, train_loss: 0.012787, valid_loss: 0.009614\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 14, train_loss: 0.012746, valid_loss: 0.009551\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 15, train_loss: 0.012716, valid_loss: 0.009534\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 16, train_loss: 0.012643, valid_loss: 0.009522\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 17, train_loss: 0.012585, valid_loss: 0.009440\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 18, train_loss: 0.012494, valid_loss: 0.009331\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 19, train_loss: 0.012393, valid_loss: 0.009325\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 20, train_loss: 0.012300, valid_loss: 0.009217\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 21, train_loss: 0.012204, valid_loss: 0.009176\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 22, train_loss: 0.012090, valid_loss: 0.009131\n",
      "SEED: 0, FOLD: 1, ALL_TARGETS, EPOCH: 23, train_loss: 0.012042, valid_loss: 0.009113\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 0, train_loss: 0.627149, valid_loss: 0.215519\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 1, train_loss: 0.051191, valid_loss: 0.020069\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 2, train_loss: 0.020891, valid_loss: 0.018196\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 3, train_loss: 0.020006, valid_loss: 0.017991\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 4, train_loss: 0.021939, valid_loss: 0.017815\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 5, train_loss: 0.019815, valid_loss: 0.017879\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 6, train_loss: 0.019703, valid_loss: 0.017829\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 7, train_loss: 0.019607, valid_loss: 0.017748\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 8, train_loss: 0.019795, valid_loss: 0.017747\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 9, train_loss: 0.019585, valid_loss: 0.017827\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 10, train_loss: 0.019435, valid_loss: 0.017686\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 11, train_loss: 0.019421, valid_loss: 0.017713\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 12, train_loss: 0.019629, valid_loss: 0.017715\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 13, train_loss: 0.019327, valid_loss: 0.017750\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 14, train_loss: 0.019149, valid_loss: 0.017757\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 15, train_loss: 0.019063, valid_loss: 0.017743\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 16, train_loss: 0.019359, valid_loss: 0.017814\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 17, train_loss: 0.018938, valid_loss: 0.017665\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 18, train_loss: 0.018628, valid_loss: 0.017642\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 19, train_loss: 0.018332, valid_loss: 0.017636\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 20, train_loss: 0.018031, valid_loss: 0.017613\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 21, train_loss: 0.017812, valid_loss: 0.017641\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 22, train_loss: 0.017635, valid_loss: 0.017645\n",
      "SEED: 0, FOLD: 1, SCORED_ONLY, EPOCH: 23, train_loss: 0.017557, valid_loss: 0.017653\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 0, train_loss: 0.485340, valid_loss: 0.019329\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 1, train_loss: 0.015515, valid_loss: 0.009815\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 2, train_loss: 0.013354, valid_loss: 0.009121\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 3, train_loss: 0.012922, valid_loss: 0.010549\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 4, train_loss: 0.013026, valid_loss: 0.009032\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 5, train_loss: 0.012897, valid_loss: 0.009111\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 6, train_loss: 0.012884, valid_loss: 0.009016\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 7, train_loss: 0.012890, valid_loss: 0.009730\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 8, train_loss: 0.012874, valid_loss: 0.009075\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 9, train_loss: 0.012859, valid_loss: 0.009078\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 10, train_loss: 0.012889, valid_loss: 0.009032\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 11, train_loss: 0.012852, valid_loss: 0.008966\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 12, train_loss: 0.012831, valid_loss: 0.008935\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 13, train_loss: 0.012804, valid_loss: 0.008992\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 14, train_loss: 0.012754, valid_loss: 0.008916\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 15, train_loss: 0.012736, valid_loss: 0.009025\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 16, train_loss: 0.012686, valid_loss: 0.008910\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 17, train_loss: 0.012588, valid_loss: 0.008880\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 18, train_loss: 0.012537, valid_loss: 0.008849\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 19, train_loss: 0.012413, valid_loss: 0.008745\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 20, train_loss: 0.012304, valid_loss: 0.008697\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 21, train_loss: 0.012208, valid_loss: 0.008635\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 22, train_loss: 0.012106, valid_loss: 0.008620\n",
      "SEED: 0, FOLD: 2, ALL_TARGETS, EPOCH: 23, train_loss: 0.012054, valid_loss: 0.008605\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 0, train_loss: 0.628469, valid_loss: 0.224294\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 1, train_loss: 0.052204, valid_loss: 0.019423\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 2, train_loss: 0.020881, valid_loss: 0.017446\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 3, train_loss: 0.019973, valid_loss: 0.017289\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 4, train_loss: 0.022975, valid_loss: 0.017080\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 5, train_loss: 0.019817, valid_loss: 0.016927\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 6, train_loss: 0.019711, valid_loss: 0.017049\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 7, train_loss: 0.019587, valid_loss: 0.016870\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 8, train_loss: 0.019848, valid_loss: 0.016994\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 9, train_loss: 0.019599, valid_loss: 0.017092\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 10, train_loss: 0.019496, valid_loss: 0.016963\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 11, train_loss: 0.019423, valid_loss: 0.016870\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 12, train_loss: 0.019564, valid_loss: 0.016969\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 13, train_loss: 0.019408, valid_loss: 0.016832\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 14, train_loss: 0.019172, valid_loss: 0.016876\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 15, train_loss: 0.019098, valid_loss: 0.016740\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 16, train_loss: 0.019371, valid_loss: 0.016781\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 17, train_loss: 0.018989, valid_loss: 0.016762\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 18, train_loss: 0.018648, valid_loss: 0.016720\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 19, train_loss: 0.018366, valid_loss: 0.016633\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 20, train_loss: 0.018031, valid_loss: 0.016530\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 21, train_loss: 0.017786, valid_loss: 0.016584\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 22, train_loss: 0.017640, valid_loss: 0.016564\n",
      "SEED: 0, FOLD: 2, SCORED_ONLY, EPOCH: 23, train_loss: 0.017528, valid_loss: 0.016564\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 0, train_loss: 0.486773, valid_loss: 0.020982\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 1, train_loss: 0.015347, valid_loss: 0.010280\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 2, train_loss: 0.013441, valid_loss: 0.009981\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 3, train_loss: 0.013303, valid_loss: 0.012085\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 4, train_loss: 0.013025, valid_loss: 0.009383\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 5, train_loss: 0.012875, valid_loss: 0.009402\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 6, train_loss: 0.012924, valid_loss: 0.009266\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 7, train_loss: 0.012820, valid_loss: 0.009346\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 8, train_loss: 0.012865, valid_loss: 0.009272\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 9, train_loss: 0.012818, valid_loss: 0.009587\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 10, train_loss: 0.012839, valid_loss: 0.009359\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 11, train_loss: 0.012815, valid_loss: 0.009359\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 12, train_loss: 0.012800, valid_loss: 0.009356\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 13, train_loss: 0.012774, valid_loss: 0.009280\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 14, train_loss: 0.012737, valid_loss: 0.009250\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 15, train_loss: 0.012692, valid_loss: 0.009155\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 16, train_loss: 0.012604, valid_loss: 0.009177\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 17, train_loss: 0.012574, valid_loss: 0.009146\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 18, train_loss: 0.012479, valid_loss: 0.009093\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 19, train_loss: 0.012388, valid_loss: 0.009030\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 20, train_loss: 0.012287, valid_loss: 0.009012\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 21, train_loss: 0.012175, valid_loss: 0.008953\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 22, train_loss: 0.012077, valid_loss: 0.008943\n",
      "SEED: 0, FOLD: 3, ALL_TARGETS, EPOCH: 23, train_loss: 0.012027, valid_loss: 0.008921\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 0, train_loss: 0.632064, valid_loss: 0.227443\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 1, train_loss: 0.052264, valid_loss: 0.018828\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 2, train_loss: 0.020829, valid_loss: 0.016936\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 3, train_loss: 0.020013, valid_loss: 0.016746\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 4, train_loss: 0.023459, valid_loss: 0.016460\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 5, train_loss: 0.019794, valid_loss: 0.016485\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 6, train_loss: 0.019646, valid_loss: 0.016485\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 7, train_loss: 0.019527, valid_loss: 0.016525\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 8, train_loss: 0.019771, valid_loss: 0.016536\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 9, train_loss: 0.019561, valid_loss: 0.016569\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 10, train_loss: 0.019404, valid_loss: 0.016434\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 11, train_loss: 0.019369, valid_loss: 0.016515\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 12, train_loss: 0.019649, valid_loss: 0.016581\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 13, train_loss: 0.019368, valid_loss: 0.016308\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 14, train_loss: 0.019214, valid_loss: 0.016393\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 15, train_loss: 0.019074, valid_loss: 0.016455\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 16, train_loss: 0.019413, valid_loss: 0.016332\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 17, train_loss: 0.018984, valid_loss: 0.016347\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 18, train_loss: 0.018633, valid_loss: 0.016307\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 19, train_loss: 0.018333, valid_loss: 0.016243\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 20, train_loss: 0.018027, valid_loss: 0.016271\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 21, train_loss: 0.017732, valid_loss: 0.016263\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 22, train_loss: 0.017593, valid_loss: 0.016250\n",
      "SEED: 0, FOLD: 3, SCORED_ONLY, EPOCH: 23, train_loss: 0.017521, valid_loss: 0.016289\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 0, train_loss: 0.483934, valid_loss: 0.019824\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 1, train_loss: 0.015643, valid_loss: 0.011285\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 2, train_loss: 0.013326, valid_loss: 0.013094\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 3, train_loss: 0.013274, valid_loss: 0.012307\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 4, train_loss: 0.013205, valid_loss: 0.012028\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 5, train_loss: 0.013095, valid_loss: 0.010942\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 6, train_loss: 0.012867, valid_loss: 0.011421\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 7, train_loss: 0.012888, valid_loss: 0.010123\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 8, train_loss: 0.012797, valid_loss: 0.010049\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 9, train_loss: 0.012840, valid_loss: 0.009900\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 10, train_loss: 0.012788, valid_loss: 0.009914\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 11, train_loss: 0.012770, valid_loss: 0.009954\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 12, train_loss: 0.012783, valid_loss: 0.010026\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 13, train_loss: 0.012757, valid_loss: 0.009950\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 14, train_loss: 0.012708, valid_loss: 0.009924\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 15, train_loss: 0.012691, valid_loss: 0.009767\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 16, train_loss: 0.012611, valid_loss: 0.009802\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 17, train_loss: 0.012547, valid_loss: 0.009724\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 18, train_loss: 0.012499, valid_loss: 0.009612\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 19, train_loss: 0.012381, valid_loss: 0.009636\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 20, train_loss: 0.012290, valid_loss: 0.009570\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 21, train_loss: 0.012171, valid_loss: 0.009492\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 22, train_loss: 0.012076, valid_loss: 0.009471\n",
      "SEED: 0, FOLD: 4, ALL_TARGETS, EPOCH: 23, train_loss: 0.012007, valid_loss: 0.009476\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 0, train_loss: 0.634343, valid_loss: 0.219041\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 1, train_loss: 0.051851, valid_loss: 0.020554\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 2, train_loss: 0.020966, valid_loss: 0.018714\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 3, train_loss: 0.020103, valid_loss: 0.018434\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 4, train_loss: 0.021703, valid_loss: 0.018620\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 5, train_loss: 0.019879, valid_loss: 0.018479\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 6, train_loss: 0.019765, valid_loss: 0.018243\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 7, train_loss: 0.019618, valid_loss: 0.018341\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 8, train_loss: 0.019893, valid_loss: 0.018463\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 9, train_loss: 0.019697, valid_loss: 0.018515\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 10, train_loss: 0.019556, valid_loss: 0.018220\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 11, train_loss: 0.019558, valid_loss: 0.018198\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 12, train_loss: 0.019750, valid_loss: 0.018427\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 13, train_loss: 0.019435, valid_loss: 0.018244\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 14, train_loss: 0.019307, valid_loss: 0.018331\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 15, train_loss: 0.019225, valid_loss: 0.018261\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 16, train_loss: 0.019370, valid_loss: 0.018253\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 17, train_loss: 0.019120, valid_loss: 0.018247\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 18, train_loss: 0.018753, valid_loss: 0.018196\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 19, train_loss: 0.018425, valid_loss: 0.018274\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 20, train_loss: 0.018172, valid_loss: 0.018318\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 21, train_loss: 0.017982, valid_loss: 0.018318\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 22, train_loss: 0.017769, valid_loss: 0.018274\n",
      "SEED: 0, FOLD: 4, SCORED_ONLY, EPOCH: 23, train_loss: 0.017695, valid_loss: 0.018260\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 0, train_loss: 0.486359, valid_loss: 0.019065\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 1, train_loss: 0.015396, valid_loss: 0.010249\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 2, train_loss: 0.013296, valid_loss: 0.009835\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 3, train_loss: 0.013604, valid_loss: 0.009748\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 4, train_loss: 0.013022, valid_loss: 0.009780\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 5, train_loss: 0.012946, valid_loss: 0.009641\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 6, train_loss: 0.012960, valid_loss: 0.009558\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 7, train_loss: 0.012911, valid_loss: 0.009704\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 8, train_loss: 0.012871, valid_loss: 0.009580\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 9, train_loss: 0.012868, valid_loss: 0.009800\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 10, train_loss: 0.012850, valid_loss: 0.009561\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 11, train_loss: 0.012825, valid_loss: 0.009586\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 12, train_loss: 0.012784, valid_loss: 0.009600\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 13, train_loss: 0.012784, valid_loss: 0.009571\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 14, train_loss: 0.012718, valid_loss: 0.009486\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 15, train_loss: 0.012661, valid_loss: 0.009565\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 16, train_loss: 0.012620, valid_loss: 0.009425\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 17, train_loss: 0.012551, valid_loss: 0.009386\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 18, train_loss: 0.012483, valid_loss: 0.009341\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 19, train_loss: 0.012389, valid_loss: 0.009291\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 20, train_loss: 0.012281, valid_loss: 0.009240\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 21, train_loss: 0.012160, valid_loss: 0.009127\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 22, train_loss: 0.012058, valid_loss: 0.009122\n",
      "SEED: 0, FOLD: 5, ALL_TARGETS, EPOCH: 23, train_loss: 0.012000, valid_loss: 0.009086\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 0, train_loss: 0.632334, valid_loss: 0.224941\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 1, train_loss: 0.051897, valid_loss: 0.020037\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 2, train_loss: 0.020784, valid_loss: 0.018178\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 3, train_loss: 0.019897, valid_loss: 0.017980\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 4, train_loss: 0.021520, valid_loss: 0.017774\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 5, train_loss: 0.019705, valid_loss: 0.017654\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 6, train_loss: 0.019571, valid_loss: 0.017687\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 7, train_loss: 0.019539, valid_loss: 0.017745\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 8, train_loss: 0.019753, valid_loss: 0.017740\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 9, train_loss: 0.019445, valid_loss: 0.017967\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 10, train_loss: 0.019343, valid_loss: 0.017712\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 11, train_loss: 0.019318, valid_loss: 0.017596\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 12, train_loss: 0.019579, valid_loss: 0.017741\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 13, train_loss: 0.019338, valid_loss: 0.017564\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 14, train_loss: 0.019168, valid_loss: 0.017809\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 15, train_loss: 0.019003, valid_loss: 0.017743\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 16, train_loss: 0.019383, valid_loss: 0.017691\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 17, train_loss: 0.018923, valid_loss: 0.017710\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 18, train_loss: 0.018567, valid_loss: 0.017656\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 19, train_loss: 0.018142, valid_loss: 0.017708\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 20, train_loss: 0.017825, valid_loss: 0.017697\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 21, train_loss: 0.017499, valid_loss: 0.017734\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 22, train_loss: 0.017276, valid_loss: 0.017752\n",
      "SEED: 0, FOLD: 5, SCORED_ONLY, EPOCH: 23, train_loss: 0.017194, valid_loss: 0.017774\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 0, train_loss: 0.484975, valid_loss: 0.020359\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 1, train_loss: 0.015893, valid_loss: 0.011853\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 2, train_loss: 0.013427, valid_loss: 0.010387\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 3, train_loss: 0.013187, valid_loss: 0.010993\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 4, train_loss: 0.013142, valid_loss: 0.011084\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 5, train_loss: 0.013126, valid_loss: 0.010148\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 6, train_loss: 0.012970, valid_loss: 0.010168\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 7, train_loss: 0.012885, valid_loss: 0.010325\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 8, train_loss: 0.012863, valid_loss: 0.010572\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 9, train_loss: 0.012850, valid_loss: 0.010149\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 10, train_loss: 0.012812, valid_loss: 0.010034\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 11, train_loss: 0.012797, valid_loss: 0.010014\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 12, train_loss: 0.012760, valid_loss: 0.010006\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 13, train_loss: 0.012758, valid_loss: 0.010046\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 14, train_loss: 0.012707, valid_loss: 0.010051\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 15, train_loss: 0.012677, valid_loss: 0.010011\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 16, train_loss: 0.012585, valid_loss: 0.009898\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 17, train_loss: 0.012560, valid_loss: 0.009798\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 18, train_loss: 0.012458, valid_loss: 0.009823\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 19, train_loss: 0.012425, valid_loss: 0.009762\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 20, train_loss: 0.012286, valid_loss: 0.009702\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 21, train_loss: 0.012145, valid_loss: 0.009663\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 22, train_loss: 0.012061, valid_loss: 0.009646\n",
      "SEED: 0, FOLD: 6, ALL_TARGETS, EPOCH: 23, train_loss: 0.012012, valid_loss: 0.009623\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 0, train_loss: 0.632523, valid_loss: 0.221489\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 1, train_loss: 0.051919, valid_loss: 0.020164\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 2, train_loss: 0.020948, valid_loss: 0.018222\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 3, train_loss: 0.020071, valid_loss: 0.018087\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 4, train_loss: 0.023074, valid_loss: 0.017745\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 5, train_loss: 0.019878, valid_loss: 0.017689\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 6, train_loss: 0.019785, valid_loss: 0.017695\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 7, train_loss: 0.019650, valid_loss: 0.017686\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 8, train_loss: 0.019793, valid_loss: 0.017656\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 9, train_loss: 0.019676, valid_loss: 0.017677\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 10, train_loss: 0.019617, valid_loss: 0.017534\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 11, train_loss: 0.019520, valid_loss: 0.017683\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 12, train_loss: 0.019766, valid_loss: 0.017470\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 13, train_loss: 0.019456, valid_loss: 0.017496\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 14, train_loss: 0.019235, valid_loss: 0.017632\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 15, train_loss: 0.019157, valid_loss: 0.017593\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 16, train_loss: 0.019447, valid_loss: 0.017514\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 17, train_loss: 0.019143, valid_loss: 0.017502\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 18, train_loss: 0.018701, valid_loss: 0.017377\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 19, train_loss: 0.018513, valid_loss: 0.017455\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 20, train_loss: 0.018244, valid_loss: 0.017375\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 21, train_loss: 0.017964, valid_loss: 0.017397\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 22, train_loss: 0.017763, valid_loss: 0.017405\n",
      "SEED: 0, FOLD: 6, SCORED_ONLY, EPOCH: 23, train_loss: 0.017776, valid_loss: 0.017387\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 0, train_loss: 0.487713, valid_loss: 0.022186\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 1, train_loss: 0.015180, valid_loss: 0.010117\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 2, train_loss: 0.013394, valid_loss: 0.009751\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 3, train_loss: 0.013063, valid_loss: 0.009624\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 4, train_loss: 0.013914, valid_loss: 0.009749\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 5, train_loss: 0.013057, valid_loss: 0.009601\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 6, train_loss: 0.012971, valid_loss: 0.009559\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 7, train_loss: 0.012916, valid_loss: 0.009563\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 8, train_loss: 0.012864, valid_loss: 0.009411\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 9, train_loss: 0.012843, valid_loss: 0.009482\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 10, train_loss: 0.012822, valid_loss: 0.009565\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 11, train_loss: 0.012824, valid_loss: 0.009461\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 12, train_loss: 0.012801, valid_loss: 0.009455\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 13, train_loss: 0.012782, valid_loss: 0.009533\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 14, train_loss: 0.012757, valid_loss: 0.009447\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 15, train_loss: 0.012678, valid_loss: 0.009313\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 16, train_loss: 0.012654, valid_loss: 0.009277\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 17, train_loss: 0.012571, valid_loss: 0.009186\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 18, train_loss: 0.012491, valid_loss: 0.009208\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 19, train_loss: 0.012376, valid_loss: 0.009141\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 20, train_loss: 0.012292, valid_loss: 0.009101\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 21, train_loss: 0.012189, valid_loss: 0.009055\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 22, train_loss: 0.012094, valid_loss: 0.009001\n",
      "SEED: 0, FOLD: 7, ALL_TARGETS, EPOCH: 23, train_loss: 0.012039, valid_loss: 0.009010\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 0, train_loss: 0.632894, valid_loss: 0.223731\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 1, train_loss: 0.052079, valid_loss: 0.019836\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 2, train_loss: 0.020912, valid_loss: 0.017618\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 3, train_loss: 0.020023, valid_loss: 0.017452\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 4, train_loss: 0.023201, valid_loss: 0.017195\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 5, train_loss: 0.019771, valid_loss: 0.017129\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 6, train_loss: 0.019648, valid_loss: 0.017150\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 7, train_loss: 0.019576, valid_loss: 0.017066\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 8, train_loss: 0.019725, valid_loss: 0.017180\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 9, train_loss: 0.019564, valid_loss: 0.017240\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 10, train_loss: 0.019444, valid_loss: 0.017165\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 11, train_loss: 0.019384, valid_loss: 0.017086\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 12, train_loss: 0.019678, valid_loss: 0.017107\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 13, train_loss: 0.019327, valid_loss: 0.017112\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 14, train_loss: 0.019179, valid_loss: 0.017136\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 15, train_loss: 0.019028, valid_loss: 0.017021\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 16, train_loss: 0.019349, valid_loss: 0.017163\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 17, train_loss: 0.018934, valid_loss: 0.017106\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 18, train_loss: 0.018575, valid_loss: 0.017138\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 19, train_loss: 0.018235, valid_loss: 0.017144\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 20, train_loss: 0.017963, valid_loss: 0.017143\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 21, train_loss: 0.017703, valid_loss: 0.017174\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 22, train_loss: 0.017572, valid_loss: 0.017174\n",
      "SEED: 0, FOLD: 7, SCORED_ONLY, EPOCH: 23, train_loss: 0.017484, valid_loss: 0.017148\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 0, train_loss: 0.485177, valid_loss: 0.016230\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 1, train_loss: 0.015441, valid_loss: 0.010273\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 2, train_loss: 0.013621, valid_loss: 0.013002\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 3, train_loss: 0.013233, valid_loss: 0.009634\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 4, train_loss: 0.012818, valid_loss: 0.009757\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 5, train_loss: 0.012811, valid_loss: 0.009497\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 6, train_loss: 0.012846, valid_loss: 0.009640\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 7, train_loss: 0.012824, valid_loss: 0.009619\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 8, train_loss: 0.012819, valid_loss: 0.009677\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 9, train_loss: 0.012810, valid_loss: 0.009459\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 10, train_loss: 0.012826, valid_loss: 0.009534\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 11, train_loss: 0.012820, valid_loss: 0.009494\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 12, train_loss: 0.012784, valid_loss: 0.009765\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 13, train_loss: 0.012745, valid_loss: 0.009673\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 14, train_loss: 0.012746, valid_loss: 0.009652\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 15, train_loss: 0.012673, valid_loss: 0.009476\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 16, train_loss: 0.012613, valid_loss: 0.009371\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 17, train_loss: 0.012546, valid_loss: 0.009345\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 18, train_loss: 0.012467, valid_loss: 0.009330\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 19, train_loss: 0.012369, valid_loss: 0.009207\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 20, train_loss: 0.012273, valid_loss: 0.009169\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 21, train_loss: 0.012160, valid_loss: 0.009112\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 22, train_loss: 0.012071, valid_loss: 0.009073\n",
      "SEED: 0, FOLD: 8, ALL_TARGETS, EPOCH: 23, train_loss: 0.012003, valid_loss: 0.009063\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 0, train_loss: 0.633385, valid_loss: 0.229613\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 1, train_loss: 0.052511, valid_loss: 0.019247\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 2, train_loss: 0.020813, valid_loss: 0.017278\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 3, train_loss: 0.019939, valid_loss: 0.017241\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 4, train_loss: 0.021434, valid_loss: 0.016935\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 5, train_loss: 0.019740, valid_loss: 0.017196\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 6, train_loss: 0.019647, valid_loss: 0.016839\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 7, train_loss: 0.019537, valid_loss: 0.016935\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 8, train_loss: 0.019738, valid_loss: 0.016969\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 9, train_loss: 0.019502, valid_loss: 0.016838\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 10, train_loss: 0.019417, valid_loss: 0.016822\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 11, train_loss: 0.019310, valid_loss: 0.016942\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 12, train_loss: 0.019555, valid_loss: 0.016956\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 13, train_loss: 0.019334, valid_loss: 0.016889\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 14, train_loss: 0.019180, valid_loss: 0.016955\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 15, train_loss: 0.019028, valid_loss: 0.016849\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 16, train_loss: 0.019366, valid_loss: 0.016931\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 17, train_loss: 0.018952, valid_loss: 0.016867\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 18, train_loss: 0.018626, valid_loss: 0.016882\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 19, train_loss: 0.018325, valid_loss: 0.016906\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 20, train_loss: 0.018010, valid_loss: 0.016809\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 21, train_loss: 0.017770, valid_loss: 0.016791\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 22, train_loss: 0.017620, valid_loss: 0.016821\n",
      "SEED: 0, FOLD: 8, SCORED_ONLY, EPOCH: 23, train_loss: 0.017541, valid_loss: 0.016798\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 0, train_loss: 0.486195, valid_loss: 0.017523\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 1, train_loss: 0.015166, valid_loss: 0.010416\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 2, train_loss: 0.013155, valid_loss: 0.009939\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 3, train_loss: 0.013853, valid_loss: 0.009956\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 4, train_loss: 0.013032, valid_loss: 0.009818\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 5, train_loss: 0.012960, valid_loss: 0.009850\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 6, train_loss: 0.012892, valid_loss: 0.009851\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 7, train_loss: 0.012874, valid_loss: 0.009846\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 8, train_loss: 0.012914, valid_loss: 0.009719\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 9, train_loss: 0.012856, valid_loss: 0.009797\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 10, train_loss: 0.012857, valid_loss: 0.009756\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 11, train_loss: 0.012843, valid_loss: 0.009746\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 12, train_loss: 0.012826, valid_loss: 0.009659\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 13, train_loss: 0.012772, valid_loss: 0.009680\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 14, train_loss: 0.012736, valid_loss: 0.009583\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 15, train_loss: 0.012682, valid_loss: 0.009455\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 16, train_loss: 0.012620, valid_loss: 0.009523\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 17, train_loss: 0.012546, valid_loss: 0.009420\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 18, train_loss: 0.012462, valid_loss: 0.009364\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 19, train_loss: 0.012389, valid_loss: 0.009350\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 20, train_loss: 0.012286, valid_loss: 0.009208\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 21, train_loss: 0.012171, valid_loss: 0.009167\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 22, train_loss: 0.012074, valid_loss: 0.009130\n",
      "SEED: 0, FOLD: 9, ALL_TARGETS, EPOCH: 23, train_loss: 0.012024, valid_loss: 0.009101\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 0, train_loss: 0.631606, valid_loss: 0.226752\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 1, train_loss: 0.051808, valid_loss: 0.019068\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 2, train_loss: 0.020863, valid_loss: 0.017130\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 3, train_loss: 0.020005, valid_loss: 0.016958\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 4, train_loss: 0.023026, valid_loss: 0.016638\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 5, train_loss: 0.019768, valid_loss: 0.016615\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 6, train_loss: 0.019690, valid_loss: 0.016770\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 7, train_loss: 0.019564, valid_loss: 0.016803\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 8, train_loss: 0.019867, valid_loss: 0.016825\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 9, train_loss: 0.019594, valid_loss: 0.016655\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 10, train_loss: 0.019515, valid_loss: 0.016745\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 11, train_loss: 0.019414, valid_loss: 0.016559\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 12, train_loss: 0.019656, valid_loss: 0.016824\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 13, train_loss: 0.019429, valid_loss: 0.016539\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 14, train_loss: 0.019249, valid_loss: 0.016652\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 15, train_loss: 0.019114, valid_loss: 0.016557\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 16, train_loss: 0.019427, valid_loss: 0.016603\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 17, train_loss: 0.018994, valid_loss: 0.016511\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 18, train_loss: 0.018703, valid_loss: 0.016595\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 19, train_loss: 0.018326, valid_loss: 0.016650\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 20, train_loss: 0.018016, valid_loss: 0.016651\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 21, train_loss: 0.017736, valid_loss: 0.016625\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 22, train_loss: 0.017565, valid_loss: 0.016641\n",
      "SEED: 0, FOLD: 9, SCORED_ONLY, EPOCH: 23, train_loss: 0.017442, valid_loss: 0.016607\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 0, train_loss: 0.485819, valid_loss: 0.019315\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 1, train_loss: 0.015453, valid_loss: 0.010727\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 2, train_loss: 0.013701, valid_loss: 0.010741\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 3, train_loss: 0.012883, valid_loss: 0.010969\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 4, train_loss: 0.012911, valid_loss: 0.015137\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 5, train_loss: 0.012959, valid_loss: 0.009532\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 6, train_loss: 0.012838, valid_loss: 0.009910\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 7, train_loss: 0.012816, valid_loss: 0.009616\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 8, train_loss: 0.012824, valid_loss: 0.009547\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 9, train_loss: 0.012845, valid_loss: 0.009565\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 10, train_loss: 0.012815, valid_loss: 0.009568\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 11, train_loss: 0.012821, valid_loss: 0.009520\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 12, train_loss: 0.012811, valid_loss: 0.009533\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 13, train_loss: 0.012751, valid_loss: 0.009516\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 14, train_loss: 0.012748, valid_loss: 0.009438\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 15, train_loss: 0.012657, valid_loss: 0.009388\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 16, train_loss: 0.012599, valid_loss: 0.009347\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 17, train_loss: 0.012539, valid_loss: 0.009388\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 18, train_loss: 0.012485, valid_loss: 0.009201\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 19, train_loss: 0.012387, valid_loss: 0.009285\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 20, train_loss: 0.012280, valid_loss: 0.009155\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 21, train_loss: 0.012168, valid_loss: 0.009104\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 22, train_loss: 0.012082, valid_loss: 0.009069\n",
      "SEED: 0, FOLD: 10, ALL_TARGETS, EPOCH: 23, train_loss: 0.012013, valid_loss: 0.009060\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 0, train_loss: 0.631492, valid_loss: 0.225778\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 1, train_loss: 0.051724, valid_loss: 0.019861\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 2, train_loss: 0.020840, valid_loss: 0.017734\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 3, train_loss: 0.019974, valid_loss: 0.017684\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 4, train_loss: 0.022001, valid_loss: 0.017402\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 5, train_loss: 0.019781, valid_loss: 0.017462\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 6, train_loss: 0.019616, valid_loss: 0.017370\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 7, train_loss: 0.019543, valid_loss: 0.017260\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 8, train_loss: 0.019785, valid_loss: 0.017360\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 9, train_loss: 0.019540, valid_loss: 0.017367\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 10, train_loss: 0.019405, valid_loss: 0.017207\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 11, train_loss: 0.019345, valid_loss: 0.017196\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 12, train_loss: 0.019566, valid_loss: 0.017443\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 13, train_loss: 0.019318, valid_loss: 0.017324\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 14, train_loss: 0.019187, valid_loss: 0.017226\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 15, train_loss: 0.019019, valid_loss: 0.017501\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 16, train_loss: 0.019301, valid_loss: 0.017235\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 17, train_loss: 0.018900, valid_loss: 0.017448\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 18, train_loss: 0.018584, valid_loss: 0.017148\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 19, train_loss: 0.018258, valid_loss: 0.017091\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 20, train_loss: 0.017939, valid_loss: 0.017148\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 21, train_loss: 0.017678, valid_loss: 0.017121\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 22, train_loss: 0.017525, valid_loss: 0.017138\n",
      "SEED: 0, FOLD: 10, SCORED_ONLY, EPOCH: 23, train_loss: 0.017416, valid_loss: 0.017093\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 0, train_loss: 0.485458, valid_loss: 0.018706\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 1, train_loss: 0.015109, valid_loss: 0.010761\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 2, train_loss: 0.013143, valid_loss: 0.010499\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 3, train_loss: 0.012868, valid_loss: 0.010122\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 4, train_loss: 0.012745, valid_loss: 0.010028\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 5, train_loss: 0.012819, valid_loss: 0.009967\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 6, train_loss: 0.012746, valid_loss: 0.010099\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 7, train_loss: 0.012754, valid_loss: 0.010061\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 8, train_loss: 0.012762, valid_loss: 0.010265\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 9, train_loss: 0.012774, valid_loss: 0.010014\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 10, train_loss: 0.012771, valid_loss: 0.010102\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 11, train_loss: 0.012746, valid_loss: 0.010060\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 12, train_loss: 0.012762, valid_loss: 0.010032\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 13, train_loss: 0.012732, valid_loss: 0.010047\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 14, train_loss: 0.012682, valid_loss: 0.010036\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 15, train_loss: 0.012640, valid_loss: 0.010099\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 16, train_loss: 0.012576, valid_loss: 0.009928\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 17, train_loss: 0.012497, valid_loss: 0.009869\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 18, train_loss: 0.012436, valid_loss: 0.009811\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 19, train_loss: 0.012343, valid_loss: 0.009754\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 20, train_loss: 0.012241, valid_loss: 0.009700\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 21, train_loss: 0.012139, valid_loss: 0.009629\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 22, train_loss: 0.012044, valid_loss: 0.009614\n",
      "SEED: 1, FOLD: 0, ALL_TARGETS, EPOCH: 23, train_loss: 0.011988, valid_loss: 0.009620\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 0, train_loss: 0.629639, valid_loss: 0.225823\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 1, train_loss: 0.052598, valid_loss: 0.020883\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 2, train_loss: 0.020856, valid_loss: 0.019279\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 3, train_loss: 0.019913, valid_loss: 0.018991\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 4, train_loss: 0.021625, valid_loss: 0.018789\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 5, train_loss: 0.019762, valid_loss: 0.018982\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 6, train_loss: 0.019663, valid_loss: 0.018834\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 7, train_loss: 0.019553, valid_loss: 0.018897\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 8, train_loss: 0.019802, valid_loss: 0.019005\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 9, train_loss: 0.019555, valid_loss: 0.018885\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 10, train_loss: 0.019397, valid_loss: 0.018750\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 11, train_loss: 0.019365, valid_loss: 0.018899\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 12, train_loss: 0.019559, valid_loss: 0.018890\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 13, train_loss: 0.019305, valid_loss: 0.018886\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 14, train_loss: 0.019192, valid_loss: 0.018775\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 15, train_loss: 0.019009, valid_loss: 0.018850\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 16, train_loss: 0.019250, valid_loss: 0.018858\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 17, train_loss: 0.018850, valid_loss: 0.018776\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 18, train_loss: 0.018494, valid_loss: 0.018812\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 19, train_loss: 0.018215, valid_loss: 0.018926\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 20, train_loss: 0.017949, valid_loss: 0.018971\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 21, train_loss: 0.017695, valid_loss: 0.019054\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 22, train_loss: 0.017569, valid_loss: 0.019016\n",
      "SEED: 1, FOLD: 0, SCORED_ONLY, EPOCH: 23, train_loss: 0.017476, valid_loss: 0.018949\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 0, train_loss: 0.486606, valid_loss: 0.086593\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 1, train_loss: 0.015218, valid_loss: 0.010165\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 2, train_loss: 0.013367, valid_loss: 0.009589\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 3, train_loss: 0.013305, valid_loss: 0.009649\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 4, train_loss: 0.012933, valid_loss: 0.009455\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 5, train_loss: 0.012863, valid_loss: 0.009387\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 6, train_loss: 0.012833, valid_loss: 0.009391\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 7, train_loss: 0.012862, valid_loss: 0.009458\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 8, train_loss: 0.012851, valid_loss: 0.009308\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 9, train_loss: 0.012840, valid_loss: 0.009301\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 10, train_loss: 0.012843, valid_loss: 0.009512\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 11, train_loss: 0.012825, valid_loss: 0.009319\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 12, train_loss: 0.012816, valid_loss: 0.009426\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 13, train_loss: 0.012780, valid_loss: 0.009396\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 14, train_loss: 0.012760, valid_loss: 0.009361\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 15, train_loss: 0.012701, valid_loss: 0.009270\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 16, train_loss: 0.012658, valid_loss: 0.009299\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 17, train_loss: 0.012561, valid_loss: 0.009213\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 18, train_loss: 0.012518, valid_loss: 0.009097\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 19, train_loss: 0.012393, valid_loss: 0.009053\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 20, train_loss: 0.012311, valid_loss: 0.009061\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 21, train_loss: 0.012207, valid_loss: 0.008958\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 22, train_loss: 0.012106, valid_loss: 0.008941\n",
      "SEED: 1, FOLD: 1, ALL_TARGETS, EPOCH: 23, train_loss: 0.012049, valid_loss: 0.008949\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 0, train_loss: 0.630501, valid_loss: 0.231753\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 1, train_loss: 0.052930, valid_loss: 0.019389\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 2, train_loss: 0.020883, valid_loss: 0.017451\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 3, train_loss: 0.020028, valid_loss: 0.017119\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 4, train_loss: 0.022217, valid_loss: 0.016876\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 5, train_loss: 0.019851, valid_loss: 0.016931\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 6, train_loss: 0.019713, valid_loss: 0.016930\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 7, train_loss: 0.019616, valid_loss: 0.016885\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 8, train_loss: 0.019851, valid_loss: 0.016851\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 9, train_loss: 0.019621, valid_loss: 0.016963\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 10, train_loss: 0.019539, valid_loss: 0.016872\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 11, train_loss: 0.019453, valid_loss: 0.016881\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 12, train_loss: 0.019674, valid_loss: 0.016785\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 13, train_loss: 0.019423, valid_loss: 0.016711\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 14, train_loss: 0.019287, valid_loss: 0.016812\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 15, train_loss: 0.019135, valid_loss: 0.016886\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 16, train_loss: 0.019384, valid_loss: 0.016747\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 17, train_loss: 0.019002, valid_loss: 0.016861\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 18, train_loss: 0.018667, valid_loss: 0.016713\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 19, train_loss: 0.018413, valid_loss: 0.016807\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 20, train_loss: 0.018090, valid_loss: 0.016778\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 21, train_loss: 0.017856, valid_loss: 0.016757\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 22, train_loss: 0.017703, valid_loss: 0.016784\n",
      "SEED: 1, FOLD: 1, SCORED_ONLY, EPOCH: 23, train_loss: 0.017650, valid_loss: 0.016790\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 0, train_loss: 0.484589, valid_loss: 0.019736\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 1, train_loss: 0.015571, valid_loss: 0.010385\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 2, train_loss: 0.013445, valid_loss: 0.010776\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 3, train_loss: 0.012960, valid_loss: 0.009706\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 4, train_loss: 0.014269, valid_loss: 0.009701\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 5, train_loss: 0.012933, valid_loss: 0.009683\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 6, train_loss: 0.012824, valid_loss: 0.009791\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 7, train_loss: 0.012809, valid_loss: 0.009613\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 8, train_loss: 0.012825, valid_loss: 0.009762\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 9, train_loss: 0.012814, valid_loss: 0.009653\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 10, train_loss: 0.012807, valid_loss: 0.009644\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 11, train_loss: 0.012812, valid_loss: 0.009528\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 12, train_loss: 0.012789, valid_loss: 0.009675\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 13, train_loss: 0.012776, valid_loss: 0.009629\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 14, train_loss: 0.012734, valid_loss: 0.009444\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 15, train_loss: 0.012687, valid_loss: 0.009535\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 16, train_loss: 0.012594, valid_loss: 0.009452\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 17, train_loss: 0.012551, valid_loss: 0.009419\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 18, train_loss: 0.012460, valid_loss: 0.009267\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 19, train_loss: 0.012362, valid_loss: 0.009314\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 20, train_loss: 0.012266, valid_loss: 0.009228\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 21, train_loss: 0.012153, valid_loss: 0.009172\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 22, train_loss: 0.012052, valid_loss: 0.009172\n",
      "SEED: 1, FOLD: 2, ALL_TARGETS, EPOCH: 23, train_loss: 0.011998, valid_loss: 0.009176\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 0, train_loss: 0.635476, valid_loss: 0.229223\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 1, train_loss: 0.052541, valid_loss: 0.020280\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 2, train_loss: 0.020835, valid_loss: 0.018211\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 3, train_loss: 0.019937, valid_loss: 0.018112\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 4, train_loss: 0.022582, valid_loss: 0.017881\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 5, train_loss: 0.019692, valid_loss: 0.017808\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 6, train_loss: 0.019554, valid_loss: 0.017713\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 7, train_loss: 0.019478, valid_loss: 0.017662\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 8, train_loss: 0.019814, valid_loss: 0.017676\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 9, train_loss: 0.019535, valid_loss: 0.017723\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 10, train_loss: 0.019397, valid_loss: 0.017660\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 11, train_loss: 0.019266, valid_loss: 0.017696\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 12, train_loss: 0.019580, valid_loss: 0.017678\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 13, train_loss: 0.019285, valid_loss: 0.017764\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 14, train_loss: 0.019140, valid_loss: 0.017661\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 15, train_loss: 0.018963, valid_loss: 0.017790\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 16, train_loss: 0.019365, valid_loss: 0.017707\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 17, train_loss: 0.018882, valid_loss: 0.017568\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 18, train_loss: 0.018510, valid_loss: 0.017624\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 19, train_loss: 0.018168, valid_loss: 0.017641\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 20, train_loss: 0.017874, valid_loss: 0.017633\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 21, train_loss: 0.017588, valid_loss: 0.017589\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 22, train_loss: 0.017416, valid_loss: 0.017641\n",
      "SEED: 1, FOLD: 2, SCORED_ONLY, EPOCH: 23, train_loss: 0.017313, valid_loss: 0.017625\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 0, train_loss: 0.485182, valid_loss: 0.020485\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 1, train_loss: 0.015221, valid_loss: 0.009938\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 2, train_loss: 0.013342, valid_loss: 0.009256\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 3, train_loss: 0.013004, valid_loss: 0.009191\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 4, train_loss: 0.012882, valid_loss: 0.009268\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 5, train_loss: 0.012995, valid_loss: 0.009176\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 6, train_loss: 0.012939, valid_loss: 0.009195\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 7, train_loss: 0.012888, valid_loss: 0.009316\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 8, train_loss: 0.012881, valid_loss: 0.009302\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 9, train_loss: 0.012873, valid_loss: 0.009233\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 10, train_loss: 0.012859, valid_loss: 0.009304\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 11, train_loss: 0.012860, valid_loss: 0.009189\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 12, train_loss: 0.012837, valid_loss: 0.009249\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 13, train_loss: 0.012808, valid_loss: 0.009122\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 14, train_loss: 0.012785, valid_loss: 0.009095\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 15, train_loss: 0.012724, valid_loss: 0.009090\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 16, train_loss: 0.012649, valid_loss: 0.009041\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 17, train_loss: 0.012614, valid_loss: 0.008964\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 18, train_loss: 0.012490, valid_loss: 0.008883\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 19, train_loss: 0.012401, valid_loss: 0.008857\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 20, train_loss: 0.012319, valid_loss: 0.008781\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 21, train_loss: 0.012212, valid_loss: 0.008719\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 22, train_loss: 0.012114, valid_loss: 0.008717\n",
      "SEED: 1, FOLD: 3, ALL_TARGETS, EPOCH: 23, train_loss: 0.012052, valid_loss: 0.008707\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 0, train_loss: 0.630039, valid_loss: 0.228501\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 1, train_loss: 0.052590, valid_loss: 0.019627\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 2, train_loss: 0.020872, valid_loss: 0.017677\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 3, train_loss: 0.019981, valid_loss: 0.017295\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 4, train_loss: 0.025009, valid_loss: 0.017132\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 5, train_loss: 0.019795, valid_loss: 0.017137\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 6, train_loss: 0.019649, valid_loss: 0.017230\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 7, train_loss: 0.019560, valid_loss: 0.017131\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 8, train_loss: 0.019846, valid_loss: 0.017107\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 9, train_loss: 0.019555, valid_loss: 0.017030\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 10, train_loss: 0.019439, valid_loss: 0.017157\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 11, train_loss: 0.019402, valid_loss: 0.017019\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 12, train_loss: 0.019581, valid_loss: 0.017065\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 13, train_loss: 0.019413, valid_loss: 0.016959\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 14, train_loss: 0.019238, valid_loss: 0.017066\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 15, train_loss: 0.019089, valid_loss: 0.016993\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 16, train_loss: 0.019413, valid_loss: 0.016951\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 17, train_loss: 0.019010, valid_loss: 0.017014\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 18, train_loss: 0.018635, valid_loss: 0.017025\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 19, train_loss: 0.018311, valid_loss: 0.017043\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 20, train_loss: 0.017974, valid_loss: 0.017040\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 21, train_loss: 0.017767, valid_loss: 0.017100\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 22, train_loss: 0.017588, valid_loss: 0.017138\n",
      "SEED: 1, FOLD: 3, SCORED_ONLY, EPOCH: 23, train_loss: 0.017464, valid_loss: 0.017088\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 0, train_loss: 0.485923, valid_loss: 0.019830\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 1, train_loss: 0.015262, valid_loss: 0.010408\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 2, train_loss: 0.013236, valid_loss: 0.010575\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 3, train_loss: 0.012884, valid_loss: 0.009886\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 4, train_loss: 0.012913, valid_loss: 0.009842\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 5, train_loss: 0.012927, valid_loss: 0.009741\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 6, train_loss: 0.012826, valid_loss: 0.009578\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 7, train_loss: 0.012803, valid_loss: 0.009698\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 8, train_loss: 0.012816, valid_loss: 0.009707\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 9, train_loss: 0.012815, valid_loss: 0.009615\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 10, train_loss: 0.012807, valid_loss: 0.009688\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 11, train_loss: 0.012802, valid_loss: 0.009610\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 12, train_loss: 0.012764, valid_loss: 0.009810\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 13, train_loss: 0.012724, valid_loss: 0.009662\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 14, train_loss: 0.012710, valid_loss: 0.009594\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 15, train_loss: 0.012630, valid_loss: 0.009562\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 16, train_loss: 0.012587, valid_loss: 0.009570\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 17, train_loss: 0.012539, valid_loss: 0.009519\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 18, train_loss: 0.012431, valid_loss: 0.009456\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 19, train_loss: 0.012353, valid_loss: 0.009350\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 20, train_loss: 0.012252, valid_loss: 0.009252\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 21, train_loss: 0.012141, valid_loss: 0.009231\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 22, train_loss: 0.012053, valid_loss: 0.009238\n",
      "SEED: 1, FOLD: 4, ALL_TARGETS, EPOCH: 23, train_loss: 0.011993, valid_loss: 0.009216\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 0, train_loss: 0.631860, valid_loss: 0.223819\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 1, train_loss: 0.052489, valid_loss: 0.019622\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 2, train_loss: 0.020852, valid_loss: 0.017757\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 3, train_loss: 0.019993, valid_loss: 0.017435\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 4, train_loss: 0.021431, valid_loss: 0.017266\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 5, train_loss: 0.019757, valid_loss: 0.019625\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 6, train_loss: 0.019657, valid_loss: 0.017403\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 7, train_loss: 0.019514, valid_loss: 0.017311\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 8, train_loss: 0.019712, valid_loss: 0.017457\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 9, train_loss: 0.019486, valid_loss: 0.017255\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 10, train_loss: 0.019441, valid_loss: 0.017259\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 11, train_loss: 0.019311, valid_loss: 0.017304\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 12, train_loss: 0.019592, valid_loss: 0.017294\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 13, train_loss: 0.019292, valid_loss: 0.017206\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 14, train_loss: 0.019189, valid_loss: 0.017175\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 15, train_loss: 0.019024, valid_loss: 0.017215\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 16, train_loss: 0.019287, valid_loss: 0.017237\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 17, train_loss: 0.018920, valid_loss: 0.017109\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 18, train_loss: 0.018559, valid_loss: 0.017082\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 19, train_loss: 0.018198, valid_loss: 0.017042\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 20, train_loss: 0.017939, valid_loss: 0.017030\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 21, train_loss: 0.017693, valid_loss: 0.017067\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 22, train_loss: 0.017539, valid_loss: 0.017061\n",
      "SEED: 1, FOLD: 4, SCORED_ONLY, EPOCH: 23, train_loss: 0.017465, valid_loss: 0.017053\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 0, train_loss: 0.485946, valid_loss: 0.018051\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 1, train_loss: 0.015267, valid_loss: 0.010730\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 2, train_loss: 0.013261, valid_loss: 0.009735\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 3, train_loss: 0.013189, valid_loss: 0.009289\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 4, train_loss: 0.013038, valid_loss: 0.009371\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 5, train_loss: 0.012786, valid_loss: 0.009589\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 6, train_loss: 0.012864, valid_loss: 0.009470\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 7, train_loss: 0.012858, valid_loss: 0.009437\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 8, train_loss: 0.012806, valid_loss: 0.009449\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 9, train_loss: 0.012815, valid_loss: 0.009633\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 10, train_loss: 0.012825, valid_loss: 0.009428\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 11, train_loss: 0.012809, valid_loss: 0.009424\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 12, train_loss: 0.012813, valid_loss: 0.009437\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 13, train_loss: 0.012778, valid_loss: 0.009356\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 14, train_loss: 0.012731, valid_loss: 0.009282\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 15, train_loss: 0.012693, valid_loss: 0.009282\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 16, train_loss: 0.012624, valid_loss: 0.009286\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 17, train_loss: 0.012555, valid_loss: 0.009201\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 18, train_loss: 0.012483, valid_loss: 0.009200\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 19, train_loss: 0.012402, valid_loss: 0.009101\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 20, train_loss: 0.012287, valid_loss: 0.009074\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 21, train_loss: 0.012167, valid_loss: 0.009016\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 22, train_loss: 0.012080, valid_loss: 0.008966\n",
      "SEED: 1, FOLD: 5, ALL_TARGETS, EPOCH: 23, train_loss: 0.012031, valid_loss: 0.008973\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 0, train_loss: 0.628929, valid_loss: 0.224940\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 1, train_loss: 0.052371, valid_loss: 0.019308\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 2, train_loss: 0.020874, valid_loss: 0.017486\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 3, train_loss: 0.019996, valid_loss: 0.017228\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 4, train_loss: 0.021759, valid_loss: 0.017023\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 5, train_loss: 0.019805, valid_loss: 0.017067\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 6, train_loss: 0.019672, valid_loss: 0.016976\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 7, train_loss: 0.019573, valid_loss: 0.017223\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 8, train_loss: 0.019853, valid_loss: 0.017173\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 9, train_loss: 0.019630, valid_loss: 0.017021\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 10, train_loss: 0.019423, valid_loss: 0.016970\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 11, train_loss: 0.019405, valid_loss: 0.017012\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 12, train_loss: 0.019636, valid_loss: 0.017102\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 13, train_loss: 0.019413, valid_loss: 0.016964\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 14, train_loss: 0.019302, valid_loss: 0.017060\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 15, train_loss: 0.019127, valid_loss: 0.017058\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 16, train_loss: 0.019378, valid_loss: 0.016934\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 17, train_loss: 0.018931, valid_loss: 0.016902\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 18, train_loss: 0.018648, valid_loss: 0.016913\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 19, train_loss: 0.018312, valid_loss: 0.016866\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 20, train_loss: 0.018046, valid_loss: 0.016844\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 21, train_loss: 0.017774, valid_loss: 0.016858\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 22, train_loss: 0.017602, valid_loss: 0.016853\n",
      "SEED: 1, FOLD: 5, SCORED_ONLY, EPOCH: 23, train_loss: 0.017543, valid_loss: 0.016860\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 0, train_loss: 0.485767, valid_loss: 0.023747\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 1, train_loss: 0.015265, valid_loss: 0.011231\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 2, train_loss: 0.013486, valid_loss: 0.009881\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 3, train_loss: 0.012943, valid_loss: 0.009735\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 4, train_loss: 0.012799, valid_loss: 0.009650\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 5, train_loss: 0.012850, valid_loss: 0.009712\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 6, train_loss: 0.012829, valid_loss: 0.009925\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 7, train_loss: 0.012874, valid_loss: 0.009823\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 8, train_loss: 0.012806, valid_loss: 0.009760\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 9, train_loss: 0.012827, valid_loss: 0.009712\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 10, train_loss: 0.012806, valid_loss: 0.009837\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 11, train_loss: 0.012798, valid_loss: 0.009747\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 12, train_loss: 0.012799, valid_loss: 0.009774\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 13, train_loss: 0.012786, valid_loss: 0.009584\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 14, train_loss: 0.012745, valid_loss: 0.009592\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 15, train_loss: 0.012672, valid_loss: 0.009607\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 16, train_loss: 0.012628, valid_loss: 0.009520\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 17, train_loss: 0.012554, valid_loss: 0.009440\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 18, train_loss: 0.012499, valid_loss: 0.009437\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 19, train_loss: 0.012387, valid_loss: 0.009317\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 20, train_loss: 0.012269, valid_loss: 0.009274\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 21, train_loss: 0.012178, valid_loss: 0.009203\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 22, train_loss: 0.012075, valid_loss: 0.009173\n",
      "SEED: 1, FOLD: 6, ALL_TARGETS, EPOCH: 23, train_loss: 0.012022, valid_loss: 0.009193\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 0, train_loss: 0.631948, valid_loss: 0.230141\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 1, train_loss: 0.052878, valid_loss: 0.019845\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 2, train_loss: 0.020832, valid_loss: 0.017928\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 3, train_loss: 0.020014, valid_loss: 0.017682\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 4, train_loss: 0.021325, valid_loss: 0.017505\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 5, train_loss: 0.019751, valid_loss: 0.017334\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 6, train_loss: 0.019653, valid_loss: 0.017372\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 7, train_loss: 0.019572, valid_loss: 0.017418\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 8, train_loss: 0.019748, valid_loss: 0.017460\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 9, train_loss: 0.019528, valid_loss: 0.017342\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 10, train_loss: 0.019463, valid_loss: 0.017388\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 11, train_loss: 0.019341, valid_loss: 0.017357\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 12, train_loss: 0.019650, valid_loss: 0.017454\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 13, train_loss: 0.019346, valid_loss: 0.017268\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 14, train_loss: 0.019220, valid_loss: 0.017347\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 15, train_loss: 0.019077, valid_loss: 0.017350\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 16, train_loss: 0.019347, valid_loss: 0.017292\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 17, train_loss: 0.018979, valid_loss: 0.017139\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 18, train_loss: 0.018610, valid_loss: 0.017115\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 19, train_loss: 0.018313, valid_loss: 0.017054\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 20, train_loss: 0.017979, valid_loss: 0.017156\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 21, train_loss: 0.017724, valid_loss: 0.017188\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 22, train_loss: 0.017575, valid_loss: 0.017193\n",
      "SEED: 1, FOLD: 6, SCORED_ONLY, EPOCH: 23, train_loss: 0.017482, valid_loss: 0.017169\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 0, train_loss: 0.484422, valid_loss: 0.019869\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 1, train_loss: 0.015325, valid_loss: 0.010383\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 2, train_loss: 0.013388, valid_loss: 0.010759\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 3, train_loss: 0.013171, valid_loss: 0.011923\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 4, train_loss: 0.012965, valid_loss: 0.010212\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 5, train_loss: 0.013063, valid_loss: 0.011474\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 6, train_loss: 0.013079, valid_loss: 0.011496\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 7, train_loss: 0.012952, valid_loss: 0.009593\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 8, train_loss: 0.012911, valid_loss: 0.009735\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 9, train_loss: 0.012908, valid_loss: 0.009471\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 10, train_loss: 0.012867, valid_loss: 0.009580\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 11, train_loss: 0.012860, valid_loss: 0.009583\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 12, train_loss: 0.012841, valid_loss: 0.009704\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 13, train_loss: 0.012804, valid_loss: 0.009437\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 14, train_loss: 0.012735, valid_loss: 0.009413\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 15, train_loss: 0.012701, valid_loss: 0.009391\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 16, train_loss: 0.012671, valid_loss: 0.009339\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 17, train_loss: 0.012602, valid_loss: 0.009259\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 18, train_loss: 0.012485, valid_loss: 0.009239\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 19, train_loss: 0.012442, valid_loss: 0.009201\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 20, train_loss: 0.012337, valid_loss: 0.009132\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 21, train_loss: 0.012223, valid_loss: 0.009132\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 22, train_loss: 0.012133, valid_loss: 0.009086\n",
      "SEED: 1, FOLD: 7, ALL_TARGETS, EPOCH: 23, train_loss: 0.012062, valid_loss: 0.009066\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 0, train_loss: 0.628524, valid_loss: 0.219175\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 1, train_loss: 0.051763, valid_loss: 0.019779\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 2, train_loss: 0.020973, valid_loss: 0.017848\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 3, train_loss: 0.020135, valid_loss: 0.017646\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 4, train_loss: 0.022871, valid_loss: 0.017671\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 5, train_loss: 0.019945, valid_loss: 0.017468\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 6, train_loss: 0.019839, valid_loss: 0.017412\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 7, train_loss: 0.019741, valid_loss: 0.017516\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 8, train_loss: 0.019869, valid_loss: 0.017717\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 9, train_loss: 0.019731, valid_loss: 0.017483\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 10, train_loss: 0.019611, valid_loss: 0.017456\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 11, train_loss: 0.019569, valid_loss: 0.017420\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 12, train_loss: 0.019726, valid_loss: 0.017576\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 13, train_loss: 0.019492, valid_loss: 0.017646\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 14, train_loss: 0.019411, valid_loss: 0.017499\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 15, train_loss: 0.019242, valid_loss: 0.017384\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 16, train_loss: 0.019396, valid_loss: 0.017455\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 17, train_loss: 0.019073, valid_loss: 0.017314\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 18, train_loss: 0.018800, valid_loss: 0.017306\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 19, train_loss: 0.018565, valid_loss: 0.017264\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 20, train_loss: 0.018290, valid_loss: 0.017182\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 21, train_loss: 0.018054, valid_loss: 0.017232\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 22, train_loss: 0.017974, valid_loss: 0.017248\n",
      "SEED: 1, FOLD: 7, SCORED_ONLY, EPOCH: 23, train_loss: 0.017843, valid_loss: 0.017269\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 0, train_loss: 0.485556, valid_loss: 0.021806\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 1, train_loss: 0.015297, valid_loss: 0.010883\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 2, train_loss: 0.013295, valid_loss: 0.010264\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 3, train_loss: 0.012986, valid_loss: 0.010070\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 4, train_loss: 0.012779, valid_loss: 0.010257\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 5, train_loss: 0.012873, valid_loss: 0.010060\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 6, train_loss: 0.012834, valid_loss: 0.010096\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 7, train_loss: 0.012811, valid_loss: 0.010321\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 8, train_loss: 0.012807, valid_loss: 0.010212\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 9, train_loss: 0.012791, valid_loss: 0.009952\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 10, train_loss: 0.012749, valid_loss: 0.009952\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 11, train_loss: 0.012732, valid_loss: 0.009913\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 12, train_loss: 0.012747, valid_loss: 0.010059\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 13, train_loss: 0.012705, valid_loss: 0.010010\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 14, train_loss: 0.012688, valid_loss: 0.009995\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 15, train_loss: 0.012613, valid_loss: 0.009890\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 16, train_loss: 0.012574, valid_loss: 0.009848\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 17, train_loss: 0.012486, valid_loss: 0.009865\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 18, train_loss: 0.012418, valid_loss: 0.009707\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 19, train_loss: 0.012318, valid_loss: 0.009699\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 20, train_loss: 0.012194, valid_loss: 0.009637\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 21, train_loss: 0.012100, valid_loss: 0.009579\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 22, train_loss: 0.011992, valid_loss: 0.009532\n",
      "SEED: 1, FOLD: 8, ALL_TARGETS, EPOCH: 23, train_loss: 0.011941, valid_loss: 0.009517\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 0, train_loss: 0.630392, valid_loss: 0.226524\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 1, train_loss: 0.052447, valid_loss: 0.020157\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 2, train_loss: 0.020775, valid_loss: 0.018233\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 3, train_loss: 0.019793, valid_loss: 0.018026\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 4, train_loss: 0.023465, valid_loss: 0.017600\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 5, train_loss: 0.019618, valid_loss: 0.017750\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 6, train_loss: 0.019467, valid_loss: 0.017842\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 7, train_loss: 0.019376, valid_loss: 0.017706\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 8, train_loss: 0.019616, valid_loss: 0.017679\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 9, train_loss: 0.019338, valid_loss: 0.017789\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 10, train_loss: 0.019274, valid_loss: 0.017660\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 11, train_loss: 0.019211, valid_loss: 0.017831\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 12, train_loss: 0.019437, valid_loss: 0.017714\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 13, train_loss: 0.019154, valid_loss: 0.017710\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 14, train_loss: 0.019009, valid_loss: 0.017606\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 15, train_loss: 0.018870, valid_loss: 0.017737\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 16, train_loss: 0.019228, valid_loss: 0.017551\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 17, train_loss: 0.018773, valid_loss: 0.017613\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 18, train_loss: 0.018450, valid_loss: 0.017605\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 19, train_loss: 0.018117, valid_loss: 0.017599\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 20, train_loss: 0.017799, valid_loss: 0.017495\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 21, train_loss: 0.017557, valid_loss: 0.017514\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 22, train_loss: 0.017379, valid_loss: 0.017533\n",
      "SEED: 1, FOLD: 8, SCORED_ONLY, EPOCH: 23, train_loss: 0.017280, valid_loss: 0.017515\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 0, train_loss: 0.485252, valid_loss: 0.019425\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 1, train_loss: 0.015167, valid_loss: 0.010634\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 2, train_loss: 0.014039, valid_loss: 0.010153\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 3, train_loss: 0.013010, valid_loss: 0.010118\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 4, train_loss: 0.012807, valid_loss: 0.009964\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 5, train_loss: 0.012905, valid_loss: 0.010120\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 6, train_loss: 0.012798, valid_loss: 0.009938\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 7, train_loss: 0.012827, valid_loss: 0.009920\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 8, train_loss: 0.012825, valid_loss: 0.010153\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 9, train_loss: 0.012799, valid_loss: 0.010048\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 10, train_loss: 0.012790, valid_loss: 0.010042\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 11, train_loss: 0.012778, valid_loss: 0.010032\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 12, train_loss: 0.012785, valid_loss: 0.009952\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 13, train_loss: 0.012763, valid_loss: 0.009916\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 14, train_loss: 0.012712, valid_loss: 0.009841\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 15, train_loss: 0.012651, valid_loss: 0.009821\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 16, train_loss: 0.012600, valid_loss: 0.009748\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 17, train_loss: 0.012539, valid_loss: 0.009724\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 18, train_loss: 0.012449, valid_loss: 0.009728\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 19, train_loss: 0.012368, valid_loss: 0.009635\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 20, train_loss: 0.012250, valid_loss: 0.009550\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 21, train_loss: 0.012157, valid_loss: 0.009509\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 22, train_loss: 0.012050, valid_loss: 0.009467\n",
      "SEED: 1, FOLD: 9, ALL_TARGETS, EPOCH: 23, train_loss: 0.011995, valid_loss: 0.009470\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 0, train_loss: 0.631744, valid_loss: 0.230688\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 1, train_loss: 0.053119, valid_loss: 0.019906\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 2, train_loss: 0.020872, valid_loss: 0.018069\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 3, train_loss: 0.020064, valid_loss: 0.017748\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 4, train_loss: 0.023299, valid_loss: 0.017492\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 5, train_loss: 0.019802, valid_loss: 0.017580\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 6, train_loss: 0.019680, valid_loss: 0.017444\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 7, train_loss: 0.019606, valid_loss: 0.017567\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 8, train_loss: 0.019802, valid_loss: 0.017490\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 9, train_loss: 0.019565, valid_loss: 0.017516\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 10, train_loss: 0.019460, valid_loss: 0.017401\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 11, train_loss: 0.019406, valid_loss: 0.017632\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 12, train_loss: 0.019659, valid_loss: 0.017441\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 13, train_loss: 0.019406, valid_loss: 0.017481\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 14, train_loss: 0.019227, valid_loss: 0.017474\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 15, train_loss: 0.019086, valid_loss: 0.017451\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 16, train_loss: 0.019357, valid_loss: 0.017369\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 17, train_loss: 0.018914, valid_loss: 0.017388\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 18, train_loss: 0.018612, valid_loss: 0.017256\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 19, train_loss: 0.018268, valid_loss: 0.017331\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 20, train_loss: 0.017979, valid_loss: 0.017300\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 21, train_loss: 0.017753, valid_loss: 0.017293\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 22, train_loss: 0.017575, valid_loss: 0.017305\n",
      "SEED: 1, FOLD: 9, SCORED_ONLY, EPOCH: 23, train_loss: 0.017496, valid_loss: 0.017277\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 0, train_loss: 0.483150, valid_loss: 0.017842\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 1, train_loss: 0.015356, valid_loss: 0.010025\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 2, train_loss: 0.013573, valid_loss: 0.010808\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 3, train_loss: 0.013191, valid_loss: 0.010999\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 4, train_loss: 0.013252, valid_loss: 0.009416\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 5, train_loss: 0.013236, valid_loss: 0.009453\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 6, train_loss: 0.012929, valid_loss: 0.009726\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 7, train_loss: 0.012932, valid_loss: 0.009393\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 8, train_loss: 0.012912, valid_loss: 0.009773\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 9, train_loss: 0.012872, valid_loss: 0.009211\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 10, train_loss: 0.012839, valid_loss: 0.009280\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 11, train_loss: 0.012892, valid_loss: 0.009216\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 12, train_loss: 0.012884, valid_loss: 0.009322\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 13, train_loss: 0.012831, valid_loss: 0.009173\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 14, train_loss: 0.012804, valid_loss: 0.009126\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 15, train_loss: 0.012735, valid_loss: 0.009032\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 16, train_loss: 0.012703, valid_loss: 0.009095\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 17, train_loss: 0.012588, valid_loss: 0.009044\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 18, train_loss: 0.012519, valid_loss: 0.009034\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 19, train_loss: 0.012440, valid_loss: 0.008890\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 20, train_loss: 0.012320, valid_loss: 0.008897\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 21, train_loss: 0.012236, valid_loss: 0.008809\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 22, train_loss: 0.012110, valid_loss: 0.008800\n",
      "SEED: 1, FOLD: 10, ALL_TARGETS, EPOCH: 23, train_loss: 0.012080, valid_loss: 0.008785\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 0, train_loss: 0.632847, valid_loss: 0.221903\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 1, train_loss: 0.052241, valid_loss: 0.019120\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 2, train_loss: 0.020997, valid_loss: 0.017270\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 3, train_loss: 0.020125, valid_loss: 0.016886\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 4, train_loss: 0.022644, valid_loss: 0.016737\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 5, train_loss: 0.019905, valid_loss: 0.016804\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 6, train_loss: 0.019723, valid_loss: 0.016621\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 7, train_loss: 0.019730, valid_loss: 0.016660\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 8, train_loss: 0.019814, valid_loss: 0.016721\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 9, train_loss: 0.019754, valid_loss: 0.016792\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 10, train_loss: 0.019608, valid_loss: 0.016648\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 11, train_loss: 0.019485, valid_loss: 0.016778\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 12, train_loss: 0.019779, valid_loss: 0.016652\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 13, train_loss: 0.019570, valid_loss: 0.016666\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 14, train_loss: 0.019443, valid_loss: 0.016760\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 15, train_loss: 0.019293, valid_loss: 0.016652\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 16, train_loss: 0.019563, valid_loss: 0.016783\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 17, train_loss: 0.019180, valid_loss: 0.016770\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 18, train_loss: 0.018834, valid_loss: 0.016571\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 19, train_loss: 0.018386, valid_loss: 0.016718\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 20, train_loss: 0.018235, valid_loss: 0.016697\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 21, train_loss: 0.017917, valid_loss: 0.016707\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 22, train_loss: 0.017814, valid_loss: 0.016725\n",
      "SEED: 1, FOLD: 10, SCORED_ONLY, EPOCH: 23, train_loss: 0.017699, valid_loss: 0.016641\n",
      "CV log_loss:  0.015748882111919278\n"
     ]
    }
   ],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        \n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "        return dct\n",
    "\n",
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    return final_loss\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    return preds\n",
    "\n",
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "            \n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = [1500, 1250, 1000, 750]\n",
    "        self.dropout_value = [0.5, 0.35, 0.3, 0.25]\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dense1 = nn.Linear(num_features, self.hidden_size[0])\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(self.hidden_size[0])\n",
    "        self.dropout2 = nn.Dropout(self.dropout_value[0])\n",
    "        self.dense2 = nn.Linear(self.hidden_size[0], self.hidden_size[1])\n",
    "\n",
    "        self.batch_norm3 = nn.BatchNorm1d(self.hidden_size[1])\n",
    "        self.dropout3 = nn.Dropout(self.dropout_value[1])\n",
    "        self.dense3 = nn.Linear(self.hidden_size[1], self.hidden_size[2])\n",
    "\n",
    "        self.batch_norm4 = nn.BatchNorm1d(self.hidden_size[2])\n",
    "        self.dropout4 = nn.Dropout(self.dropout_value[2])\n",
    "        self.dense4 = nn.Linear(self.hidden_size[2], self.hidden_size[3])\n",
    "\n",
    "        self.batch_norm5 = nn.BatchNorm1d(self.hidden_size[3])\n",
    "        self.dropout5 = nn.Dropout(self.dropout_value[3])\n",
    "        self.dense5 = nn.utils.weight_norm(nn.Linear(self.hidden_size[3], num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.leaky_relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.leaky_relu(self.dense2(x))\n",
    "\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = F.leaky_relu(self.dense3(x))\n",
    "\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = F.leaky_relu(self.dense4(x))\n",
    "\n",
    "        x = self.batch_norm5(x)\n",
    "        x = self.dropout5(x)\n",
    "        x = self.dense5(x)\n",
    "        return x\n",
    "    \n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "            \n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))    \n",
    "\n",
    "class FineTuneScheduler:\n",
    "    def __init__(self, epochs):\n",
    "        self.epochs = epochs\n",
    "        self.epochs_per_step = 0\n",
    "        self.frozen_layers = []\n",
    "\n",
    "    def copy_without_top(self, model, num_features, num_targets, num_targets_new):\n",
    "        self.frozen_layers = []\n",
    "\n",
    "        model_new = Model(num_features, num_targets)\n",
    "        model_new.load_state_dict(model.state_dict())\n",
    "\n",
    "        # Freeze all weights\n",
    "        for name, param in model_new.named_parameters():\n",
    "            layer_index = name.split('.')[0][-1]\n",
    "\n",
    "            if layer_index == 5:\n",
    "                continue\n",
    "\n",
    "            param.requires_grad = False\n",
    "\n",
    "            # Save frozen layer names\n",
    "            if layer_index not in self.frozen_layers:\n",
    "                self.frozen_layers.append(layer_index)\n",
    "\n",
    "        self.epochs_per_step = self.epochs // len(self.frozen_layers)\n",
    "\n",
    "        # Replace the top layers with another ones\n",
    "        model_new.batch_norm5 = nn.BatchNorm1d(model_new.hidden_size[3])\n",
    "        model_new.dropout5 = nn.Dropout(model_new.dropout_value[3])\n",
    "        model_new.dense5 = nn.utils.weight_norm(nn.Linear(model_new.hidden_size[-1], num_targets_new))\n",
    "        model_new.to(DEVICE)\n",
    "        return model_new\n",
    "\n",
    "    def step(self, epoch, model):\n",
    "        if len(self.frozen_layers) == 0:\n",
    "            return\n",
    "\n",
    "        if epoch % self.epochs_per_step == 0:\n",
    "            last_frozen_index = self.frozen_layers[-1]\n",
    "            \n",
    "            # Unfreeze parameters of the last frozen layer\n",
    "            for name, param in model.named_parameters():\n",
    "                layer_index = name.split('.')[0][-1]\n",
    "\n",
    "                if layer_index == last_frozen_index:\n",
    "                    param.requires_grad = True\n",
    "\n",
    "            del self.frozen_layers[-1]  # Remove the last layer as unfrozen\n",
    "\n",
    "def process_data(data):\n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return data\n",
    "\n",
    "feature_cols = [c for c in process_data(train).columns if c not in all_target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold', 'sig_id', 'drug_id']]\n",
    "num_features = len(feature_cols)\n",
    "\n",
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 24\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "WEIGHT_DECAY = {'ALL_TARGETS': 1e-5, 'SCORED_ONLY': 3e-6}\n",
    "MAX_LR = {'ALL_TARGETS': 1e-2, 'SCORED_ONLY': 3e-3}\n",
    "DIV_FACTOR = {'ALL_TARGETS': 1e3, 'SCORED_ONLY': 1e2}\n",
    "PCT_START = 0.1\n",
    "\n",
    "# Show model architecture\n",
    "model = Model(num_features, num_all_targets)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def make_cv_folds(train, SEEDS, NFOLDS, DRUG_THRESH):\n",
    "    vc = train.drug_id.value_counts()\n",
    "    vc1 = vc.loc[vc <= DRUG_THRESH].index.sort_values()\n",
    "    vc2 = vc.loc[vc > DRUG_THRESH].index.sort_values()\n",
    "\n",
    "    for seed_id in range(SEEDS):\n",
    "        kfold_col = 'kfold_{}'.format(seed_id)\n",
    "        \n",
    "        # STRATIFY DRUGS 18X OR LESS\n",
    "        dct1 = {}\n",
    "        dct2 = {}\n",
    "\n",
    "        skf = MultilabelStratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=seed_id)\n",
    "        tmp = train.groupby('drug_id')[target_cols].mean().loc[vc1]\n",
    "\n",
    "        for fold,(idxT, idxV) in enumerate(skf.split(tmp, tmp[target_cols])):\n",
    "            dd = {k: fold for k in tmp.index[idxV].values}\n",
    "            dct1.update(dd)\n",
    "\n",
    "        # STRATIFY DRUGS MORE THAN 18X\n",
    "        skf = MultilabelStratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=seed_id)\n",
    "        tmp = train.loc[train.drug_id.isin(vc2)].reset_index(drop=True)\n",
    "\n",
    "        for fold,(idxT, idxV) in enumerate(skf.split(tmp, tmp[target_cols])):\n",
    "            dd = {k: fold for k in tmp.sig_id[idxV].values}\n",
    "            dct2.update(dd)\n",
    "\n",
    "        # ASSIGN FOLDS\n",
    "        train[kfold_col] = train.drug_id.map(dct1)\n",
    "        train.loc[train[kfold_col].isna(), kfold_col] = train.loc[train[kfold_col].isna(), 'sig_id'].map(dct2)\n",
    "        train[kfold_col] = train[kfold_col].astype('int8')\n",
    "        \n",
    "    return train\n",
    "\n",
    "SEEDS = 2\n",
    "NFOLDS = 11\n",
    "DRUG_THRESH = 18\n",
    "\n",
    "train = make_cv_folds(train, SEEDS, NFOLDS, DRUG_THRESH)\n",
    "train.head()\n",
    "\n",
    "def run_training(fold_id, seed_id):\n",
    "    seed_everything(seed_id)\n",
    "    \n",
    "    train_ = process_data(train)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    kfold_col = f'kfold_{seed_id}'\n",
    "    trn_idx = train_[train_[kfold_col] != fold_id].index\n",
    "    val_idx = train_[train_[kfold_col] == fold_id].index\n",
    "    \n",
    "    train_df = train_[train_[kfold_col] != fold_id].reset_index(drop=True)\n",
    "    valid_df = train_[train_[kfold_col] == fold_id].reset_index(drop=True)\n",
    "    \n",
    "    def train_model(model, tag_name, target_cols_now, fine_tune_scheduler=None):\n",
    "        x_train, y_train  = train_df[feature_cols].values, train_df[target_cols_now].values\n",
    "        x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols_now].values\n",
    "        \n",
    "        train_dataset = MoADataset(x_train, y_train)\n",
    "        valid_dataset = MoADataset(x_valid, y_valid)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=WEIGHT_DECAY[tag_name])\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer,\n",
    "                                                  steps_per_epoch=len(trainloader),\n",
    "                                                  pct_start=PCT_START,\n",
    "                                                  div_factor=DIV_FACTOR[tag_name], \n",
    "                                                  max_lr=MAX_LR[tag_name],\n",
    "                                                  epochs=EPOCHS)\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        loss_tr = SmoothBCEwLogits(smoothing=0.001)\n",
    "\n",
    "        oof = np.zeros((len(train), len(target_cols_now)))\n",
    "        best_loss = np.inf\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            if fine_tune_scheduler is not None:\n",
    "                fine_tune_scheduler.step(epoch, model)\n",
    "\n",
    "            train_loss = train_fn(model, optimizer, scheduler, loss_tr, trainloader, DEVICE)\n",
    "            valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "            print(f\"SEED: {seed_id}, FOLD: {fold_id}, {tag_name}, EPOCH: {epoch}, train_loss: {train_loss:.6f}, valid_loss: {valid_loss:.6f}\")\n",
    "\n",
    "            if np.isnan(valid_loss):\n",
    "                break\n",
    "            \n",
    "            if valid_loss < best_loss:\n",
    "                best_loss = valid_loss\n",
    "                oof[val_idx] = valid_preds\n",
    "                torch.save(model.state_dict(), f\"{tag_name}_FOLD{fold_id}_.pth\")\n",
    "\n",
    "        return oof\n",
    "\n",
    "    fine_tune_scheduler = FineTuneScheduler(EPOCHS)\n",
    "\n",
    "    pretrained_model = Model(num_features, num_all_targets)\n",
    "    pretrained_model.to(DEVICE)\n",
    "\n",
    "    # Train on scored + nonscored targets\n",
    "    train_model(pretrained_model, 'ALL_TARGETS', all_target_cols)\n",
    "\n",
    "    # Load the pretrained model with the best loss\n",
    "    pretrained_model = Model(num_features, num_all_targets)\n",
    "    pretrained_model.load_state_dict(torch.load(f\"ALL_TARGETS_FOLD{fold_id}_.pth\"))\n",
    "    pretrained_model.to(DEVICE)\n",
    "\n",
    "    # Copy model without the top layer\n",
    "    final_model = fine_tune_scheduler.copy_without_top(pretrained_model, num_features, num_all_targets, num_targets)\n",
    "\n",
    "    # Fine-tune the model on scored targets only\n",
    "    oof = train_model(final_model, 'SCORED_ONLY', target_cols, fine_tune_scheduler)\n",
    "\n",
    "    # Load the fine-tuned model with the best loss\n",
    "    model = Model(num_features, num_targets)\n",
    "    model.load_state_dict(torch.load(f\"SCORED_ONLY_FOLD{fold_id}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), num_targets))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    return oof, predictions\n",
    "\n",
    "def run_k_fold(NFOLDS, seed_id):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold_id in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold_id, seed_id)\n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions\n",
    "\n",
    "from time import time\n",
    "\n",
    "# Averaging on multiple SEEDS\n",
    "SEED = [0, 1]\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "time_begin = time()\n",
    "\n",
    "for seed_id in SEED:\n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed_id)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "time_diff = time() - time_begin\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions\n",
    "\n",
    "from datetime import timedelta\n",
    "str(timedelta(seconds=time_diff))\n",
    "\n",
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "\n",
    "for i in range(len(target_cols)):\n",
    "    score += log_loss(y_true[:, i], y_pred[:, i])\n",
    "\n",
    "print(\"CV log_loss: \", score / y_pred.shape[1])\n",
    "\n",
    "sub13 = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.433565,
     "end_time": "2020-11-29T07:22:57.566923",
     "exception": false,
     "start_time": "2020-11-29T07:22:57.133358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-29T07:22:58.433112Z",
     "iopub.status.busy": "2020-11-29T07:22:58.432263Z",
     "iopub.status.idle": "2020-11-29T07:23:03.384835Z",
     "shell.execute_reply": "2020-11-29T07:23:03.385424Z"
    },
    "papermill": {
     "duration": 5.403847,
     "end_time": "2020-11-29T07:23:03.385594",
     "exception": false,
     "start_time": "2020-11-29T07:22:57.981747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')\n",
    "\n",
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "\n",
    "files__ = [] ######################### INPUT FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.41275,
     "end_time": "2020-11-29T07:23:04.208025",
     "exception": false,
     "start_time": "2020-11-29T07:23:03.795275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Data looks loke almost normal. So, forcing it to gaussian distribution doesnot effect the original data. Tramnsformng using QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:05.087850Z",
     "iopub.status.busy": "2020-11-29T07:23:05.085338Z",
     "iopub.status.idle": "2020-11-29T07:23:14.426868Z",
     "shell.execute_reply": "2020-11-29T07:23:14.427347Z"
    },
    "papermill": {
     "duration": 9.773971,
     "end_time": "2020-11-29T07:23:14.427496",
     "exception": false,
     "start_time": "2020-11-29T07:23:04.653525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#RankGauss\n",
    "\n",
    "for col in (GENES + CELLS):\n",
    "\n",
    "    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = train_features[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:15.310005Z",
     "iopub.status.busy": "2020-11-29T07:23:15.308123Z",
     "iopub.status.idle": "2020-11-29T07:23:15.310696Z",
     "shell.execute_reply": "2020-11-29T07:23:15.311155Z"
    },
    "papermill": {
     "duration": 0.429487,
     "end_time": "2020-11-29T07:23:15.311276",
     "exception": false,
     "start_time": "2020-11-29T07:23:14.881789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.416792,
     "end_time": "2020-11-29T07:23:16.151281",
     "exception": false,
     "start_time": "2020-11-29T07:23:15.734489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PCA + Existing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:17.011593Z",
     "iopub.status.busy": "2020-11-29T07:23:17.008794Z",
     "iopub.status.idle": "2020-11-29T07:23:27.930127Z",
     "shell.execute_reply": "2020-11-29T07:23:27.930628Z"
    },
    "papermill": {
     "duration": 11.345884,
     "end_time": "2020-11-29T07:23:27.930781",
     "exception": false,
     "start_time": "2020-11-29T07:23:16.584897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GENES\n",
    "n_comp = 600  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[GENES]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:28.772903Z",
     "iopub.status.busy": "2020-11-29T07:23:28.771639Z",
     "iopub.status.idle": "2020-11-29T07:23:29.450799Z",
     "shell.execute_reply": "2020-11-29T07:23:29.450149Z"
    },
    "papermill": {
     "duration": 1.102495,
     "end_time": "2020-11-29T07:23:29.450919",
     "exception": false,
     "start_time": "2020-11-29T07:23:28.348424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 50  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.413183,
     "end_time": "2020-11-29T07:23:30.278141",
     "exception": false,
     "start_time": "2020-11-29T07:23:29.864958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Selection using Varience Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:31.117963Z",
     "iopub.status.busy": "2020-11-29T07:23:31.116685Z",
     "iopub.status.idle": "2020-11-29T07:23:32.211932Z",
     "shell.execute_reply": "2020-11-29T07:23:32.211153Z"
    },
    "papermill": {
     "duration": 1.514698,
     "end_time": "2020-11-29T07:23:32.212046",
     "exception": false,
     "start_time": "2020-11-29T07:23:30.697348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "var_thresh = VarianceThreshold(0.8)  #<-- Update\n",
    "data = train_features.append(test_features)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:33.050972Z",
     "iopub.status.busy": "2020-11-29T07:23:33.049558Z",
     "iopub.status.idle": "2020-11-29T07:23:33.447510Z",
     "shell.execute_reply": "2020-11-29T07:23:33.446984Z"
    },
    "papermill": {
     "duration": 0.816611,
     "end_time": "2020-11-29T07:23:33.447665",
     "exception": false,
     "start_time": "2020-11-29T07:23:32.631054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]\n",
    "\n",
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)\n",
    "\n",
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.411115,
     "end_time": "2020-11-29T07:23:34.272776",
     "exception": false,
     "start_time": "2020-11-29T07:23:33.861661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CVFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:35.149741Z",
     "iopub.status.busy": "2020-11-29T07:23:35.141697Z",
     "iopub.status.idle": "2020-11-29T07:23:38.095725Z",
     "shell.execute_reply": "2020-11-29T07:23:38.095128Z"
    },
    "papermill": {
     "duration": 3.406274,
     "end_time": "2020-11-29T07:23:38.095845",
     "exception": false,
     "start_time": "2020-11-29T07:23:34.689571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=10)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.417759,
     "end_time": "2020-11-29T07:23:38.961684",
     "exception": false,
     "start_time": "2020-11-29T07:23:38.543925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:39.818536Z",
     "iopub.status.busy": "2020-11-29T07:23:39.816768Z",
     "iopub.status.idle": "2020-11-29T07:23:39.819238Z",
     "shell.execute_reply": "2020-11-29T07:23:39.819761Z"
    },
    "papermill": {
     "duration": 0.42681,
     "end_time": "2020-11-29T07:23:39.819913",
     "exception": false,
     "start_time": "2020-11-29T07:23:39.393103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx,:], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx,:], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx,:], dtype=torch.float)\n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:40.671362Z",
     "iopub.status.busy": "2020-11-29T07:23:40.670634Z",
     "iopub.status.idle": "2020-11-29T07:23:40.674378Z",
     "shell.execute_reply": "2020-11-29T07:23:40.673459Z"
    },
    "papermill": {
     "duration": 0.438604,
     "end_time": "2020-11-29T07:23:40.674480",
     "exception": false,
     "start_time": "2020-11-29T07:23:40.235876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0 \n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:41.531741Z",
     "iopub.status.busy": "2020-11-29T07:23:41.530098Z",
     "iopub.status.idle": "2020-11-29T07:23:41.532818Z",
     "shell.execute_reply": "2020-11-29T07:23:41.533290Z"
    },
    "papermill": {
     "duration": 0.445957,
     "end_time": "2020-11-29T07:23:41.533412",
     "exception": false,
     "start_time": "2020-11-29T07:23:41.087455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.439923,
     "end_time": "2020-11-29T07:23:42.385497",
     "exception": false,
     "start_time": "2020-11-29T07:23:41.945574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:43.225496Z",
     "iopub.status.busy": "2020-11-29T07:23:43.220593Z",
     "iopub.status.idle": "2020-11-29T07:23:43.233208Z",
     "shell.execute_reply": "2020-11-29T07:23:43.234870Z"
    },
    "papermill": {
     "duration": 0.434432,
     "end_time": "2020-11-29T07:23:43.235036",
     "exception": false,
     "start_time": "2020-11-29T07:23:42.800604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.2619422201258426)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.2619422201258426)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.leaky_relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.leaky_relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            # true_dist = pred.data.clone()\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.571024,
     "end_time": "2020-11-29T07:23:44.442099",
     "exception": false,
     "start_time": "2020-11-29T07:23:43.871075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:45.289969Z",
     "iopub.status.busy": "2020-11-29T07:23:45.288675Z",
     "iopub.status.idle": "2020-11-29T07:23:45.479925Z",
     "shell.execute_reply": "2020-11-29T07:23:45.479278Z"
    },
    "papermill": {
     "duration": 0.62105,
     "end_time": "2020-11-29T07:23:45.480057",
     "exception": false,
     "start_time": "2020-11-29T07:23:44.859007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return data\n",
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)\n",
    "\n",
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 10 #################################################################### 7           \n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.584824,
     "end_time": "2020-11-29T07:23:46.482674",
     "exception": false,
     "start_time": "2020-11-29T07:23:45.897850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:47.427556Z",
     "iopub.status.busy": "2020-11-29T07:23:47.425675Z",
     "iopub.status.idle": "2020-11-29T07:23:47.428273Z",
     "shell.execute_reply": "2020-11-29T07:23:47.428751Z"
    },
    "papermill": {
     "duration": 0.455848,
     "end_time": "2020-11-29T07:23:47.428873",
     "exception": false,
     "start_time": "2020-11-29T07:23:46.973025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "   \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n",
    "            files__.append(f\"FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:48.268819Z",
     "iopub.status.busy": "2020-11-29T07:23:48.268131Z",
     "iopub.status.idle": "2020-11-29T07:23:48.272171Z",
     "shell.execute_reply": "2020-11-29T07:23:48.272592Z"
    },
    "papermill": {
     "duration": 0.427142,
     "end_time": "2020-11-29T07:23:48.272739",
     "exception": false,
     "start_time": "2020-11-29T07:23:47.845597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:23:49.356526Z",
     "iopub.status.busy": "2020-11-29T07:23:49.355331Z",
     "iopub.status.idle": "2020-11-29T07:44:48.896335Z",
     "shell.execute_reply": "2020-11-29T07:44:48.899531Z"
    },
    "papermill": {
     "duration": 1260.203886,
     "end_time": "2020-11-29T07:44:48.899768",
     "exception": false,
     "start_time": "2020-11-29T07:23:48.695882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0, EPOCH: 0, train_loss: 0.46682314675661823\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.02452770931025346\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.0236533704664438\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.01849211933505204\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.021808507954401354\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.017635045159194205\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.02059578065189623\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017228512610826228\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.020392540914397086\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.01843412375698487\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.020337880907520173\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017096174001279805\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.02030114600014302\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017391323060211208\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.020310672084170003\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017342933194918767\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.0203382154986743\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017380950661997\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.020370213230771404\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017290517791277833\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.020273250798063892\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.017065292172547843\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.020264959287258886\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.017275772626615234\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.020216435891005302\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.017103915620181296\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.02010843100086335\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.01706422322119276\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.02007066822580753\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.016839986408336297\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.019843495565076027\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.017086966066724725\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.01973065218377498\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01677886334558328\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.019462019505520022\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016729805670264695\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.019208175502717494\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.01660946797993448\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.018841587313480915\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016376034046212833\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.01848201924153874\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016261369403865602\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.01804156120145513\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016207839983205\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.01758719098063246\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.01616221469723516\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.017262854811645325\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.016139550341500178\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.017103545938528354\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.016123156477179792\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.46653423860909476\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.023795347557299666\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.023772336218145586\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.0216548689123657\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02192157059907913\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.01793798390361998\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.020745364324219764\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01768883178010583\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.020348491687928478\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017183114619304735\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.02031719533185805\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017337210321178038\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.020323643520955118\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017286163806501362\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.0204092268020876\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017307824765642483\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.020315470546483992\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.01719129794380731\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.020378179475665094\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017324884318643145\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.02040653697425319\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01686196903594666\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.020262520159444502\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017057659932308726\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.020259373947497338\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.016920445176462334\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.020184768664260066\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.016754444015936718\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.020066478139450474\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.016714147343817685\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.01990961754514325\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.016553535281370085\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01971455481984923\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.01648409566324618\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.0195081511932996\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016349314763728116\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.01918616624128434\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016241856747203402\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.018876733690980942\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016172526197301015\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.018467176032643164\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.0159642337821424\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.018043990607463544\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.015857991555498704\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.01761532517810983\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.015775396695567503\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.01728345545068864\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.01581594648046626\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.017135266653232038\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.015809843213193946\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.4668407073905391\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.026253924187686708\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.023738728415581486\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.01930129248648882\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.02174507903475915\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018406885469125375\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.020687557768917852\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.017766401844306126\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.020316955495265222\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017572045533193484\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.02032342470220981\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017611444720791444\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.020291242255799233\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017973493370744918\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.02039122558649509\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017385196044213243\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.020324823272324377\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.01758443574524588\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.020353318630687654\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01755027359144555\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.020328896564822042\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.01752130811413129\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.020237777478271914\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017615685135953955\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.020203516259789465\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.01722498967622717\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.020138691870435592\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.017300206960903272\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.019981842283760348\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.017231922803653613\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.019831853263801144\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.017016575413031712\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01966800744975767\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.016953802564077906\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.019474847614765166\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016724478401657607\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.019204659255281573\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016556292203151517\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.018887040950357915\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.01647679538776477\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.018520377239873334\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.016364008809129398\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.018068848736584188\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.01633154818167289\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.01760168353756589\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.016196585467292204\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.0172718497894464\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.016218868135992024\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.017126275196431145\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.016194461948341794\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.4675025713900405\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.023974875609079998\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.023878316965795333\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.018862597023447353\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02172181639940508\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.017682909810294706\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.02078158999643018\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017446674561748903\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.020385738185817195\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017148640627662342\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.020304564867288835\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017259474326339033\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.020337247860527808\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017456038803276088\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.020306290710164654\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.017291301913145516\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.020441211904248885\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017458201799955633\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.020362040076044297\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.01723285924850239\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.020333724577100046\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.016985374813278515\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.02027024192915809\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.01725858512024085\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.02022907195552703\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01696812966838479\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.020096715984325254\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.01674723682097263\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.02001522944098519\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.016911812850998506\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.019871450095407424\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.016598107448468607\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.01962423223641611\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.016625133912182517\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.019442689046263693\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.016515749454912212\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.019224240919274667\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01643087678692407\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.018910425072235445\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.016187681609557733\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01847394168256752\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.01604682465808259\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.018069422142880577\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.015836568497535255\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.01761068708954319\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.01577942507962386\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.017290680561094514\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.01575000113290217\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.01713025360217979\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.01573716476559639\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.4671922381726965\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.023636163626280095\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.023633497076169137\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.01892307348963287\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.02176351339345978\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018294553479386702\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.02066336421956939\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017383285539431706\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.020297030491694328\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017445869743824005\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.020295231080343645\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017482444023092587\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.02029927338082944\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017545319472750027\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.02040931254384979\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017303009207050007\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.020368123583255276\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017624211290644273\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.020339664516429747\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.01764671556237671\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.020337452997844067\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.01733950339257717\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.020270592238633863\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017554338193602033\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.02021044013240645\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.017269598734047677\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.020061816455375765\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.01719737094309595\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.02001437288859198\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.0169754797178838\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01979133424259001\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016954445694055822\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.019686742463419515\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.01684792696808775\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01946726676316992\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.01666900510382321\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.01920212652654417\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016839238970230024\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.01888800826404364\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.016481934477471642\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.018486387583036577\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016344360179371305\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.01809017288108026\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.01626734042333232\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.017678659637608837\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.016184939744157925\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.017339426879921266\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.016189450346347358\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.01717999174349731\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.016187999604476824\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.4658215244450877\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.025691933929920197\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.023759521700201496\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.01941904229008489\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.021745297937623916\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.017732471072425444\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.02058964568761087\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.017866129521280527\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.02035675904443187\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.01739236515843206\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.020304674462926005\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.01735923071909282\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.020299832240468073\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.017394506527731817\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.020370652887129016\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.017487168156852324\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.020333070932857453\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.0173739957002302\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.020375178706261418\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.01728376704785559\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.020296815181932142\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.017261738371517923\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.02027783743556469\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.017084935110890202\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.020221999479878332\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.017014044388714764\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.020097907007701935\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.01705049542296264\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.020010051984460122\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.017071765433582995\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.019840221443483907\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.016891888963679474\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.019629932086794605\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.01679527045538028\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.019435244354028856\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.01652215053844783\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.019158330175184434\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.016314953255156677\n",
      "FOLD: 5, EPOCH: 19, train_loss: 0.01883336842781113\n",
      "FOLD: 5, EPOCH: 19, valid_loss: 0.016323348507285118\n",
      "FOLD: 5, EPOCH: 20, train_loss: 0.01841334197069368\n",
      "FOLD: 5, EPOCH: 20, valid_loss: 0.016157771822892956\n",
      "FOLD: 5, EPOCH: 21, train_loss: 0.017979139726488822\n",
      "FOLD: 5, EPOCH: 21, valid_loss: 0.016034425288024876\n",
      "FOLD: 5, EPOCH: 22, train_loss: 0.01755822830262684\n",
      "FOLD: 5, EPOCH: 22, valid_loss: 0.016018420820020966\n",
      "FOLD: 5, EPOCH: 23, train_loss: 0.01721995760115885\n",
      "FOLD: 5, EPOCH: 23, valid_loss: 0.015993807413097885\n",
      "FOLD: 5, EPOCH: 24, train_loss: 0.017048619134772208\n",
      "FOLD: 5, EPOCH: 24, valid_loss: 0.015982468509011798\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.46555564852972187\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.024076104785005253\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.02387718551101223\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.020037360799809296\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.02193612944214575\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.018310312492152054\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.0206387932622625\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.017721233165098563\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.020350066392171767\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.017320957862668566\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.020301432378830447\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.017439060430559847\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.02027470178661808\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.01715574051356978\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.020382059557783987\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.017698619411223464\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.02033223535024351\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.01731503915248646\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.020292537755543186\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.017231062106374238\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.020354195744279893\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.017274220681024924\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.02024344119333452\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.017251215719928343\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.020217899004778554\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.017017736720542114\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.02010389978606855\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.016941716842767265\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.02002638115757896\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.017049219821476273\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.019809438997218685\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.016994017072849803\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.01970955503563727\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.016727825678471062\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.019430791226125534\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.01663693045783374\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.01916448425862097\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.016422809049901035\n",
      "FOLD: 6, EPOCH: 19, train_loss: 0.018873684000103703\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.016295869938201375\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.018467343814911382\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.01619339610139529\n",
      "FOLD: 6, EPOCH: 21, train_loss: 0.018068177841844096\n",
      "FOLD: 6, EPOCH: 21, valid_loss: 0.016059674736526277\n",
      "FOLD: 6, EPOCH: 22, train_loss: 0.017630848102271557\n",
      "FOLD: 6, EPOCH: 22, valid_loss: 0.016041946752617758\n",
      "FOLD: 6, EPOCH: 23, train_loss: 0.017286785571805893\n",
      "FOLD: 6, EPOCH: 23, valid_loss: 0.01600760894103183\n",
      "FOLD: 6, EPOCH: 24, train_loss: 0.017126145586371423\n",
      "FOLD: 6, EPOCH: 24, valid_loss: 0.016035070539348655\n",
      "FOLD: 7, EPOCH: 0, train_loss: 0.46750463236483836\n",
      "FOLD: 7, EPOCH: 0, valid_loss: 0.023948595962590642\n",
      "FOLD: 7, EPOCH: 1, train_loss: 0.023724574547621512\n",
      "FOLD: 7, EPOCH: 1, valid_loss: 0.019936305936425924\n",
      "FOLD: 7, EPOCH: 2, train_loss: 0.021822076891699144\n",
      "FOLD: 7, EPOCH: 2, valid_loss: 0.017673582407749362\n",
      "FOLD: 7, EPOCH: 3, train_loss: 0.020783876195069283\n",
      "FOLD: 7, EPOCH: 3, valid_loss: 0.017480360240572028\n",
      "FOLD: 7, EPOCH: 4, train_loss: 0.020290217476506386\n",
      "FOLD: 7, EPOCH: 4, valid_loss: 0.01716573562266098\n",
      "FOLD: 7, EPOCH: 5, train_loss: 0.02033432519003268\n",
      "FOLD: 7, EPOCH: 5, valid_loss: 0.0171673525021308\n",
      "FOLD: 7, EPOCH: 6, train_loss: 0.020352800130363433\n",
      "FOLD: 7, EPOCH: 6, valid_loss: 0.017323169857263565\n",
      "FOLD: 7, EPOCH: 7, train_loss: 0.020327778977732504\n",
      "FOLD: 7, EPOCH: 7, valid_loss: 0.017016394063830376\n",
      "FOLD: 7, EPOCH: 8, train_loss: 0.020295938945585682\n",
      "FOLD: 7, EPOCH: 8, valid_loss: 0.017397657243741885\n",
      "FOLD: 7, EPOCH: 9, train_loss: 0.020370389004388163\n",
      "FOLD: 7, EPOCH: 9, valid_loss: 0.017295829279141292\n",
      "FOLD: 7, EPOCH: 10, train_loss: 0.020352756796825317\n",
      "FOLD: 7, EPOCH: 10, valid_loss: 0.017140235958827868\n",
      "FOLD: 7, EPOCH: 11, train_loss: 0.02025548640278078\n",
      "FOLD: 7, EPOCH: 11, valid_loss: 0.017328001869221527\n",
      "FOLD: 7, EPOCH: 12, train_loss: 0.020222033500190705\n",
      "FOLD: 7, EPOCH: 12, valid_loss: 0.01709512108936906\n",
      "FOLD: 7, EPOCH: 13, train_loss: 0.020118105026983444\n",
      "FOLD: 7, EPOCH: 13, valid_loss: 0.01694346922967169\n",
      "FOLD: 7, EPOCH: 14, train_loss: 0.019994945475651373\n",
      "FOLD: 7, EPOCH: 14, valid_loss: 0.01673576458253794\n",
      "FOLD: 7, EPOCH: 15, train_loss: 0.01983451635366486\n",
      "FOLD: 7, EPOCH: 15, valid_loss: 0.0167949761574467\n",
      "FOLD: 7, EPOCH: 16, train_loss: 0.019644870777283944\n",
      "FOLD: 7, EPOCH: 16, valid_loss: 0.01672680318976442\n",
      "FOLD: 7, EPOCH: 17, train_loss: 0.019458336070660623\n",
      "FOLD: 7, EPOCH: 17, valid_loss: 0.016462055397116475\n",
      "FOLD: 7, EPOCH: 18, train_loss: 0.019170386187972562\n",
      "FOLD: 7, EPOCH: 18, valid_loss: 0.016235167522811227\n",
      "FOLD: 7, EPOCH: 19, train_loss: 0.018834429348428404\n",
      "FOLD: 7, EPOCH: 19, valid_loss: 0.01618315212221609\n",
      "FOLD: 7, EPOCH: 20, train_loss: 0.0184825201308535\n",
      "FOLD: 7, EPOCH: 20, valid_loss: 0.015991046352105007\n",
      "FOLD: 7, EPOCH: 21, train_loss: 0.018038338170416893\n",
      "FOLD: 7, EPOCH: 21, valid_loss: 0.015889801033255126\n",
      "FOLD: 7, EPOCH: 22, train_loss: 0.017595235757049053\n",
      "FOLD: 7, EPOCH: 22, valid_loss: 0.015817069345050387\n",
      "FOLD: 7, EPOCH: 23, train_loss: 0.017203923110519687\n",
      "FOLD: 7, EPOCH: 23, valid_loss: 0.015823011079596147\n",
      "FOLD: 7, EPOCH: 24, train_loss: 0.01702313988559669\n",
      "FOLD: 7, EPOCH: 24, valid_loss: 0.015812456814779177\n",
      "FOLD: 8, EPOCH: 0, train_loss: 0.464951815828681\n",
      "FOLD: 8, EPOCH: 0, valid_loss: 0.023470887603859108\n",
      "FOLD: 8, EPOCH: 1, train_loss: 0.0237076181798212\n",
      "FOLD: 8, EPOCH: 1, valid_loss: 0.01918796543031931\n",
      "FOLD: 8, EPOCH: 2, train_loss: 0.021714534946987704\n",
      "FOLD: 8, EPOCH: 2, valid_loss: 0.018273822135395475\n",
      "FOLD: 8, EPOCH: 3, train_loss: 0.020887184467527173\n",
      "FOLD: 8, EPOCH: 3, valid_loss: 0.017328116577118635\n",
      "FOLD: 8, EPOCH: 4, train_loss: 0.02035335093255966\n",
      "FOLD: 8, EPOCH: 4, valid_loss: 0.017217779376854498\n",
      "FOLD: 8, EPOCH: 5, train_loss: 0.02031791693260593\n",
      "FOLD: 8, EPOCH: 5, valid_loss: 0.017375543092687924\n",
      "FOLD: 8, EPOCH: 6, train_loss: 0.020368385050565967\n",
      "FOLD: 8, EPOCH: 6, valid_loss: 0.01735229655686352\n",
      "FOLD: 8, EPOCH: 7, train_loss: 0.020322978364363795\n",
      "FOLD: 8, EPOCH: 7, valid_loss: 0.017530846719940502\n",
      "FOLD: 8, EPOCH: 8, train_loss: 0.020360794603343932\n",
      "FOLD: 8, EPOCH: 8, valid_loss: 0.017277504213982157\n",
      "FOLD: 8, EPOCH: 9, train_loss: 0.020341511935957016\n",
      "FOLD: 8, EPOCH: 9, valid_loss: 0.017205560114234686\n",
      "FOLD: 8, EPOCH: 10, train_loss: 0.020374523475766182\n",
      "FOLD: 8, EPOCH: 10, valid_loss: 0.01725811878633168\n",
      "FOLD: 8, EPOCH: 11, train_loss: 0.020255445448621626\n",
      "FOLD: 8, EPOCH: 11, valid_loss: 0.017064437063203916\n",
      "FOLD: 8, EPOCH: 12, train_loss: 0.02022245690947579\n",
      "FOLD: 8, EPOCH: 12, valid_loss: 0.017021773383021355\n",
      "FOLD: 8, EPOCH: 13, train_loss: 0.02017708137150734\n",
      "FOLD: 8, EPOCH: 13, valid_loss: 0.016832982138213184\n",
      "FOLD: 8, EPOCH: 14, train_loss: 0.019995083251307087\n",
      "FOLD: 8, EPOCH: 14, valid_loss: 0.0169709506444633\n",
      "FOLD: 8, EPOCH: 15, train_loss: 0.019918608353022605\n",
      "FOLD: 8, EPOCH: 15, valid_loss: 0.016721188504662778\n",
      "FOLD: 8, EPOCH: 16, train_loss: 0.019666805298578355\n",
      "FOLD: 8, EPOCH: 16, valid_loss: 0.016628038914253313\n",
      "FOLD: 8, EPOCH: 17, train_loss: 0.01945909320587112\n",
      "FOLD: 8, EPOCH: 17, valid_loss: 0.016387209347966645\n",
      "FOLD: 8, EPOCH: 18, train_loss: 0.01922625496743187\n",
      "FOLD: 8, EPOCH: 18, valid_loss: 0.016288778744637966\n",
      "FOLD: 8, EPOCH: 19, train_loss: 0.018826010384626928\n",
      "FOLD: 8, EPOCH: 19, valid_loss: 0.016224133626868326\n",
      "FOLD: 8, EPOCH: 20, train_loss: 0.018480131654970106\n",
      "FOLD: 8, EPOCH: 20, valid_loss: 0.016092094644490216\n",
      "FOLD: 8, EPOCH: 21, train_loss: 0.01804084549507787\n",
      "FOLD: 8, EPOCH: 21, valid_loss: 0.01603081449866295\n",
      "FOLD: 8, EPOCH: 22, train_loss: 0.017636336716673067\n",
      "FOLD: 8, EPOCH: 22, valid_loss: 0.015938153438684013\n",
      "FOLD: 8, EPOCH: 23, train_loss: 0.017328484668847052\n",
      "FOLD: 8, EPOCH: 23, valid_loss: 0.0159294452621705\n",
      "FOLD: 8, EPOCH: 24, train_loss: 0.01715736127788982\n",
      "FOLD: 8, EPOCH: 24, valid_loss: 0.015921964775770903\n",
      "FOLD: 9, EPOCH: 0, train_loss: 0.46639329884802144\n",
      "FOLD: 9, EPOCH: 0, valid_loss: 0.024497838794357248\n",
      "FOLD: 9, EPOCH: 1, train_loss: 0.02367495348857295\n",
      "FOLD: 9, EPOCH: 1, valid_loss: 0.018698658276763227\n",
      "FOLD: 9, EPOCH: 2, train_loss: 0.021912544521112597\n",
      "FOLD: 9, EPOCH: 2, valid_loss: 0.01769353521780835\n",
      "FOLD: 9, EPOCH: 3, train_loss: 0.020763480230685204\n",
      "FOLD: 9, EPOCH: 3, valid_loss: 0.01726467167544696\n",
      "FOLD: 9, EPOCH: 4, train_loss: 0.020327590201650897\n",
      "FOLD: 9, EPOCH: 4, valid_loss: 0.01739286222598619\n",
      "FOLD: 9, EPOCH: 5, train_loss: 0.0203026992298903\n",
      "FOLD: 9, EPOCH: 5, valid_loss: 0.01706827116302318\n",
      "FOLD: 9, EPOCH: 6, train_loss: 0.02033530669587274\n",
      "FOLD: 9, EPOCH: 6, valid_loss: 0.01704251357457704\n",
      "FOLD: 9, EPOCH: 7, train_loss: 0.0203151126542399\n",
      "FOLD: 9, EPOCH: 7, valid_loss: 0.017215691610342927\n",
      "FOLD: 9, EPOCH: 8, train_loss: 0.020316176825473386\n",
      "FOLD: 9, EPOCH: 8, valid_loss: 0.017313798165155783\n",
      "FOLD: 9, EPOCH: 9, train_loss: 0.02031464599553616\n",
      "FOLD: 9, EPOCH: 9, valid_loss: 0.0173089569951925\n",
      "FOLD: 9, EPOCH: 10, train_loss: 0.02031572336150754\n",
      "FOLD: 9, EPOCH: 10, valid_loss: 0.017119056907378964\n",
      "FOLD: 9, EPOCH: 11, train_loss: 0.020330730020519227\n",
      "FOLD: 9, EPOCH: 11, valid_loss: 0.01701655528611607\n",
      "FOLD: 9, EPOCH: 12, train_loss: 0.02023670812768321\n",
      "FOLD: 9, EPOCH: 12, valid_loss: 0.01697269356292155\n",
      "FOLD: 9, EPOCH: 13, train_loss: 0.02020492262897953\n",
      "FOLD: 9, EPOCH: 13, valid_loss: 0.01686666999012232\n",
      "FOLD: 9, EPOCH: 14, train_loss: 0.020053178684846046\n",
      "FOLD: 9, EPOCH: 14, valid_loss: 0.016838740195251174\n",
      "FOLD: 9, EPOCH: 15, train_loss: 0.019878969690011395\n",
      "FOLD: 9, EPOCH: 15, valid_loss: 0.016623381214837234\n",
      "FOLD: 9, EPOCH: 16, train_loss: 0.01971806526905106\n",
      "FOLD: 9, EPOCH: 16, valid_loss: 0.016640028036716912\n",
      "FOLD: 9, EPOCH: 17, train_loss: 0.019464854487488345\n",
      "FOLD: 9, EPOCH: 17, valid_loss: 0.016380026729570493\n",
      "FOLD: 9, EPOCH: 18, train_loss: 0.019164156240801658\n",
      "FOLD: 9, EPOCH: 18, valid_loss: 0.016263104406081967\n",
      "FOLD: 9, EPOCH: 19, train_loss: 0.018877949084966414\n",
      "FOLD: 9, EPOCH: 19, valid_loss: 0.016078695447908506\n",
      "FOLD: 9, EPOCH: 20, train_loss: 0.01850381282068068\n",
      "FOLD: 9, EPOCH: 20, valid_loss: 0.015962040569219325\n",
      "FOLD: 9, EPOCH: 21, train_loss: 0.018040847429825414\n",
      "FOLD: 9, EPOCH: 21, valid_loss: 0.015914029493514035\n",
      "FOLD: 9, EPOCH: 22, train_loss: 0.017654499093130712\n",
      "FOLD: 9, EPOCH: 22, valid_loss: 0.01583809803964363\n",
      "FOLD: 9, EPOCH: 23, train_loss: 0.017332447139966872\n",
      "FOLD: 9, EPOCH: 23, valid_loss: 0.015805640257894993\n",
      "FOLD: 9, EPOCH: 24, train_loss: 0.017126303484603284\n",
      "FOLD: 9, EPOCH: 24, valid_loss: 0.01584638458573156\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.46646967704498\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.02375694705794255\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.024010254550845392\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.01897607081466251\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.021710075269783698\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01747399816910426\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.0206395533897223\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017349650307248037\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.02036844693845318\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.01715801076756583\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.02027109490046578\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.0173789087889923\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.02029965605226255\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.017476847757481866\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.02033648542579143\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.01768476039999061\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.02032052639030641\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.017344195085267227\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.020363294176997677\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.01743206490452091\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.020290399126468166\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.0171546154241595\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.02029165141284466\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.01745202744172679\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.020209820316203178\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.01709528427778019\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.020137039319642128\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017094088718295097\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.02001207106776776\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.017072069510403607\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.019891480344437783\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.0168770811934438\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.019653397281804392\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.01679314233155714\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.01944804288927586\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.016626562561011977\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.019173073227847778\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.0165707400172121\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.018885814728996447\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.016469452685366075\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.01852022744715214\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016364058065745566\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.018024929372533676\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016206850452969473\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.017609491109126997\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.016142879095342424\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.017311434597978667\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.016169773156030312\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.017111642628667816\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.01613995500115885\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.4668808965553199\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.025532748446696334\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.023878187758307304\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.019141185511317518\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.02171448095431251\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.019763884445031483\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.020879517303359123\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.01729871053248644\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.020385977037010655\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017133106477558613\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.02029536040800233\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.01786727189189858\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.020364581264795796\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017224636911931965\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.02039669976840096\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.017404046323564317\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.020397602838854636\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.01738801132887602\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.020361623504469472\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.017111301008197997\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.0203631246402379\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.01701837395214372\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.02036933582876959\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.017045324047406513\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.02033893898610146\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01719532234387265\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.020153189138058695\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.017000013755427465\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.02010622805645389\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.016884747944358323\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.01996829794539559\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01657294388860464\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.01977284300711847\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016383760919173557\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.019499805665785266\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016264197934004996\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.019265942587967842\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016142649783028498\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.018970458479898592\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016072412280158863\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.018566893798209007\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.015886562462482188\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.018158616978795297\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.015722437606503565\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.017777782221955637\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01574107388862305\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.01742399190702746\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.01571825596814354\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.017257933264538165\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.015709162482784852\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.46737377423672904\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.02481070129821698\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.023980719560096342\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.019159426705704793\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.02174657836796776\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.018038494926359918\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.020685435170608182\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.017588488136728603\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.020275357654017785\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017629627655777667\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.020275462238538648\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.01760348900117808\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.02032712142794363\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017432572837505076\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020312574169328135\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017767699538833566\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.020336079837814453\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.0175760541525152\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.02032969185421544\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.01759184141539865\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.02036945696078962\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017404288984835148\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.020264627508098078\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017546480004158285\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.020218362334755158\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017338519657237664\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.02009217288465269\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.017413031206362777\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.020016680297351652\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.017217422421607707\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.019875126428181126\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.01695863198902872\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.01962841300954742\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.017050686861491866\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.019460259077529754\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016763766917089622\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.019156218031721732\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016662345474792853\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.01883023555480665\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.01655807506500019\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.018440795773940703\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.016429340984258387\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.018052470672034446\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.016363700489617057\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.017553071046788847\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.016302444299476013\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.017238699752957592\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.016289249942120578\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.017061677629188185\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.01631856497584118\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.4665000201112801\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.023459351518087916\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.023834676103245828\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.01886803837906983\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.021871321480120384\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.018261491631468136\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.020643432258117583\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.01725428251342641\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.02036991091745515\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017126093204650614\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.020341055491758932\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017281077802181244\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.020331450239304574\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017255188535071082\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.020347136379249633\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.0175201916653249\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.0203443770086573\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.01726556584859888\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.020346948240072497\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.017090975617369015\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.02031080194057957\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017155426709602278\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.020291903939458632\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.0170230398265024\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.0202509687552529\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.01690850220620632\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.020120309978242844\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.016939863976505067\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.019956173110873467\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.016829486418929365\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.01985718934766708\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.016755925336231787\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.019668157687110284\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.016485680722528033\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.01945595307455909\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.016430888324975967\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.019164710864424707\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.01611022889200184\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.018793962162829216\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.01596448922322856\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.018436408355351416\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.015887976934512455\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.017989798064433758\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.015699437508980434\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.017550802086630176\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.015680768475350406\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.017174028701359225\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.01564727433853679\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.017012026353228477\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.01566832683359583\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.466013751203014\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.023939720561934844\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.023758191086592214\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.018999890941712592\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.021792517926904464\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.01815837166375584\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.020678658507043316\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.01759452083044582\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.020300631982184226\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017513623771568138\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.020309752225875853\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017492678844266467\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.020281918827564485\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017354339464671083\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.02032806820446445\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017356613650918007\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.020338613888429058\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.02053853041595883\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.02031885347058696\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017357071240743\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.020314685243272013\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017322321732838947\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.02022941850366131\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017136926866239972\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.02016308406187642\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.01754626248859697\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.020125517189022033\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017250135437481932\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.019938724668275926\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01694655056214995\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.01989586018025875\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.017037308309227228\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.019662903802048777\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016870851680222485\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01947226245557108\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016693582551346883\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.019200154285757772\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016569803054961894\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.018864764837968735\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01646494958549738\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.018461558823623964\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.01623725409929951\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.01802391608756396\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.01620478115768896\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.01761194049350677\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.016192419092274375\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.017308113279361877\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.016141018519798916\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.01710362656102065\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.01615582758353816\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.467183626322977\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.024548977716929384\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.02382779697016362\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.019227647843460243\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.022100806909222757\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.018031725246045325\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.02077717492657323\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.017372127829326525\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.020396933055693102\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.017503330432292488\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.020296128959425033\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.01758771503551139\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.02025675378259151\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.017467946435014408\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.02035889571472522\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.017381235129303403\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.02039465090680507\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.017329407390207052\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.020375349192369368\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.017304156855162647\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.020354965845904044\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.01754077047937446\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.020292295900083357\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.017660820132328406\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.02020804277591167\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.017340754624456167\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.020110256152768288\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.01709721889346838\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.020002494692321748\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.017123600105858512\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.019831480975112607\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.01697563576615519\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.019618886793332714\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.016684256442305114\n",
      "FOLD: 5, EPOCH: 17, train_loss: 0.01941661624418151\n",
      "FOLD: 5, EPOCH: 17, valid_loss: 0.016664610761735175\n",
      "FOLD: 5, EPOCH: 18, train_loss: 0.019112888483270522\n",
      "FOLD: 5, EPOCH: 18, valid_loss: 0.016437259864889912\n",
      "FOLD: 5, EPOCH: 19, train_loss: 0.01880513849037309\n",
      "FOLD: 5, EPOCH: 19, valid_loss: 0.01653555402946141\n",
      "FOLD: 5, EPOCH: 20, train_loss: 0.01842704614203784\n",
      "FOLD: 5, EPOCH: 20, valid_loss: 0.01627283388127883\n",
      "FOLD: 5, EPOCH: 21, train_loss: 0.01798234925034546\n",
      "FOLD: 5, EPOCH: 21, valid_loss: 0.01611563806525535\n",
      "FOLD: 5, EPOCH: 22, train_loss: 0.01753055130642268\n",
      "FOLD: 5, EPOCH: 22, valid_loss: 0.01602167972467012\n",
      "FOLD: 5, EPOCH: 23, train_loss: 0.0171884662261413\n",
      "FOLD: 5, EPOCH: 23, valid_loss: 0.016008757934388187\n",
      "FOLD: 5, EPOCH: 24, train_loss: 0.016979643684481422\n",
      "FOLD: 5, EPOCH: 24, valid_loss: 0.016030087290952604\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.46664819377324274\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.023942070702711742\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.023536747393588867\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.018882449923290148\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.02189421075726709\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.017888755796270236\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.020719884179772868\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.01770504879661732\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.020333692972217838\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.017433044345428545\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.020393367640433775\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.017318110447376966\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.020335046598507513\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.017256988522907097\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.02037099990392885\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.017298419235481158\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.020401286357833493\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.01746165157399244\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.02038897242276899\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.01720002019363973\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.02031031855412068\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.017363015044894483\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.020284189632342707\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.016882257691274088\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.02023747452805119\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.01690653095849686\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.02014068935907656\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.017199029214680195\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.020009733688446784\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.017269724514335394\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.01988476470353142\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.016837640665471554\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.01970997654622601\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.01690079178661108\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.019484105153429892\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.016424645048876602\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.019193645494599496\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.016346965916454792\n",
      "FOLD: 6, EPOCH: 19, train_loss: 0.01892724151332532\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.016354815051373508\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.018497472941394776\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.016245937802725367\n",
      "FOLD: 6, EPOCH: 21, train_loss: 0.018091549976698814\n",
      "FOLD: 6, EPOCH: 21, valid_loss: 0.01607639632291264\n",
      "FOLD: 6, EPOCH: 22, train_loss: 0.01765575049625289\n",
      "FOLD: 6, EPOCH: 22, valid_loss: 0.016080751601192687\n",
      "FOLD: 6, EPOCH: 23, train_loss: 0.01730280831576355\n",
      "FOLD: 6, EPOCH: 23, valid_loss: 0.016057106924967632\n",
      "FOLD: 6, EPOCH: 24, train_loss: 0.017149404430341336\n",
      "FOLD: 6, EPOCH: 24, valid_loss: 0.016058912862920098\n",
      "FOLD: 7, EPOCH: 0, train_loss: 0.46645234492757626\n",
      "FOLD: 7, EPOCH: 0, valid_loss: 0.025081813645859558\n",
      "FOLD: 7, EPOCH: 1, train_loss: 0.023913358019724967\n",
      "FOLD: 7, EPOCH: 1, valid_loss: 0.01910304692056444\n",
      "FOLD: 7, EPOCH: 2, train_loss: 0.02180499227777604\n",
      "FOLD: 7, EPOCH: 2, valid_loss: 0.01819745089030928\n",
      "FOLD: 7, EPOCH: 3, train_loss: 0.021189839525088187\n",
      "FOLD: 7, EPOCH: 3, valid_loss: 0.017299574334174395\n",
      "FOLD: 7, EPOCH: 4, train_loss: 0.02041894253944197\n",
      "FOLD: 7, EPOCH: 4, valid_loss: 0.017524652027835447\n",
      "FOLD: 7, EPOCH: 5, train_loss: 0.02035222066746604\n",
      "FOLD: 7, EPOCH: 5, valid_loss: 0.017285119742155075\n",
      "FOLD: 7, EPOCH: 6, train_loss: 0.020336732616828335\n",
      "FOLD: 7, EPOCH: 6, valid_loss: 0.017392438784655597\n",
      "FOLD: 7, EPOCH: 7, train_loss: 0.020434739284457697\n",
      "FOLD: 7, EPOCH: 7, valid_loss: 0.01768215119631754\n",
      "FOLD: 7, EPOCH: 8, train_loss: 0.02039550240001371\n",
      "FOLD: 7, EPOCH: 8, valid_loss: 0.01716816316669186\n",
      "FOLD: 7, EPOCH: 9, train_loss: 0.020354493298838216\n",
      "FOLD: 7, EPOCH: 9, valid_loss: 0.017351276758644316\n",
      "FOLD: 7, EPOCH: 10, train_loss: 0.0203382600219019\n",
      "FOLD: 7, EPOCH: 10, valid_loss: 0.017214169518815145\n",
      "FOLD: 7, EPOCH: 11, train_loss: 0.020302025505131292\n",
      "FOLD: 7, EPOCH: 11, valid_loss: 0.01719224623714884\n",
      "FOLD: 7, EPOCH: 12, train_loss: 0.020204936917270384\n",
      "FOLD: 7, EPOCH: 12, valid_loss: 0.016929836581564613\n",
      "FOLD: 7, EPOCH: 13, train_loss: 0.02009611776278865\n",
      "FOLD: 7, EPOCH: 13, valid_loss: 0.016863175874782935\n",
      "FOLD: 7, EPOCH: 14, train_loss: 0.020052704154964417\n",
      "FOLD: 7, EPOCH: 14, valid_loss: 0.0167740396120482\n",
      "FOLD: 7, EPOCH: 15, train_loss: 0.019888599841825425\n",
      "FOLD: 7, EPOCH: 15, valid_loss: 0.016684183850884438\n",
      "FOLD: 7, EPOCH: 16, train_loss: 0.019743801749521686\n",
      "FOLD: 7, EPOCH: 16, valid_loss: 0.01651570149179962\n",
      "FOLD: 7, EPOCH: 17, train_loss: 0.0195088492886674\n",
      "FOLD: 7, EPOCH: 17, valid_loss: 0.01656245279850231\n",
      "FOLD: 7, EPOCH: 18, train_loss: 0.019206470719748927\n",
      "FOLD: 7, EPOCH: 18, valid_loss: 0.016192544406900804\n",
      "FOLD: 7, EPOCH: 19, train_loss: 0.01889195305806014\n",
      "FOLD: 7, EPOCH: 19, valid_loss: 0.016102653100258775\n",
      "FOLD: 7, EPOCH: 20, train_loss: 0.01847588133908087\n",
      "FOLD: 7, EPOCH: 20, valid_loss: 0.015936916124903493\n",
      "FOLD: 7, EPOCH: 21, train_loss: 0.01805159929058244\n",
      "FOLD: 7, EPOCH: 21, valid_loss: 0.015869363055874903\n",
      "FOLD: 7, EPOCH: 22, train_loss: 0.01765331633749508\n",
      "FOLD: 7, EPOCH: 22, valid_loss: 0.01582453130847878\n",
      "FOLD: 7, EPOCH: 23, train_loss: 0.017253268359889908\n",
      "FOLD: 7, EPOCH: 23, valid_loss: 0.0158045817580488\n",
      "FOLD: 7, EPOCH: 24, train_loss: 0.017082017954559096\n",
      "FOLD: 7, EPOCH: 24, valid_loss: 0.01579058315191004\n",
      "FOLD: 8, EPOCH: 0, train_loss: 0.46710898528896994\n",
      "FOLD: 8, EPOCH: 0, valid_loss: 0.023792728057338133\n",
      "FOLD: 8, EPOCH: 1, train_loss: 0.024292878998864082\n",
      "FOLD: 8, EPOCH: 1, valid_loss: 0.022654482887850866\n",
      "FOLD: 8, EPOCH: 2, train_loss: 0.02189761257219699\n",
      "FOLD: 8, EPOCH: 2, valid_loss: 0.018172292970120907\n",
      "FOLD: 8, EPOCH: 3, train_loss: 0.020787734946896952\n",
      "FOLD: 8, EPOCH: 3, valid_loss: 0.0172653350358208\n",
      "FOLD: 8, EPOCH: 4, train_loss: 0.020300639564952542\n",
      "FOLD: 8, EPOCH: 4, valid_loss: 0.017658649943768978\n",
      "FOLD: 8, EPOCH: 5, train_loss: 0.020342966072982357\n",
      "FOLD: 8, EPOCH: 5, valid_loss: 0.01718123246812158\n",
      "FOLD: 8, EPOCH: 6, train_loss: 0.020287540603068567\n",
      "FOLD: 8, EPOCH: 6, valid_loss: 0.01720173191279173\n",
      "FOLD: 8, EPOCH: 7, train_loss: 0.020355332786998442\n",
      "FOLD: 8, EPOCH: 7, valid_loss: 0.017496371641755104\n",
      "FOLD: 8, EPOCH: 8, train_loss: 0.020388230561248718\n",
      "FOLD: 8, EPOCH: 8, valid_loss: 0.017235423386510875\n",
      "FOLD: 8, EPOCH: 9, train_loss: 0.02037208862602711\n",
      "FOLD: 8, EPOCH: 9, valid_loss: 0.01736095713244544\n",
      "FOLD: 8, EPOCH: 10, train_loss: 0.020332163211799436\n",
      "FOLD: 8, EPOCH: 10, valid_loss: 0.017154871330906946\n",
      "FOLD: 8, EPOCH: 11, train_loss: 0.02032547314320841\n",
      "FOLD: 8, EPOCH: 11, valid_loss: 0.017138798410693806\n",
      "FOLD: 8, EPOCH: 12, train_loss: 0.0202097553519472\n",
      "FOLD: 8, EPOCH: 12, valid_loss: 0.016977735536379948\n",
      "FOLD: 8, EPOCH: 13, train_loss: 0.02014981263106869\n",
      "FOLD: 8, EPOCH: 13, valid_loss: 0.017018357809219096\n",
      "FOLD: 8, EPOCH: 14, train_loss: 0.020063943788409234\n",
      "FOLD: 8, EPOCH: 14, valid_loss: 0.01690930138445563\n",
      "FOLD: 8, EPOCH: 15, train_loss: 0.019847164555422722\n",
      "FOLD: 8, EPOCH: 15, valid_loss: 0.016824947721842263\n",
      "FOLD: 8, EPOCH: 16, train_loss: 0.01969811569058126\n",
      "FOLD: 8, EPOCH: 16, valid_loss: 0.01651466643023822\n",
      "FOLD: 8, EPOCH: 17, train_loss: 0.019451247948792674\n",
      "FOLD: 8, EPOCH: 17, valid_loss: 0.016344459158264928\n",
      "FOLD: 8, EPOCH: 18, train_loss: 0.019203349082700667\n",
      "FOLD: 8, EPOCH: 18, valid_loss: 0.01622044201940298\n",
      "FOLD: 8, EPOCH: 19, train_loss: 0.01889305529334853\n",
      "FOLD: 8, EPOCH: 19, valid_loss: 0.016191933873213\n",
      "FOLD: 8, EPOCH: 20, train_loss: 0.018468685628425692\n",
      "FOLD: 8, EPOCH: 20, valid_loss: 0.016025859034723706\n",
      "FOLD: 8, EPOCH: 21, train_loss: 0.01800640360602448\n",
      "FOLD: 8, EPOCH: 21, valid_loss: 0.015928323328908946\n",
      "FOLD: 8, EPOCH: 22, train_loss: 0.017576053654474597\n",
      "FOLD: 8, EPOCH: 22, valid_loss: 0.01593054137710068\n",
      "FOLD: 8, EPOCH: 23, train_loss: 0.017199073323319033\n",
      "FOLD: 8, EPOCH: 23, valid_loss: 0.015884474902931187\n",
      "FOLD: 8, EPOCH: 24, train_loss: 0.01705072227745287\n",
      "FOLD: 8, EPOCH: 24, valid_loss: 0.01586572489597731\n",
      "FOLD: 9, EPOCH: 0, train_loss: 0.46585868320638135\n",
      "FOLD: 9, EPOCH: 0, valid_loss: 0.023967026008499995\n",
      "FOLD: 9, EPOCH: 1, train_loss: 0.023902526509857948\n",
      "FOLD: 9, EPOCH: 1, valid_loss: 0.01958314970963531\n",
      "FOLD: 9, EPOCH: 2, train_loss: 0.02183983705697521\n",
      "FOLD: 9, EPOCH: 2, valid_loss: 0.02457198066016038\n",
      "FOLD: 9, EPOCH: 3, train_loss: 0.020915665994248083\n",
      "FOLD: 9, EPOCH: 3, valid_loss: 0.01743659061483211\n",
      "FOLD: 9, EPOCH: 4, train_loss: 0.020359647610495166\n",
      "FOLD: 9, EPOCH: 4, valid_loss: 0.017057733713752694\n",
      "FOLD: 9, EPOCH: 5, train_loss: 0.020364495679255454\n",
      "FOLD: 9, EPOCH: 5, valid_loss: 0.017091607209295034\n",
      "FOLD: 9, EPOCH: 6, train_loss: 0.020323281951488987\n",
      "FOLD: 9, EPOCH: 6, valid_loss: 0.017165393930756383\n",
      "FOLD: 9, EPOCH: 7, train_loss: 0.020291489735245704\n",
      "FOLD: 9, EPOCH: 7, valid_loss: 0.017110552587029006\n",
      "FOLD: 9, EPOCH: 8, train_loss: 0.020411215962902192\n",
      "FOLD: 9, EPOCH: 8, valid_loss: 0.01728751825996571\n",
      "FOLD: 9, EPOCH: 9, train_loss: 0.020377167146052085\n",
      "FOLD: 9, EPOCH: 9, valid_loss: 0.01701587676588032\n",
      "FOLD: 9, EPOCH: 10, train_loss: 0.020336215714773825\n",
      "FOLD: 9, EPOCH: 10, valid_loss: 0.01712690687013997\n",
      "FOLD: 9, EPOCH: 11, train_loss: 0.020314335342376463\n",
      "FOLD: 9, EPOCH: 11, valid_loss: 0.01691221259534359\n",
      "FOLD: 9, EPOCH: 12, train_loss: 0.02021355137469307\n",
      "FOLD: 9, EPOCH: 12, valid_loss: 0.01685501898949345\n",
      "FOLD: 9, EPOCH: 13, train_loss: 0.020134422098917346\n",
      "FOLD: 9, EPOCH: 13, valid_loss: 0.016765759326517582\n",
      "FOLD: 9, EPOCH: 14, train_loss: 0.020019679865048778\n",
      "FOLD: 9, EPOCH: 14, valid_loss: 0.01683116616267297\n",
      "FOLD: 9, EPOCH: 15, train_loss: 0.01987563733371996\n",
      "FOLD: 9, EPOCH: 15, valid_loss: 0.016660268935892317\n",
      "FOLD: 9, EPOCH: 16, train_loss: 0.019686619913385762\n",
      "FOLD: 9, EPOCH: 16, valid_loss: 0.01642770620269908\n",
      "FOLD: 9, EPOCH: 17, train_loss: 0.019445620921830976\n",
      "FOLD: 9, EPOCH: 17, valid_loss: 0.016514689868523016\n",
      "FOLD: 9, EPOCH: 18, train_loss: 0.019268786859127782\n",
      "FOLD: 9, EPOCH: 18, valid_loss: 0.016208517002976604\n",
      "FOLD: 9, EPOCH: 19, train_loss: 0.01890318934475222\n",
      "FOLD: 9, EPOCH: 19, valid_loss: 0.016130227854268417\n",
      "FOLD: 9, EPOCH: 20, train_loss: 0.01850845761476986\n",
      "FOLD: 9, EPOCH: 20, valid_loss: 0.01598160036115183\n",
      "FOLD: 9, EPOCH: 21, train_loss: 0.018044648187295082\n",
      "FOLD: 9, EPOCH: 21, valid_loss: 0.01582507064772977\n",
      "FOLD: 9, EPOCH: 22, train_loss: 0.017631441330717455\n",
      "FOLD: 9, EPOCH: 22, valid_loss: 0.015778168828950986\n",
      "FOLD: 9, EPOCH: 23, train_loss: 0.017324184428059285\n",
      "FOLD: 9, EPOCH: 23, valid_loss: 0.015769028156581853\n",
      "FOLD: 9, EPOCH: 24, train_loss: 0.017102816658875634\n",
      "FOLD: 9, EPOCH: 24, valid_loss: 0.015754722265733614\n",
      "FOLD: 0, EPOCH: 0, train_loss: 0.4666448749962353\n",
      "FOLD: 0, EPOCH: 0, valid_loss: 0.02392277131891913\n",
      "FOLD: 0, EPOCH: 1, train_loss: 0.023798348358081232\n",
      "FOLD: 0, EPOCH: 1, valid_loss: 0.019588038480530184\n",
      "FOLD: 0, EPOCH: 2, train_loss: 0.021696162067594067\n",
      "FOLD: 0, EPOCH: 2, valid_loss: 0.01771125632027785\n",
      "FOLD: 0, EPOCH: 3, train_loss: 0.021072377444755645\n",
      "FOLD: 0, EPOCH: 3, valid_loss: 0.017773314379155636\n",
      "FOLD: 0, EPOCH: 4, train_loss: 0.020394509934609936\n",
      "FOLD: 0, EPOCH: 4, valid_loss: 0.017339498839444585\n",
      "FOLD: 0, EPOCH: 5, train_loss: 0.020329594131438963\n",
      "FOLD: 0, EPOCH: 5, valid_loss: 0.017388895205739472\n",
      "FOLD: 0, EPOCH: 6, train_loss: 0.020352587248048476\n",
      "FOLD: 0, EPOCH: 6, valid_loss: 0.01754394866940048\n",
      "FOLD: 0, EPOCH: 7, train_loss: 0.02033699760513921\n",
      "FOLD: 0, EPOCH: 7, valid_loss: 0.017395821089545887\n",
      "FOLD: 0, EPOCH: 8, train_loss: 0.020372143279640906\n",
      "FOLD: 0, EPOCH: 8, valid_loss: 0.0173322262449397\n",
      "FOLD: 0, EPOCH: 9, train_loss: 0.02037346977139673\n",
      "FOLD: 0, EPOCH: 9, valid_loss: 0.017768879265834887\n",
      "FOLD: 0, EPOCH: 10, train_loss: 0.02033305708919802\n",
      "FOLD: 0, EPOCH: 10, valid_loss: 0.017268345173862245\n",
      "FOLD: 0, EPOCH: 11, train_loss: 0.02024550411489702\n",
      "FOLD: 0, EPOCH: 11, valid_loss: 0.017135148402303457\n",
      "FOLD: 0, EPOCH: 12, train_loss: 0.02016854640096426\n",
      "FOLD: 0, EPOCH: 12, valid_loss: 0.017158556263893843\n",
      "FOLD: 0, EPOCH: 13, train_loss: 0.020100583580713118\n",
      "FOLD: 0, EPOCH: 13, valid_loss: 0.017048404965963628\n",
      "FOLD: 0, EPOCH: 14, train_loss: 0.019960145183628604\n",
      "FOLD: 0, EPOCH: 14, valid_loss: 0.01706400875829988\n",
      "FOLD: 0, EPOCH: 15, train_loss: 0.019849730078731812\n",
      "FOLD: 0, EPOCH: 15, valid_loss: 0.017026431548098724\n",
      "FOLD: 0, EPOCH: 16, train_loss: 0.019675421204057433\n",
      "FOLD: 0, EPOCH: 16, valid_loss: 0.016711980207926698\n",
      "FOLD: 0, EPOCH: 17, train_loss: 0.019393295566401174\n",
      "FOLD: 0, EPOCH: 17, valid_loss: 0.01656989546285735\n",
      "FOLD: 0, EPOCH: 18, train_loss: 0.019135458262697344\n",
      "FOLD: 0, EPOCH: 18, valid_loss: 0.016446816579749186\n",
      "FOLD: 0, EPOCH: 19, train_loss: 0.01884671333696573\n",
      "FOLD: 0, EPOCH: 19, valid_loss: 0.01640581049852901\n",
      "FOLD: 0, EPOCH: 20, train_loss: 0.0183932451711547\n",
      "FOLD: 0, EPOCH: 20, valid_loss: 0.016266174821390048\n",
      "FOLD: 0, EPOCH: 21, train_loss: 0.017976765250486713\n",
      "FOLD: 0, EPOCH: 21, valid_loss: 0.016161052613622613\n",
      "FOLD: 0, EPOCH: 22, train_loss: 0.01748577167670573\n",
      "FOLD: 0, EPOCH: 22, valid_loss: 0.01611354833261834\n",
      "FOLD: 0, EPOCH: 23, train_loss: 0.0171164981480087\n",
      "FOLD: 0, EPOCH: 23, valid_loss: 0.01608972003062566\n",
      "FOLD: 0, EPOCH: 24, train_loss: 0.01693740996021417\n",
      "FOLD: 0, EPOCH: 24, valid_loss: 0.01610297927012046\n",
      "FOLD: 1, EPOCH: 0, train_loss: 0.4670886448434284\n",
      "FOLD: 1, EPOCH: 0, valid_loss: 0.02410469690544738\n",
      "FOLD: 1, EPOCH: 1, train_loss: 0.023647251124343564\n",
      "FOLD: 1, EPOCH: 1, valid_loss: 0.01937762037333515\n",
      "FOLD: 1, EPOCH: 2, train_loss: 0.022089345248476153\n",
      "FOLD: 1, EPOCH: 2, valid_loss: 0.01804800931778219\n",
      "FOLD: 1, EPOCH: 3, train_loss: 0.020794824090215467\n",
      "FOLD: 1, EPOCH: 3, valid_loss: 0.017429115147226386\n",
      "FOLD: 1, EPOCH: 4, train_loss: 0.020431330175169054\n",
      "FOLD: 1, EPOCH: 4, valid_loss: 0.017303111756013498\n",
      "FOLD: 1, EPOCH: 5, train_loss: 0.020378478448237144\n",
      "FOLD: 1, EPOCH: 5, valid_loss: 0.017053231183025572\n",
      "FOLD: 1, EPOCH: 6, train_loss: 0.020323627988897985\n",
      "FOLD: 1, EPOCH: 6, valid_loss: 0.017345896715091333\n",
      "FOLD: 1, EPOCH: 7, train_loss: 0.020446054805671014\n",
      "FOLD: 1, EPOCH: 7, valid_loss: 0.01726025089414583\n",
      "FOLD: 1, EPOCH: 8, train_loss: 0.020436971538489866\n",
      "FOLD: 1, EPOCH: 8, valid_loss: 0.017132444410688348\n",
      "FOLD: 1, EPOCH: 9, train_loss: 0.020443292526948837\n",
      "FOLD: 1, EPOCH: 9, valid_loss: 0.01718142256140709\n",
      "FOLD: 1, EPOCH: 10, train_loss: 0.020341567971533345\n",
      "FOLD: 1, EPOCH: 10, valid_loss: 0.017148542838792007\n",
      "FOLD: 1, EPOCH: 11, train_loss: 0.020350890702778294\n",
      "FOLD: 1, EPOCH: 11, valid_loss: 0.0170384070629047\n",
      "FOLD: 1, EPOCH: 12, train_loss: 0.020294197648763657\n",
      "FOLD: 1, EPOCH: 12, valid_loss: 0.01693421115891801\n",
      "FOLD: 1, EPOCH: 13, train_loss: 0.020201687418645427\n",
      "FOLD: 1, EPOCH: 13, valid_loss: 0.01688427674687571\n",
      "FOLD: 1, EPOCH: 14, train_loss: 0.020045469076402724\n",
      "FOLD: 1, EPOCH: 14, valid_loss: 0.016756155372907717\n",
      "FOLD: 1, EPOCH: 15, train_loss: 0.019920354216329515\n",
      "FOLD: 1, EPOCH: 15, valid_loss: 0.01668016395221154\n",
      "FOLD: 1, EPOCH: 16, train_loss: 0.019766725984311874\n",
      "FOLD: 1, EPOCH: 16, valid_loss: 0.016545429929263063\n",
      "FOLD: 1, EPOCH: 17, train_loss: 0.019528142819481512\n",
      "FOLD: 1, EPOCH: 17, valid_loss: 0.016276393189198442\n",
      "FOLD: 1, EPOCH: 18, train_loss: 0.01924307968827986\n",
      "FOLD: 1, EPOCH: 18, valid_loss: 0.016161195002496243\n",
      "FOLD: 1, EPOCH: 19, train_loss: 0.018960822409679813\n",
      "FOLD: 1, EPOCH: 19, valid_loss: 0.016056874818685982\n",
      "FOLD: 1, EPOCH: 20, train_loss: 0.018599723645996664\n",
      "FOLD: 1, EPOCH: 20, valid_loss: 0.016015325000302658\n",
      "FOLD: 1, EPOCH: 21, train_loss: 0.018144920113826953\n",
      "FOLD: 1, EPOCH: 21, valid_loss: 0.015809104208730988\n",
      "FOLD: 1, EPOCH: 22, train_loss: 0.01778187379841843\n",
      "FOLD: 1, EPOCH: 22, valid_loss: 0.01580622409366899\n",
      "FOLD: 1, EPOCH: 23, train_loss: 0.017452465448408356\n",
      "FOLD: 1, EPOCH: 23, valid_loss: 0.015800028521981504\n",
      "FOLD: 1, EPOCH: 24, train_loss: 0.01731822705797611\n",
      "FOLD: 1, EPOCH: 24, valid_loss: 0.01574809243902564\n",
      "FOLD: 2, EPOCH: 0, train_loss: 0.46626967000624825\n",
      "FOLD: 2, EPOCH: 0, valid_loss: 0.02441686298698187\n",
      "FOLD: 2, EPOCH: 1, train_loss: 0.023741053561529807\n",
      "FOLD: 2, EPOCH: 1, valid_loss: 0.019329861013425723\n",
      "FOLD: 2, EPOCH: 2, train_loss: 0.0219084789676051\n",
      "FOLD: 2, EPOCH: 2, valid_loss: 0.017862524319854047\n",
      "FOLD: 2, EPOCH: 3, train_loss: 0.020729651169911507\n",
      "FOLD: 2, EPOCH: 3, valid_loss: 0.017661179105440777\n",
      "FOLD: 2, EPOCH: 4, train_loss: 0.02032028443871006\n",
      "FOLD: 2, EPOCH: 4, valid_loss: 0.017818863814075787\n",
      "FOLD: 2, EPOCH: 5, train_loss: 0.020293505742184578\n",
      "FOLD: 2, EPOCH: 5, valid_loss: 0.017516822657651372\n",
      "FOLD: 2, EPOCH: 6, train_loss: 0.02029879941574989\n",
      "FOLD: 2, EPOCH: 6, valid_loss: 0.017362431416081056\n",
      "FOLD: 2, EPOCH: 7, train_loss: 0.020320331028872922\n",
      "FOLD: 2, EPOCH: 7, valid_loss: 0.017454976681619883\n",
      "FOLD: 2, EPOCH: 8, train_loss: 0.020330711153726425\n",
      "FOLD: 2, EPOCH: 8, valid_loss: 0.017487604067557387\n",
      "FOLD: 2, EPOCH: 9, train_loss: 0.020346553479471514\n",
      "FOLD: 2, EPOCH: 9, valid_loss: 0.017307568134533033\n",
      "FOLD: 2, EPOCH: 10, train_loss: 0.02024474052652236\n",
      "FOLD: 2, EPOCH: 10, valid_loss: 0.017485793059070904\n",
      "FOLD: 2, EPOCH: 11, train_loss: 0.020245119676955286\n",
      "FOLD: 2, EPOCH: 11, valid_loss: 0.017420639594395954\n",
      "FOLD: 2, EPOCH: 12, train_loss: 0.020223044303636396\n",
      "FOLD: 2, EPOCH: 12, valid_loss: 0.017587637425296836\n",
      "FOLD: 2, EPOCH: 13, train_loss: 0.020098388795891115\n",
      "FOLD: 2, EPOCH: 13, valid_loss: 0.01728423886621992\n",
      "FOLD: 2, EPOCH: 14, train_loss: 0.019970846632795948\n",
      "FOLD: 2, EPOCH: 14, valid_loss: 0.017079525006314118\n",
      "FOLD: 2, EPOCH: 15, train_loss: 0.01986639395115837\n",
      "FOLD: 2, EPOCH: 15, valid_loss: 0.01693943375721574\n",
      "FOLD: 2, EPOCH: 16, train_loss: 0.019547057085700575\n",
      "FOLD: 2, EPOCH: 16, valid_loss: 0.01688455779933267\n",
      "FOLD: 2, EPOCH: 17, train_loss: 0.01942524900359492\n",
      "FOLD: 2, EPOCH: 17, valid_loss: 0.016726159180204075\n",
      "FOLD: 2, EPOCH: 18, train_loss: 0.019180879729890053\n",
      "FOLD: 2, EPOCH: 18, valid_loss: 0.016591073841684394\n",
      "FOLD: 2, EPOCH: 19, train_loss: 0.018842911528002833\n",
      "FOLD: 2, EPOCH: 19, valid_loss: 0.016563413923399314\n",
      "FOLD: 2, EPOCH: 20, train_loss: 0.018424998704464204\n",
      "FOLD: 2, EPOCH: 20, valid_loss: 0.01640394242066476\n",
      "FOLD: 2, EPOCH: 21, train_loss: 0.01800226265744817\n",
      "FOLD: 2, EPOCH: 21, valid_loss: 0.01632451473010911\n",
      "FOLD: 2, EPOCH: 22, train_loss: 0.017581730215780196\n",
      "FOLD: 2, EPOCH: 22, valid_loss: 0.01627573546850019\n",
      "FOLD: 2, EPOCH: 23, train_loss: 0.017232709137662765\n",
      "FOLD: 2, EPOCH: 23, valid_loss: 0.01623106851345963\n",
      "FOLD: 2, EPOCH: 24, train_loss: 0.017056648120764763\n",
      "FOLD: 2, EPOCH: 24, valid_loss: 0.01623851153999567\n",
      "FOLD: 3, EPOCH: 0, train_loss: 0.46610309475612255\n",
      "FOLD: 3, EPOCH: 0, valid_loss: 0.024228995562427573\n",
      "FOLD: 3, EPOCH: 1, train_loss: 0.023871077621175397\n",
      "FOLD: 3, EPOCH: 1, valid_loss: 0.01901898729718394\n",
      "FOLD: 3, EPOCH: 2, train_loss: 0.02187450334670082\n",
      "FOLD: 3, EPOCH: 2, valid_loss: 0.01833092798996303\n",
      "FOLD: 3, EPOCH: 3, train_loss: 0.020798071461819834\n",
      "FOLD: 3, EPOCH: 3, valid_loss: 0.017497623649736244\n",
      "FOLD: 3, EPOCH: 4, train_loss: 0.020426709733663066\n",
      "FOLD: 3, EPOCH: 4, valid_loss: 0.017167083867308166\n",
      "FOLD: 3, EPOCH: 5, train_loss: 0.020369218470108124\n",
      "FOLD: 3, EPOCH: 5, valid_loss: 0.017229029598335426\n",
      "FOLD: 3, EPOCH: 6, train_loss: 0.020326905685567085\n",
      "FOLD: 3, EPOCH: 6, valid_loss: 0.017098762043234374\n",
      "FOLD: 3, EPOCH: 7, train_loss: 0.020330179014032886\n",
      "FOLD: 3, EPOCH: 7, valid_loss: 0.01713756187301543\n",
      "FOLD: 3, EPOCH: 8, train_loss: 0.020383893001464107\n",
      "FOLD: 3, EPOCH: 8, valid_loss: 0.017040304994831484\n",
      "FOLD: 3, EPOCH: 9, train_loss: 0.020336805704620577\n",
      "FOLD: 3, EPOCH: 9, valid_loss: 0.018746710899803374\n",
      "FOLD: 3, EPOCH: 10, train_loss: 0.020366300678541584\n",
      "FOLD: 3, EPOCH: 10, valid_loss: 0.017690803338256147\n",
      "FOLD: 3, EPOCH: 11, train_loss: 0.020334953766676687\n",
      "FOLD: 3, EPOCH: 11, valid_loss: 0.016981497303479247\n",
      "FOLD: 3, EPOCH: 12, train_loss: 0.02022860332602455\n",
      "FOLD: 3, EPOCH: 12, valid_loss: 0.016929885631220207\n",
      "FOLD: 3, EPOCH: 13, train_loss: 0.020155077343506196\n",
      "FOLD: 3, EPOCH: 13, valid_loss: 0.017135479849659734\n",
      "FOLD: 3, EPOCH: 14, train_loss: 0.02003976214797266\n",
      "FOLD: 3, EPOCH: 14, valid_loss: 0.016857736019624606\n",
      "FOLD: 3, EPOCH: 15, train_loss: 0.019936006864713085\n",
      "FOLD: 3, EPOCH: 15, valid_loss: 0.01683402656474047\n",
      "FOLD: 3, EPOCH: 16, train_loss: 0.019718977526551294\n",
      "FOLD: 3, EPOCH: 16, valid_loss: 0.016580263204458687\n",
      "FOLD: 3, EPOCH: 17, train_loss: 0.019466970344224285\n",
      "FOLD: 3, EPOCH: 17, valid_loss: 0.01647155209340983\n",
      "FOLD: 3, EPOCH: 18, train_loss: 0.019224204219156694\n",
      "FOLD: 3, EPOCH: 18, valid_loss: 0.016200894489884377\n",
      "FOLD: 3, EPOCH: 19, train_loss: 0.018896361734838257\n",
      "FOLD: 3, EPOCH: 19, valid_loss: 0.016061685617185302\n",
      "FOLD: 3, EPOCH: 20, train_loss: 0.01853432201690251\n",
      "FOLD: 3, EPOCH: 20, valid_loss: 0.016046193842258718\n",
      "FOLD: 3, EPOCH: 21, train_loss: 0.018087055990772864\n",
      "FOLD: 3, EPOCH: 21, valid_loss: 0.015813654599090416\n",
      "FOLD: 3, EPOCH: 22, train_loss: 0.017727995369463196\n",
      "FOLD: 3, EPOCH: 22, valid_loss: 0.015799113652772374\n",
      "FOLD: 3, EPOCH: 23, train_loss: 0.017348087615063113\n",
      "FOLD: 3, EPOCH: 23, valid_loss: 0.015794929686105914\n",
      "FOLD: 3, EPOCH: 24, train_loss: 0.017215327732264994\n",
      "FOLD: 3, EPOCH: 24, valid_loss: 0.01576262003638678\n",
      "FOLD: 4, EPOCH: 0, train_loss: 0.4661750991618441\n",
      "FOLD: 4, EPOCH: 0, valid_loss: 0.023933163637088403\n",
      "FOLD: 4, EPOCH: 1, train_loss: 0.023696300255194785\n",
      "FOLD: 4, EPOCH: 1, valid_loss: 0.019083644780847762\n",
      "FOLD: 4, EPOCH: 2, train_loss: 0.021760025380119202\n",
      "FOLD: 4, EPOCH: 2, valid_loss: 0.018238533702161577\n",
      "FOLD: 4, EPOCH: 3, train_loss: 0.020621900236414324\n",
      "FOLD: 4, EPOCH: 3, valid_loss: 0.017574795625276037\n",
      "FOLD: 4, EPOCH: 4, train_loss: 0.02029298088483272\n",
      "FOLD: 4, EPOCH: 4, valid_loss: 0.017622401730881795\n",
      "FOLD: 4, EPOCH: 5, train_loss: 0.020271158807219997\n",
      "FOLD: 4, EPOCH: 5, valid_loss: 0.017869329390426476\n",
      "FOLD: 4, EPOCH: 6, train_loss: 0.02030682585412456\n",
      "FOLD: 4, EPOCH: 6, valid_loss: 0.017771328282025125\n",
      "FOLD: 4, EPOCH: 7, train_loss: 0.020301333201989052\n",
      "FOLD: 4, EPOCH: 7, valid_loss: 0.017608440274165735\n",
      "FOLD: 4, EPOCH: 8, train_loss: 0.02035637589231614\n",
      "FOLD: 4, EPOCH: 8, valid_loss: 0.017564460221264098\n",
      "FOLD: 4, EPOCH: 9, train_loss: 0.02033510682803969\n",
      "FOLD: 4, EPOCH: 9, valid_loss: 0.017252696264121268\n",
      "FOLD: 4, EPOCH: 10, train_loss: 0.020334268541586015\n",
      "FOLD: 4, EPOCH: 10, valid_loss: 0.017292913670341175\n",
      "FOLD: 4, EPOCH: 11, train_loss: 0.02023680777319016\n",
      "FOLD: 4, EPOCH: 11, valid_loss: 0.017649525983466044\n",
      "FOLD: 4, EPOCH: 12, train_loss: 0.02018019967982846\n",
      "FOLD: 4, EPOCH: 12, valid_loss: 0.01733681859655513\n",
      "FOLD: 4, EPOCH: 13, train_loss: 0.020092425543454386\n",
      "FOLD: 4, EPOCH: 13, valid_loss: 0.017378475206593674\n",
      "FOLD: 4, EPOCH: 14, train_loss: 0.019952543296160235\n",
      "FOLD: 4, EPOCH: 14, valid_loss: 0.01706751099684172\n",
      "FOLD: 4, EPOCH: 15, train_loss: 0.019826556802276643\n",
      "FOLD: 4, EPOCH: 15, valid_loss: 0.016912547250588734\n",
      "FOLD: 4, EPOCH: 16, train_loss: 0.019608135184934063\n",
      "FOLD: 4, EPOCH: 16, valid_loss: 0.016735595599230792\n",
      "FOLD: 4, EPOCH: 17, train_loss: 0.01939282136098031\n",
      "FOLD: 4, EPOCH: 17, valid_loss: 0.016681188355303474\n",
      "FOLD: 4, EPOCH: 18, train_loss: 0.019139321893453597\n",
      "FOLD: 4, EPOCH: 18, valid_loss: 0.016501424471951194\n",
      "FOLD: 4, EPOCH: 19, train_loss: 0.018766185641288756\n",
      "FOLD: 4, EPOCH: 19, valid_loss: 0.01647237708999051\n",
      "FOLD: 4, EPOCH: 20, train_loss: 0.018428113365605955\n",
      "FOLD: 4, EPOCH: 20, valid_loss: 0.016386597882956266\n",
      "FOLD: 4, EPOCH: 21, train_loss: 0.017943131551146508\n",
      "FOLD: 4, EPOCH: 21, valid_loss: 0.016306534150822297\n",
      "FOLD: 4, EPOCH: 22, train_loss: 0.017533852778855833\n",
      "FOLD: 4, EPOCH: 22, valid_loss: 0.016210970882740285\n",
      "FOLD: 4, EPOCH: 23, train_loss: 0.01721420144482005\n",
      "FOLD: 4, EPOCH: 23, valid_loss: 0.01617788394085235\n",
      "FOLD: 4, EPOCH: 24, train_loss: 0.017009426413043854\n",
      "FOLD: 4, EPOCH: 24, valid_loss: 0.016187326413475804\n",
      "FOLD: 5, EPOCH: 0, train_loss: 0.46618763429503285\n",
      "FOLD: 5, EPOCH: 0, valid_loss: 0.02549126951230897\n",
      "FOLD: 5, EPOCH: 1, train_loss: 0.023922688309704104\n",
      "FOLD: 5, EPOCH: 1, valid_loss: 0.019479091589649517\n",
      "FOLD: 5, EPOCH: 2, train_loss: 0.02194027063106337\n",
      "FOLD: 5, EPOCH: 2, valid_loss: 0.017828630179994635\n",
      "FOLD: 5, EPOCH: 3, train_loss: 0.020635272165940653\n",
      "FOLD: 5, EPOCH: 3, valid_loss: 0.01743939399926199\n",
      "FOLD: 5, EPOCH: 4, train_loss: 0.02029105283079609\n",
      "FOLD: 5, EPOCH: 4, valid_loss: 0.01739126816391945\n",
      "FOLD: 5, EPOCH: 5, train_loss: 0.020278707411020034\n",
      "FOLD: 5, EPOCH: 5, valid_loss: 0.0172672131512728\n",
      "FOLD: 5, EPOCH: 6, train_loss: 0.020263168648366005\n",
      "FOLD: 5, EPOCH: 6, valid_loss: 0.017313154828217294\n",
      "FOLD: 5, EPOCH: 7, train_loss: 0.020291415541883438\n",
      "FOLD: 5, EPOCH: 7, valid_loss: 0.01761880899882979\n",
      "FOLD: 5, EPOCH: 8, train_loss: 0.020332846237767127\n",
      "FOLD: 5, EPOCH: 8, valid_loss: 0.017212413147919707\n",
      "FOLD: 5, EPOCH: 9, train_loss: 0.02037255198003784\n",
      "FOLD: 5, EPOCH: 9, valid_loss: 0.017210594792332914\n",
      "FOLD: 5, EPOCH: 10, train_loss: 0.02032247954799283\n",
      "FOLD: 5, EPOCH: 10, valid_loss: 0.017621662157277267\n",
      "FOLD: 5, EPOCH: 11, train_loss: 0.02029130538144419\n",
      "FOLD: 5, EPOCH: 11, valid_loss: 0.017340257505161896\n",
      "FOLD: 5, EPOCH: 12, train_loss: 0.02020757639360043\n",
      "FOLD: 5, EPOCH: 12, valid_loss: 0.017311193514615297\n",
      "FOLD: 5, EPOCH: 13, train_loss: 0.02015289862550074\n",
      "FOLD: 5, EPOCH: 13, valid_loss: 0.017145327447603147\n",
      "FOLD: 5, EPOCH: 14, train_loss: 0.01996111196856345\n",
      "FOLD: 5, EPOCH: 14, valid_loss: 0.01690842645863692\n",
      "FOLD: 5, EPOCH: 15, train_loss: 0.019877797413256862\n",
      "FOLD: 5, EPOCH: 15, valid_loss: 0.0168136153370142\n",
      "FOLD: 5, EPOCH: 16, train_loss: 0.019646862029067933\n",
      "FOLD: 5, EPOCH: 16, valid_loss: 0.016867971358199913\n",
      "FOLD: 5, EPOCH: 17, train_loss: nan\n",
      "FOLD: 5, EPOCH: 17, valid_loss: nan\n",
      "FOLD: 5, EPOCH: 18, train_loss: nan\n",
      "FOLD: 5, EPOCH: 18, valid_loss: nan\n",
      "FOLD: 5, EPOCH: 19, train_loss: nan\n",
      "FOLD: 5, EPOCH: 19, valid_loss: nan\n",
      "FOLD: 5, EPOCH: 20, train_loss: nan\n",
      "FOLD: 5, EPOCH: 20, valid_loss: nan\n",
      "FOLD: 5, EPOCH: 21, train_loss: nan\n",
      "FOLD: 5, EPOCH: 21, valid_loss: nan\n",
      "FOLD: 5, EPOCH: 22, train_loss: nan\n",
      "FOLD: 5, EPOCH: 22, valid_loss: nan\n",
      "FOLD: 5, EPOCH: 23, train_loss: nan\n",
      "FOLD: 5, EPOCH: 23, valid_loss: nan\n",
      "FOLD: 5, EPOCH: 24, train_loss: nan\n",
      "FOLD: 5, EPOCH: 24, valid_loss: nan\n",
      "FOLD: 6, EPOCH: 0, train_loss: 0.4646961662677988\n",
      "FOLD: 6, EPOCH: 0, valid_loss: 0.02416239057977994\n",
      "FOLD: 6, EPOCH: 1, train_loss: 0.023964541261234592\n",
      "FOLD: 6, EPOCH: 1, valid_loss: 0.01885252958163619\n",
      "FOLD: 6, EPOCH: 2, train_loss: 0.021886153603273055\n",
      "FOLD: 6, EPOCH: 2, valid_loss: 0.017847910109493468\n",
      "FOLD: 6, EPOCH: 3, train_loss: 0.02066024277479418\n",
      "FOLD: 6, EPOCH: 3, valid_loss: 0.01744551920435495\n",
      "FOLD: 6, EPOCH: 4, train_loss: 0.020392282775813533\n",
      "FOLD: 6, EPOCH: 4, valid_loss: 0.017344409392939672\n",
      "FOLD: 6, EPOCH: 5, train_loss: 0.020289013006033436\n",
      "FOLD: 6, EPOCH: 5, valid_loss: 0.01717132619685597\n",
      "FOLD: 6, EPOCH: 6, train_loss: 0.020289174911956632\n",
      "FOLD: 6, EPOCH: 6, valid_loss: 0.01713996044256621\n",
      "FOLD: 6, EPOCH: 7, train_loss: 0.020287965887015865\n",
      "FOLD: 6, EPOCH: 7, valid_loss: 0.017601355185939208\n",
      "FOLD: 6, EPOCH: 8, train_loss: 0.020422751180106592\n",
      "FOLD: 6, EPOCH: 8, valid_loss: 0.017339323078178696\n",
      "FOLD: 6, EPOCH: 9, train_loss: 0.020436757009836937\n",
      "FOLD: 6, EPOCH: 9, valid_loss: 0.017348348214808438\n",
      "FOLD: 6, EPOCH: 10, train_loss: 0.020335851513570355\n",
      "FOLD: 6, EPOCH: 10, valid_loss: 0.017453889931655593\n",
      "FOLD: 6, EPOCH: 11, train_loss: 0.020330912788068093\n",
      "FOLD: 6, EPOCH: 11, valid_loss: 0.01713167591434386\n",
      "FOLD: 6, EPOCH: 12, train_loss: 0.020224620293705694\n",
      "FOLD: 6, EPOCH: 12, valid_loss: 0.017198064416233037\n",
      "FOLD: 6, EPOCH: 13, train_loss: 0.020093668720895245\n",
      "FOLD: 6, EPOCH: 13, valid_loss: 0.016980913571185537\n",
      "FOLD: 6, EPOCH: 14, train_loss: 0.020042665386872906\n",
      "FOLD: 6, EPOCH: 14, valid_loss: 0.016821393018795386\n",
      "FOLD: 6, EPOCH: 15, train_loss: 0.01985282766963205\n",
      "FOLD: 6, EPOCH: 15, valid_loss: 0.017032686569210555\n",
      "FOLD: 6, EPOCH: 16, train_loss: 0.019723756599330133\n",
      "FOLD: 6, EPOCH: 16, valid_loss: 0.016630138218816783\n",
      "FOLD: 6, EPOCH: 17, train_loss: 0.019470592335827888\n",
      "FOLD: 6, EPOCH: 17, valid_loss: 0.016509524391343195\n",
      "FOLD: 6, EPOCH: 18, train_loss: 0.019180328615250125\n",
      "FOLD: 6, EPOCH: 18, valid_loss: 0.016437673734294042\n",
      "FOLD: 6, EPOCH: 19, train_loss: 0.01886293067927322\n",
      "FOLD: 6, EPOCH: 19, valid_loss: 0.016280338271624513\n",
      "FOLD: 6, EPOCH: 20, train_loss: 0.01842445702922921\n",
      "FOLD: 6, EPOCH: 20, valid_loss: 0.01613383838492963\n",
      "FOLD: 6, EPOCH: 21, train_loss: 0.01804300592310967\n",
      "FOLD: 6, EPOCH: 21, valid_loss: 0.016107596560484834\n",
      "FOLD: 6, EPOCH: 22, train_loss: 0.017599515454663383\n",
      "FOLD: 6, EPOCH: 22, valid_loss: 0.015942549591677055\n",
      "FOLD: 6, EPOCH: 23, train_loss: 0.017305149486468684\n",
      "FOLD: 6, EPOCH: 23, valid_loss: 0.015996245563858084\n",
      "FOLD: 6, EPOCH: 24, train_loss: 0.017140861378321725\n",
      "FOLD: 6, EPOCH: 24, valid_loss: 0.01598608224756188\n",
      "FOLD: 7, EPOCH: 0, train_loss: 0.46647520181873153\n",
      "FOLD: 7, EPOCH: 0, valid_loss: 0.023444898426532745\n",
      "FOLD: 7, EPOCH: 1, train_loss: 0.023594144671674696\n",
      "FOLD: 7, EPOCH: 1, valid_loss: 0.019487453624606133\n",
      "FOLD: 7, EPOCH: 2, train_loss: 0.022153988468550868\n",
      "FOLD: 7, EPOCH: 2, valid_loss: 0.018486906981302634\n",
      "FOLD: 7, EPOCH: 3, train_loss: 0.020861733668754177\n",
      "FOLD: 7, EPOCH: 3, valid_loss: 0.01726063346076343\n",
      "FOLD: 7, EPOCH: 4, train_loss: 0.02049127359303736\n",
      "FOLD: 7, EPOCH: 4, valid_loss: 0.017600980432083208\n",
      "FOLD: 7, EPOCH: 5, train_loss: 0.02036594451675492\n",
      "FOLD: 7, EPOCH: 5, valid_loss: 0.017118127395709355\n",
      "FOLD: 7, EPOCH: 6, train_loss: 0.020312265438898917\n",
      "FOLD: 7, EPOCH: 6, valid_loss: 0.017318770651602082\n",
      "FOLD: 7, EPOCH: 7, train_loss: 0.020368913885566498\n",
      "FOLD: 7, EPOCH: 7, valid_loss: 0.017465734233458836\n",
      "FOLD: 7, EPOCH: 8, train_loss: 0.020362216895145755\n",
      "FOLD: 7, EPOCH: 8, valid_loss: 0.017399104570762977\n",
      "FOLD: 7, EPOCH: 9, train_loss: 0.020335843786597252\n",
      "FOLD: 7, EPOCH: 9, valid_loss: 0.017141287887675896\n",
      "FOLD: 7, EPOCH: 10, train_loss: 0.020382397381528732\n",
      "FOLD: 7, EPOCH: 10, valid_loss: 0.017199479767845735\n",
      "FOLD: 7, EPOCH: 11, train_loss: 0.02029335473573977\n",
      "FOLD: 7, EPOCH: 11, valid_loss: 0.017242708450390234\n",
      "FOLD: 7, EPOCH: 12, train_loss: 0.02029793746769428\n",
      "FOLD: 7, EPOCH: 12, valid_loss: 0.017030243140955765\n",
      "FOLD: 7, EPOCH: 13, train_loss: 0.020125742400846174\n",
      "FOLD: 7, EPOCH: 13, valid_loss: 0.016801916683713596\n",
      "FOLD: 7, EPOCH: 14, train_loss: 0.020005054507524735\n",
      "FOLD: 7, EPOCH: 14, valid_loss: 0.016903595429741673\n",
      "FOLD: 7, EPOCH: 15, train_loss: 0.01994541899090813\n",
      "FOLD: 7, EPOCH: 15, valid_loss: 0.016593364843477804\n",
      "FOLD: 7, EPOCH: 16, train_loss: 0.01969613625157264\n",
      "FOLD: 7, EPOCH: 16, valid_loss: 0.016636867334859237\n",
      "FOLD: 7, EPOCH: 17, train_loss: 0.019526643306016923\n",
      "FOLD: 7, EPOCH: 17, valid_loss: 0.016493182991527848\n",
      "FOLD: 7, EPOCH: 18, train_loss: 0.019280304579484847\n",
      "FOLD: 7, EPOCH: 18, valid_loss: 0.01622687378484342\n",
      "FOLD: 7, EPOCH: 19, train_loss: 0.018895142176939595\n",
      "FOLD: 7, EPOCH: 19, valid_loss: 0.01609496498066518\n",
      "FOLD: 7, EPOCH: 20, train_loss: 0.018547544267869764\n",
      "FOLD: 7, EPOCH: 20, valid_loss: 0.01604677193487684\n",
      "FOLD: 7, EPOCH: 21, train_loss: 0.018132019607770826\n",
      "FOLD: 7, EPOCH: 21, valid_loss: 0.01595569448545575\n",
      "FOLD: 7, EPOCH: 22, train_loss: 0.01772731068514047\n",
      "FOLD: 7, EPOCH: 22, valid_loss: 0.015839877900564008\n",
      "FOLD: 7, EPOCH: 23, train_loss: 0.017433817846880806\n",
      "FOLD: 7, EPOCH: 23, valid_loss: 0.015831246609903045\n",
      "FOLD: 7, EPOCH: 24, train_loss: 0.017223307135845384\n",
      "FOLD: 7, EPOCH: 24, valid_loss: 0.015812181298517518\n",
      "FOLD: 8, EPOCH: 0, train_loss: 0.4659820063580428\n",
      "FOLD: 8, EPOCH: 0, valid_loss: 0.024178832458953064\n",
      "FOLD: 8, EPOCH: 1, train_loss: 0.02394571896762617\n",
      "FOLD: 8, EPOCH: 1, valid_loss: 0.018560115144484572\n",
      "FOLD: 8, EPOCH: 2, train_loss: 0.021698412395292712\n",
      "FOLD: 8, EPOCH: 2, valid_loss: 0.01774241713186105\n",
      "FOLD: 8, EPOCH: 3, train_loss: 0.020736851495119835\n",
      "FOLD: 8, EPOCH: 3, valid_loss: 0.017355673739479646\n",
      "FOLD: 8, EPOCH: 4, train_loss: 0.02034292866385752\n",
      "FOLD: 8, EPOCH: 4, valid_loss: 0.017408084227806993\n",
      "FOLD: 8, EPOCH: 5, train_loss: 0.020356315037896557\n",
      "FOLD: 8, EPOCH: 5, valid_loss: 0.017290559597313404\n",
      "FOLD: 8, EPOCH: 6, train_loss: 0.020325391787675118\n",
      "FOLD: 8, EPOCH: 6, valid_loss: 0.017171637310336035\n",
      "FOLD: 8, EPOCH: 7, train_loss: 0.02041261933984295\n",
      "FOLD: 8, EPOCH: 7, valid_loss: 0.01724124187603593\n",
      "FOLD: 8, EPOCH: 8, train_loss: 0.02034989757643592\n",
      "FOLD: 8, EPOCH: 8, valid_loss: 0.017405243538733985\n",
      "FOLD: 8, EPOCH: 9, train_loss: 0.020431824797584163\n",
      "FOLD: 8, EPOCH: 9, valid_loss: 0.01711788856320911\n",
      "FOLD: 8, EPOCH: 10, train_loss: 0.02039405866976707\n",
      "FOLD: 8, EPOCH: 10, valid_loss: 0.017138038865394063\n",
      "FOLD: 8, EPOCH: 11, train_loss: 0.02031216352216659\n",
      "FOLD: 8, EPOCH: 11, valid_loss: 0.017139564371771283\n",
      "FOLD: 8, EPOCH: 12, train_loss: 0.020274896078532743\n",
      "FOLD: 8, EPOCH: 12, valid_loss: 0.016954868307544127\n",
      "FOLD: 8, EPOCH: 13, train_loss: 0.020170702208434383\n",
      "FOLD: 8, EPOCH: 13, valid_loss: 0.0169188614624242\n",
      "FOLD: 8, EPOCH: 14, train_loss: 0.020040463055333784\n",
      "FOLD: 8, EPOCH: 14, valid_loss: 0.016826061324940786\n",
      "FOLD: 8, EPOCH: 15, train_loss: 0.01994471422606899\n",
      "FOLD: 8, EPOCH: 15, valid_loss: 0.016700887586921453\n",
      "FOLD: 8, EPOCH: 16, train_loss: 0.019684453633043074\n",
      "FOLD: 8, EPOCH: 16, valid_loss: 0.016540764675786097\n",
      "FOLD: 8, EPOCH: 17, train_loss: 0.019485103711485863\n",
      "FOLD: 8, EPOCH: 17, valid_loss: 0.01653607613924477\n",
      "FOLD: 8, EPOCH: 18, train_loss: 0.0192535268803758\n",
      "FOLD: 8, EPOCH: 18, valid_loss: 0.016294373458044395\n",
      "FOLD: 8, EPOCH: 19, train_loss: 0.0188918074412692\n",
      "FOLD: 8, EPOCH: 19, valid_loss: 0.016228491285194952\n",
      "FOLD: 8, EPOCH: 20, train_loss: 0.018529923903124947\n",
      "FOLD: 8, EPOCH: 20, valid_loss: 0.016165466823925573\n",
      "FOLD: 8, EPOCH: 21, train_loss: 0.01807670821585963\n",
      "FOLD: 8, EPOCH: 21, valid_loss: 0.015989046388616163\n",
      "FOLD: 8, EPOCH: 22, train_loss: 0.01770212533733537\n",
      "FOLD: 8, EPOCH: 22, valid_loss: 0.015921253762725327\n",
      "FOLD: 8, EPOCH: 23, train_loss: 0.01735743517356534\n",
      "FOLD: 8, EPOCH: 23, valid_loss: 0.015915709495958354\n",
      "FOLD: 8, EPOCH: 24, train_loss: 0.01715458774518582\n",
      "FOLD: 8, EPOCH: 24, valid_loss: 0.015925846321301326\n",
      "FOLD: 9, EPOCH: 0, train_loss: 0.46559150628745555\n",
      "FOLD: 9, EPOCH: 0, valid_loss: 0.026842593629327085\n",
      "FOLD: 9, EPOCH: 1, train_loss: 0.023729062020297974\n",
      "FOLD: 9, EPOCH: 1, valid_loss: 0.018978157494631078\n",
      "FOLD: 9, EPOCH: 2, train_loss: 0.022009251278734977\n",
      "FOLD: 9, EPOCH: 2, valid_loss: 0.01771433579011096\n",
      "FOLD: 9, EPOCH: 3, train_loss: 0.02078668238414872\n",
      "FOLD: 9, EPOCH: 3, valid_loss: 0.018396461796429422\n",
      "FOLD: 9, EPOCH: 4, train_loss: 0.02040864730313901\n",
      "FOLD: 9, EPOCH: 4, valid_loss: 0.01798257190320227\n",
      "FOLD: 9, EPOCH: 5, train_loss: 0.02031336491627078\n",
      "FOLD: 9, EPOCH: 5, valid_loss: 0.017006276434080467\n",
      "FOLD: 9, EPOCH: 6, train_loss: 0.020267517864704133\n",
      "FOLD: 9, EPOCH: 6, valid_loss: 0.01750790462311771\n",
      "FOLD: 9, EPOCH: 7, train_loss: 0.020342327762515315\n",
      "FOLD: 9, EPOCH: 7, valid_loss: 0.01722218008298013\n",
      "FOLD: 9, EPOCH: 8, train_loss: 0.020354533027256688\n",
      "FOLD: 9, EPOCH: 8, valid_loss: 0.01725915151958664\n",
      "FOLD: 9, EPOCH: 9, train_loss: 0.020369703947536406\n",
      "FOLD: 9, EPOCH: 9, valid_loss: 0.017151063515080348\n",
      "FOLD: 9, EPOCH: 10, train_loss: 0.020299882609998026\n",
      "FOLD: 9, EPOCH: 10, valid_loss: 0.016996073950495984\n",
      "FOLD: 9, EPOCH: 11, train_loss: 0.02028578782994901\n",
      "FOLD: 9, EPOCH: 11, valid_loss: 0.017083211801946163\n",
      "FOLD: 9, EPOCH: 12, train_loss: 0.020206319420568403\n",
      "FOLD: 9, EPOCH: 12, valid_loss: 0.01696459504051341\n",
      "FOLD: 9, EPOCH: 13, train_loss: 0.020101292803883553\n",
      "FOLD: 9, EPOCH: 13, valid_loss: 0.01705505336738295\n",
      "FOLD: 9, EPOCH: 14, train_loss: 0.019992427167392548\n",
      "FOLD: 9, EPOCH: 14, valid_loss: 0.016835977271613147\n",
      "FOLD: 9, EPOCH: 15, train_loss: 0.01988149466774156\n",
      "FOLD: 9, EPOCH: 15, valid_loss: 0.016651712357997894\n",
      "FOLD: 9, EPOCH: 16, train_loss: 0.01968450303519926\n",
      "FOLD: 9, EPOCH: 16, valid_loss: 0.016557333163089223\n",
      "FOLD: 9, EPOCH: 17, train_loss: 0.019463843599923196\n",
      "FOLD: 9, EPOCH: 17, valid_loss: 0.016221133526414633\n",
      "FOLD: 9, EPOCH: 18, train_loss: 0.01915653685648595\n",
      "FOLD: 9, EPOCH: 18, valid_loss: 0.01625012492554055\n",
      "FOLD: 9, EPOCH: 19, train_loss: 0.018868033816256832\n",
      "FOLD: 9, EPOCH: 19, valid_loss: 0.016045043969319925\n",
      "FOLD: 9, EPOCH: 20, train_loss: 0.018444323077076864\n",
      "FOLD: 9, EPOCH: 20, valid_loss: 0.015947205583668418\n",
      "FOLD: 9, EPOCH: 21, train_loss: 0.018038148673311355\n",
      "FOLD: 9, EPOCH: 21, valid_loss: 0.01585270133283403\n",
      "FOLD: 9, EPOCH: 22, train_loss: 0.017631758400990117\n",
      "FOLD: 9, EPOCH: 22, valid_loss: 0.0158037758535809\n",
      "FOLD: 9, EPOCH: 23, train_loss: 0.01727252542491882\n",
      "FOLD: 9, EPOCH: 23, valid_loss: 0.015789968996412225\n",
      "FOLD: 9, EPOCH: 24, train_loss: 0.01712371810910202\n",
      "FOLD: 9, EPOCH: 24, valid_loss: 0.015803074981603358\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [0,1,42]#,2,5,6] #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:44:50.635962Z",
     "iopub.status.busy": "2020-11-29T07:44:50.634503Z",
     "iopub.status.idle": "2020-11-29T07:44:50.649459Z",
     "shell.execute_reply": "2020-11-29T07:44:50.648900Z"
    },
    "papermill": {
     "duration": 0.716765,
     "end_time": "2020-11-29T07:44:50.649566",
     "exception": false,
     "start_time": "2020-11-29T07:44:49.932801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_3 = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:44:52.403965Z",
     "iopub.status.busy": "2020-11-29T07:44:52.403032Z",
     "iopub.status.idle": "2020-11-29T07:44:52.504551Z",
     "shell.execute_reply": "2020-11-29T07:44:52.503471Z"
    },
    "papermill": {
     "duration": 1.177503,
     "end_time": "2020-11-29T07:44:52.504753",
     "exception": false,
     "start_time": "2020-11-29T07:44:51.327250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del data \n",
    "del folds \n",
    "del sample_submission \n",
    "del target \n",
    "del test \n",
    "del test2 \n",
    "del test_features \n",
    "del train \n",
    "del train2 \n",
    "del train_features \n",
    "del train_targets_nonscored \n",
    "del train_targets_scored\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "files__ = list(set(files__))\n",
    "for i in files__:\n",
    "    os.remove(\"/kaggle/working/\"+i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.770092,
     "end_time": "2020-11-29T07:44:54.045793",
     "exception": false,
     "start_time": "2020-11-29T07:44:53.275701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:44:55.457430Z",
     "iopub.status.busy": "2020-11-29T07:44:55.456182Z",
     "iopub.status.idle": "2020-11-29T07:45:00.856895Z",
     "shell.execute_reply": "2020-11-29T07:45:00.856320Z"
    },
    "papermill": {
     "duration": 6.106787,
     "end_time": "2020-11-29T07:45:00.857022",
     "exception": false,
     "start_time": "2020-11-29T07:44:54.750235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf\n",
    "from tensorflow.keras import layers,regularizers,Sequential,Model,backend,callbacks,optimizers,metrics,losses\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:45:02.331121Z",
     "iopub.status.busy": "2020-11-29T07:45:02.330051Z",
     "iopub.status.idle": "2020-11-29T07:45:07.171059Z",
     "shell.execute_reply": "2020-11-29T07:45:07.170506Z"
    },
    "papermill": {
     "duration": 5.621265,
     "end_time": "2020-11-29T07:45:07.171180",
     "exception": false,
     "start_time": "2020-11-29T07:45:01.549915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\n",
    "non_ctl_idx = train_features.loc[train_features['cp_type']!='ctl_vehicle'].index.to_list()\n",
    "train_features = train_features.drop(['sig_id','cp_type','cp_dose','cp_time'],axis=1)\n",
    "train_targets_scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_scored = train_targets_scored.drop('sig_id',axis=1)\n",
    "labels_train = train_targets_scored.values\n",
    "\n",
    "# Drop training data with ctl vehicle\n",
    "\n",
    "train_features = train_features.iloc[non_ctl_idx]\n",
    "labels_train = labels_train[non_ctl_idx]\n",
    "\n",
    "# Import test data\n",
    "\n",
    "test_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\n",
    "test_features = test_features.drop(['sig_id','cp_dose','cp_time'],axis=1)\n",
    "\n",
    "predictors = [\"g-0\",\"g-7\",\"g-8\",\"g-10\",\"g-13\",\"g-17\",\"g-20\",\"g-22\",\"g-24\",  \"g-26\",\"g-28\",\"g-29\",\"g-30\",\"g-31\",\"g-32\",\"g-34\",\"g-35\",\"g-36\", \n",
    "  \"g-37\",\"g-38\",\"g-39\",\"g-41\",\"g-46\",\"g-48\",\"g-50\",\"g-51\",\"g-52\" ,  \"g-55\",\"g-58\",\"g-59\",\"g-61\",\"g-62\",\"g-63\",\"g-65\",\"g-66\",\"g-67\" ,\n",
    "  \"g-68\",\"g-70\",\"g-72\",\"g-74\",\"g-75\",\"g-79\",\"g-83\",\"g-84\",\"g-85\" ,  \"g-86\",\"g-90\",\"g-91\",\"g-94\",\"g-95\",\"g-96\",\"g-97\",\"g-98\",\"g-100\",\n",
    "  \"g-102\",\"g-105\",\"g-106\",\"g-112\",\"g-113\",\"g-114\",\"g-116\",\"g-121\",\"g-123\",  \"g-126\",\"g-128\",\"g-131\",\"g-132\",\"g-134\",\"g-135\",\"g-138\",\"g-139\",\"g-140\",\n",
    "  \"g-142\",\"g-144\",\"g-145\",\"g-146\",\"g-147\",\"g-148\",\"g-152\",\"g-155\",\"g-157\",  \"g-158\",\"g-160\",\"g-163\",\"g-164\",\"g-165\",\"g-170\",\"g-173\",\"g-174\",\"g-175\",\n",
    "  \"g-177\",\"g-178\",\"g-181\",\"g-183\",\"g-185\",\"g-186\",\"g-189\",\"g-192\",\"g-194\", \"g-195\",\"g-196\",\"g-197\",\"g-199\",\"g-201\",\"g-202\",\"g-206\",\"g-208\",\"g-210\",\n",
    " \"g-213\",\"g-214\",\"g-215\",\"g-220\",\"g-226\",\"g-228\",\"g-229\",\"g-235\",\"g-238\", \"g-241\",\"g-242\",\"g-243\",\"g-244\",\"g-245\",\"g-248\",\"g-250\",\"g-251\",\"g-254\",\n",
    " \"g-257\",\"g-259\",\"g-261\",\"g-266\",\"g-270\",\"g-271\",\"g-272\",\"g-275\",\"g-278\", \"g-282\",\"g-287\",\"g-288\",\"g-289\",\"g-291\",\"g-293\",\"g-294\",\"g-297\",\"g-298\",\n",
    " \"g-301\",\"g-303\",\"g-304\",\"g-306\",\"g-308\",\"g-309\",\"g-310\",\"g-311\",\"g-314\", \"g-315\",\"g-316\",\"g-317\",\"g-320\",\"g-321\",\"g-322\",\"g-327\",\"g-328\",\"g-329\",\n",
    " \"g-332\",\"g-334\",\"g-335\",\"g-336\",\"g-337\",\"g-339\",\"g-342\",\"g-344\",\"g-349\", \"g-350\",\"g-351\",\"g-353\",\"g-354\",\"g-355\",\"g-357\",\"g-359\",\"g-360\",\"g-364\",\n",
    " \"g-365\",\"g-366\",\"g-367\",\"g-368\",\"g-369\",\"g-374\",\"g-375\",\"g-377\",\"g-379\", \"g-385\",\"g-386\",\"g-390\",\"g-392\",\"g-393\",\"g-400\",\"g-402\",\"g-406\",\"g-407\",\n",
    " \"g-409\",\"g-410\",\"g-411\",\"g-414\",\"g-417\",\"g-418\",\"g-421\",\"g-423\",\"g-424\", \"g-427\",\"g-429\",\"g-431\",\"g-432\",\"g-433\",\"g-434\",\"g-437\",\"g-439\",\"g-440\",\n",
    " \"g-443\",\"g-449\",\"g-458\",\"g-459\",\"g-460\",\"g-461\",\"g-464\",\"g-467\",\"g-468\", \"g-470\",\"g-473\",\"g-477\",\"g-478\",\"g-479\",\"g-484\",\"g-485\",\"g-486\",\"g-488\",\n",
    " \"g-489\",\"g-491\",\"g-494\",\"g-496\",\"g-498\",\"g-500\",\"g-503\",\"g-504\",\"g-506\", \"g-508\",\"g-509\",\"g-512\",\"g-522\",\"g-529\",\"g-531\",\"g-534\",\"g-539\",\"g-541\",\n",
    " \"g-546\",\"g-551\",\"g-553\",\"g-554\",\"g-559\",\"g-561\",\"g-562\",\"g-565\",\"g-568\", \"g-569\",\"g-574\",\"g-577\",\"g-578\",\"g-586\",\"g-588\",\"g-590\",\"g-594\",\"g-595\",\n",
    " \"g-596\",\"g-597\",\"g-599\",\"g-600\",\"g-603\",\"g-607\",\"g-615\",\"g-618\",\"g-619\", \"g-620\",\"g-625\",\"g-628\",\"g-629\",\"g-632\",\"g-634\",\"g-635\",\"g-636\",\"g-638\",\n",
    " \"g-639\",\"g-641\",\"g-643\",\"g-644\",\"g-645\",\"g-646\",\"g-647\",\"g-648\",\"g-663\", \"g-664\",\"g-665\",\"g-668\",\"g-669\",\"g-670\",\"g-671\",\"g-672\",\"g-673\",\"g-674\",\n",
    " \"g-677\",\"g-678\",\"g-680\",\"g-683\",\"g-689\",\"g-691\",\"g-693\",\"g-695\",\"g-701\", \"g-702\",\"g-703\",\"g-704\",\"g-705\",\"g-706\",\"g-708\",\"g-711\",\"g-712\",\"g-720\",\n",
    " \"g-721\",\"g-723\",\"g-724\",\"g-726\",\"g-728\",\"g-731\",\"g-733\",\"g-738\",\"g-739\", \"g-742\",\"g-743\",\"g-744\",\"g-745\",\"g-749\",\"g-750\",\"g-752\",\"g-760\",\"g-761\",\n",
    " \"g-764\",\"g-766\",\"g-768\",\"g-770\",\"g-771\",\"c-0\",\"c-1\",\"c-2\",\"c-3\"  , \"c-4\",\"c-5\",\"c-6\",\"c-7\",\"c-8\",\"c-9\",\"c-10\",\"c-11\",\"c-12\" ,\n",
    " \"c-13\",\"c-14\",\"c-15\",\"c-16\",\"c-17\",\"c-18\",\"c-19\",\"c-20\",\"c-21\",  \"c-22\",\"c-23\",\"c-24\",\"c-25\",\"c-26\",\"c-27\",\"c-28\",\"c-29\",\"c-30\" ,\n",
    " \"c-31\",\"c-32\",\"c-33\",\"c-34\",\"c-35\",\"c-36\",\"c-37\",\"c-38\",\"c-39\" , \"c-40\",\"c-41\",\"c-42\",\"c-43\",\"c-44\",\"c-45\",\"c-46\",\"c-47\",\"c-48\" ,\n",
    " \"c-49\",\"c-50\",\"c-51\",\"c-52\",\"c-53\",\"c-54\",\"c-55\",\"c-56\",\"c-57\" , \"c-58\",\"c-59\",\"c-60\",\"c-61\",\"c-62\",\"c-63\",\"c-64\",\"c-65\",\"c-66\" ,\n",
    " \"c-67\",\"c-68\",\"c-69\",\"c-70\",\"c-71\",\"c-72\",\"c-73\",\"c-74\",\"c-75\" , \"c-76\",\"c-77\",\"c-78\",\"c-79\",\"c-80\",\"c-81\",\"c-82\",\"c-83\",\"c-84\" ,\n",
    " \"c-85\",\"c-86\",\"c-87\",\"c-88\",\"c-89\",\"c-90\",\"c-91\",\"c-92\",\"c-93\" , \"c-94\",\"c-95\",\"c-96\",\"c-97\",\"c-98\",\"c-99\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:45:08.539737Z",
     "iopub.status.busy": "2020-11-29T07:45:08.538359Z",
     "iopub.status.idle": "2020-11-29T07:45:08.540375Z",
     "shell.execute_reply": "2020-11-29T07:45:08.540878Z"
    },
    "papermill": {
     "duration": 0.699079,
     "end_time": "2020-11-29T07:45:08.541003",
     "exception": false,
     "start_time": "2020-11-29T07:45:07.841924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create g-mean, c-mean, genes_pca (2 components), cells_pca (all components)\n",
    "\n",
    "cs = train_features.columns.str.contains('c-')\n",
    "gs = train_features.columns.str.contains('g-')\n",
    "\n",
    "def preprocessor(train,test):\n",
    "    \n",
    "    # PCA\n",
    "    \n",
    "    n_gs = 2 # No of PCA comps to include\n",
    "    n_cs = 100 # No of PCA comps to include\n",
    "    \n",
    "    pca_cs = PCA(n_components = n_cs)\n",
    "    pca_gs = PCA(n_components = n_gs)\n",
    "\n",
    "    train_pca_gs = pca_gs.fit_transform(train[:,gs])\n",
    "    train_pca_cs = pca_cs.fit_transform(train[:,cs])\n",
    "    test_pca_gs = pca_gs.transform(test[:,gs])\n",
    "    test_pca_cs = pca_cs.transform(test[:,cs])\n",
    "    \n",
    "    # c-mean, g-mean\n",
    "    \n",
    "    train_c_mean = train[:,cs].mean(axis=1)\n",
    "    test_c_mean = test[:,cs].mean(axis=1)\n",
    "    train_g_mean = train[:,gs].mean(axis=1)\n",
    "    test_g_mean = test[:,gs].mean(axis=1)\n",
    "    \n",
    "    # Append Features\n",
    "    \n",
    "    train = np.concatenate((train,train_pca_gs,train_pca_cs,train_c_mean[:,np.newaxis]\n",
    "                            ,train_g_mean[:,np.newaxis]),axis=1)\n",
    "    test = np.concatenate((test,test_pca_gs,test_pca_cs,test_c_mean[:,np.newaxis],\n",
    "                           test_g_mean[:,np.newaxis]),axis=1)\n",
    "    \n",
    "    # Scaler for numerical values\n",
    "\n",
    "    # Scale train data\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    train = scaler.fit_transform(train)\n",
    "\n",
    "    # Scale Test data\n",
    "    test = scaler.transform(test)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:45:09.892192Z",
     "iopub.status.busy": "2020-11-29T07:45:09.890272Z",
     "iopub.status.idle": "2020-11-29T07:45:09.892877Z",
     "shell.execute_reply": "2020-11-29T07:45:09.893348Z"
    },
    "papermill": {
     "duration": 0.680996,
     "end_time": "2020-11-29T07:45:09.893471",
     "exception": false,
     "start_time": "2020-11-29T07:45:09.212475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_labels = train_targets_scored.shape[1]\n",
    "n_train = train_features.shape[0]\n",
    "n_test = test_features.shape[0]\n",
    "\n",
    "\n",
    "# Prediction Clipping Thresholds\n",
    "\n",
    "p_min = 0.0005\n",
    "p_max = 0.9995\n",
    "\n",
    "# OOF Evaluation Metric with clipping and no label smoothing\n",
    "\n",
    "def logloss(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred,p_min,p_max)\n",
    "    return -backend.mean(y_true*backend.log(y_pred) + (1-y_true)*backend.log(1-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:45:11.261457Z",
     "iopub.status.busy": "2020-11-29T07:45:11.260444Z",
     "iopub.status.idle": "2020-11-29T07:45:11.263485Z",
     "shell.execute_reply": "2020-11-29T07:45:11.262999Z"
    },
    "papermill": {
     "duration": 0.690271,
     "end_time": "2020-11-29T07:45:11.263591",
     "exception": false,
     "start_time": "2020-11-29T07:45:10.573320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(n_features, n_features_2, n_labels, label_smoothing = 0.0005):    \n",
    "    input_1 = layers.Input(shape = (n_features,), name = 'Input1')\n",
    "    input_2 = layers.Input(shape = (n_features_2,), name = 'Input2')\n",
    "\n",
    "    head_1 = Sequential([\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(512, activation=\"elu\"), \n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(256, activation = \"elu\")\n",
    "        ],name='Head1') \n",
    "\n",
    "    input_3 = head_1(input_1)\n",
    "    input_3_concat = layers.Concatenate()([input_2, input_3])\n",
    "\n",
    "    head_2 = Sequential([\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(512, \"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(512, \"elu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(256, \"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(256, \"elu\")\n",
    "        ],name='Head2')\n",
    "\n",
    "    input_4 = head_2(input_3_concat)\n",
    "    input_4_avg = layers.Average()([input_3, input_4]) \n",
    "\n",
    "    head_3 = Sequential([\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(256, kernel_initializer='lecun_normal', activation='selu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(n_labels, kernel_initializer='lecun_normal', activation='selu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(n_labels, activation=\"sigmoid\")\n",
    "        ],name='Head3')\n",
    "\n",
    "    output = head_3(input_4_avg)\n",
    "\n",
    "\n",
    "    model = Model(inputs = [input_1, input_2], outputs = output)\n",
    "    model.compile(optimizer='adam', loss=losses.BinaryCrossentropy(label_smoothing=label_smoothing), metrics=logloss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T07:45:12.657384Z",
     "iopub.status.busy": "2020-11-29T07:45:12.646664Z",
     "iopub.status.idle": "2020-11-29T08:01:08.315575Z",
     "shell.execute_reply": "2020-11-29T08:01:08.314216Z"
    },
    "papermill": {
     "duration": 956.378249,
     "end_time": "2020-11-29T08:01:08.315728",
     "exception": false,
     "start_time": "2020-11-29T07:45:11.937479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate Seeds\n",
    "\n",
    "n_seeds = 2 ############################################################ 6\n",
    "np.random.seed(1)\n",
    "seeds = np.random.randint(0,100,size=n_seeds)\n",
    "\n",
    "# Training Loop\n",
    "\n",
    "n_folds = 16 ############################################################ 10\n",
    "y_pred = np.zeros((n_test,n_labels))\n",
    "oof = tf.constant(0.0)\n",
    "hists = []\n",
    "for seed in seeds:\n",
    "    fold = 0\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=seed)\n",
    "    for train, test in kf.split(train_features):\n",
    "        X_train, X_test = preprocessor(train_features.iloc[train].values,\n",
    "                                       train_features.iloc[test].values)\n",
    "        _,data_test = preprocessor(train_features.iloc[train].values,\n",
    "                                   test_features.drop('cp_type',axis=1).values)\n",
    "        X_train_2 = train_features.iloc[train][predictors].values\n",
    "        X_test_2 = train_features.iloc[test][predictors].values\n",
    "        data_test_2 = test_features[predictors].values\n",
    "        y_train = labels_train[train]\n",
    "        y_test = labels_train[test]\n",
    "        n_features = X_train.shape[1]\n",
    "        n_features_2 = X_train_2.shape[1]\n",
    "\n",
    "        model = build_model(n_features, n_features_2, n_labels)\n",
    "        \n",
    "        reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_logloss', factor=0.1, patience=2, mode='min', min_lr=1E-5)\n",
    "        early_stopping = callbacks.EarlyStopping(monitor='val_logloss', min_delta=1E-5, patience=10, mode='min',restore_best_weights=True)\n",
    "\n",
    "        hist = model.fit([X_train,X_train_2],y_train, batch_size=128, epochs=192,verbose=0,validation_data = ([X_test,X_test_2],y_test),\n",
    "                         callbacks=[reduce_lr, early_stopping])\n",
    "        hists.append(hist)\n",
    "        \n",
    "        # Save Model\n",
    "#         model.save('TwoHeads_seed_'+str(seed)+'_fold_'+str(fold))\n",
    "\n",
    "        # OOF Score\n",
    "        y_val = model.predict([X_test,X_test_2])\n",
    "        oof += logloss(tf.constant(y_test,dtype=tf.float32),tf.constant(y_val,dtype=tf.float32))/(n_folds*n_seeds)\n",
    "\n",
    "        # Run prediction\n",
    "        y_pred += model.predict([data_test,data_test_2])/(n_folds*n_seeds)\n",
    "\n",
    "        fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:01:09.671696Z",
     "iopub.status.busy": "2020-11-29T08:01:09.670878Z",
     "iopub.status.idle": "2020-11-29T08:01:10.134967Z",
     "shell.execute_reply": "2020-11-29T08:01:10.136563Z"
    },
    "papermill": {
     "duration": 1.127384,
     "end_time": "2020-11-29T08:01:10.136790",
     "exception": false,
     "start_time": "2020-11-29T08:01:09.009406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate submission file, Clip Predictions\n",
    "\n",
    "sub_5 = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\n",
    "sub_5.iloc[:,1:] = np.clip(y_pred,p_min,p_max)\n",
    "\n",
    "# Set ctl_vehicle to 0\n",
    "sub_5.iloc[test_features['cp_type'] == 'ctl_vehicle',1:] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:01:11.658932Z",
     "iopub.status.busy": "2020-11-29T08:01:11.657160Z",
     "iopub.status.idle": "2020-11-29T08:01:11.659581Z",
     "shell.execute_reply": "2020-11-29T08:01:11.660063Z"
    },
    "papermill": {
     "duration": 0.666479,
     "end_time": "2020-11-29T08:01:11.660186",
     "exception": false,
     "start_time": "2020-11-29T08:01:10.993707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del test_features\n",
    "del train_features\n",
    "del train_targets_scored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.658242,
     "end_time": "2020-11-29T08:01:12.998041",
     "exception": false,
     "start_time": "2020-11-29T08:01:12.339799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# M6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:01:14.317042Z",
     "iopub.status.busy": "2020-11-29T08:01:14.316272Z",
     "iopub.status.idle": "2020-11-29T08:01:14.321114Z",
     "shell.execute_reply": "2020-11-29T08:01:14.320415Z"
    },
    "papermill": {
     "duration": 0.666745,
     "end_time": "2020-11-29T08:01:14.321221",
     "exception": false,
     "start_time": "2020-11-29T08:01:13.654476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:01:15.652862Z",
     "iopub.status.busy": "2020-11-29T08:01:15.651041Z",
     "iopub.status.idle": "2020-11-29T08:01:15.653505Z",
     "shell.execute_reply": "2020-11-29T08:01:15.653984Z"
    },
    "papermill": {
     "duration": 0.666265,
     "end_time": "2020-11-29T08:01:15.654117",
     "exception": false,
     "start_time": "2020-11-29T08:01:14.987852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "data_path = \"../input/lish-moa/\"\n",
    "no_ctl = True\n",
    "scale = \"rankgauss\"\n",
    "variance_threshould = 0.7\n",
    "decompo = \"PCA\"\n",
    "ncompo_genes = 80\n",
    "ncompo_cells = 10\n",
    "encoding = \"dummy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:01:16.976532Z",
     "iopub.status.busy": "2020-11-29T08:01:16.975702Z",
     "iopub.status.idle": "2020-11-29T08:01:21.014524Z",
     "shell.execute_reply": "2020-11-29T08:01:21.013318Z"
    },
    "papermill": {
     "duration": 4.703109,
     "end_time": "2020-11-29T08:01:21.014679",
     "exception": false,
     "start_time": "2020-11-29T08:01:16.311570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path + \"train_features.csv\")\n",
    "targets = pd.read_csv(data_path + \"train_targets_scored.csv\")\n",
    "test = pd.read_csv(data_path + \"test_features.csv\")\n",
    "submission = pd.read_csv(data_path + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:01:22.615121Z",
     "iopub.status.busy": "2020-11-29T08:01:22.614010Z",
     "iopub.status.idle": "2020-11-29T08:01:22.689549Z",
     "shell.execute_reply": "2020-11-29T08:01:22.688996Z"
    },
    "papermill": {
     "duration": 0.760874,
     "end_time": "2020-11-29T08:01:22.689688",
     "exception": false,
     "start_time": "2020-11-29T08:01:21.928814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_ctl\n"
     ]
    }
   ],
   "source": [
    "if no_ctl:\n",
    "    print( \"not_ctl\")\n",
    "    train = train[train[\"cp_type\"] != \"ctl_vehicle\"]\n",
    "    test = test[test[\"cp_type\"] != \"ctl_vehicle\"]\n",
    "    targets = targets.iloc[train.index]\n",
    "    train.reset_index(drop = True, inplace = True)\n",
    "    test.reset_index(drop = True, inplace = True)\n",
    "    targets.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.658377,
     "end_time": "2020-11-29T08:01:24.015472",
     "exception": false,
     "start_time": "2020-11-29T08:01:23.357095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Rank Gauss Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:01:25.336399Z",
     "iopub.status.busy": "2020-11-29T08:01:25.335255Z",
     "iopub.status.idle": "2020-11-29T08:01:25.735066Z",
     "shell.execute_reply": "2020-11-29T08:01:25.734060Z"
    },
    "papermill": {
     "duration": 1.065056,
     "end_time": "2020-11-29T08:01:25.735186",
     "exception": false,
     "start_time": "2020-11-29T08:01:24.670130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_all = pd.concat([train, test], ignore_index = True)\n",
    "cols_numeric = [feat for feat in list(data_all.columns) if feat not in [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]]\n",
    "mask = (data_all[cols_numeric].var() >= variance_threshould).values\n",
    "tmp = data_all[cols_numeric].loc[:, mask]\n",
    "data_all = pd.concat([data_all[[\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]], tmp], axis = 1)\n",
    "cols_numeric = [feat for feat in list(data_all.columns) if feat not in [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:01:27.062168Z",
     "iopub.status.busy": "2020-11-29T08:01:27.061161Z",
     "iopub.status.idle": "2020-11-29T08:01:42.510072Z",
     "shell.execute_reply": "2020-11-29T08:01:42.509441Z"
    },
    "papermill": {
     "duration": 16.119718,
     "end_time": "2020-11-29T08:01:42.510189",
     "exception": false,
     "start_time": "2020-11-29T08:01:26.390471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank Gauss\n"
     ]
    }
   ],
   "source": [
    "def scale_minmax(col):\n",
    "    return (col - col.min()) / (col.max() - col.min())\n",
    "\n",
    "def scale_norm(col):\n",
    "    return (col - col.mean()) / col.std()\n",
    "\n",
    "if scale == \"rankgauss\":\n",
    "    ### Rank Gauss ###\n",
    "    print( \"Rank Gauss\")\n",
    "    scaler = GaussRankScaler()\n",
    "    data_all[cols_numeric] = scaler.fit_transform(data_all[cols_numeric])\n",
    "    \n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:01:44.089550Z",
     "iopub.status.busy": "2020-11-29T08:01:44.088116Z",
     "iopub.status.idle": "2020-11-29T08:01:45.814532Z",
     "shell.execute_reply": "2020-11-29T08:01:45.813999Z"
    },
    "papermill": {
     "duration": 2.57994,
     "end_time": "2020-11-29T08:01:45.814669",
     "exception": false,
     "start_time": "2020-11-29T08:01:43.234729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "if decompo == \"PCA\":\n",
    "    print(\"PCA\")\n",
    "    GENES = [col for col in data_all.columns if col.startswith(\"g-\")]\n",
    "    CELLS = [col for col in data_all.columns if col.startswith(\"c-\")]\n",
    "    \n",
    "    pca_genes = PCA(n_components = ncompo_genes,\n",
    "                    random_state = seed).fit_transform(data_all[GENES])\n",
    "    pca_cells = PCA(n_components = ncompo_cells,\n",
    "                    random_state = seed).fit_transform(data_all[CELLS])\n",
    "    \n",
    "    pca_genes = pd.DataFrame(pca_genes, columns = [f\"pca_g-{i}\" for i in range(ncompo_genes)])\n",
    "    pca_cells = pd.DataFrame(pca_cells, columns = [f\"pca_c-{i}\" for i in range(ncompo_cells)])\n",
    "    data_all = pd.concat([data_all, pca_genes, pca_cells], axis = 1)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:01:47.142816Z",
     "iopub.status.busy": "2020-11-29T08:01:47.141539Z",
     "iopub.status.idle": "2020-11-29T08:01:52.587102Z",
     "shell.execute_reply": "2020-11-29T08:01:52.586579Z"
    },
    "papermill": {
     "duration": 6.11389,
     "end_time": "2020-11-29T08:01:52.587214",
     "exception": false,
     "start_time": "2020-11-29T08:01:46.473324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:05<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# Encoding\n",
    "if encoding == \"lb\":\n",
    "    print(\"Label Encoding\")\n",
    "    for feat in [\"cp_time\", \"cp_dose\"]:\n",
    "        data_all[feat] = LabelEncoder().fit_transform(data_all[feat])\n",
    "elif encoding == \"dummy\":\n",
    "    print(\"One-Hot\")\n",
    "    data_all = pd.get_dummies(data_all, columns = [\"cp_time\", \"cp_dose\"])\n",
    "\n",
    "GENES = [col for col in data_all.columns if col.startswith(\"g-\")]\n",
    "CELLS = [col for col in data_all.columns if col.startswith(\"c-\")]\n",
    "\n",
    "for stats in tqdm.tqdm([\"sum\", \"mean\", \"std\", \"kurt\", \"skew\"]):\n",
    "    data_all[\"g_\" + stats] = getattr(data_all[GENES], stats)(axis = 1)\n",
    "    data_all[\"c_\" + stats] = getattr(data_all[CELLS], stats)(axis = 1)    \n",
    "    data_all[\"gc_\" + stats] = getattr(data_all[GENES + CELLS], stats)(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:01:54.038152Z",
     "iopub.status.busy": "2020-11-29T08:01:54.037227Z",
     "iopub.status.idle": "2020-11-29T08:01:54.275305Z",
     "shell.execute_reply": "2020-11-29T08:01:54.276680Z"
    },
    "papermill": {
     "duration": 0.981211,
     "end_time": "2020-11-29T08:01:54.276883",
     "exception": false,
     "start_time": "2020-11-29T08:01:53.295672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df and test_df\n",
    "features_to_drop = [\"sig_id\", \"cp_type\"]\n",
    "data_all.drop(features_to_drop, axis = 1, inplace = True)\n",
    "try:\n",
    "    targets.drop(\"sig_id\", axis = 1, inplace = True)\n",
    "except:\n",
    "    pass\n",
    "train_df = data_all[: train.shape[0]]\n",
    "train_df.reset_index(drop = True, inplace = True)\n",
    "# The following line it's a bad practice in my opinion, targets on train set\n",
    "#train_df = pd.concat([train_df, targets], axis = 1)\n",
    "test_df = data_all[train_df.shape[0]: ]\n",
    "test_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:01:56.126738Z",
     "iopub.status.busy": "2020-11-29T08:01:56.125027Z",
     "iopub.status.idle": "2020-11-29T08:01:56.135081Z",
     "shell.execute_reply": "2020-11-29T08:01:56.134508Z"
    },
    "papermill": {
     "duration": 0.83788,
     "end_time": "2020-11-29T08:01:56.135183",
     "exception": false,
     "start_time": "2020-11-29T08:01:55.297303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape: (3624, 947)\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.values\n",
    "print(f\"X_test.shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.674431,
     "end_time": "2020-11-29T08:01:57.486552",
     "exception": false,
     "start_time": "2020-11-29T08:01:56.812121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:01:58.871812Z",
     "iopub.status.busy": "2020-11-29T08:01:58.871152Z",
     "iopub.status.idle": "2020-11-29T08:01:58.875646Z",
     "shell.execute_reply": "2020-11-29T08:01:58.875138Z"
    },
    "papermill": {
     "duration": 0.675623,
     "end_time": "2020-11-29T08:01:58.875749",
     "exception": false,
     "start_time": "2020-11-29T08:01:58.200126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_EPOCH = 200\n",
    "tabnet_params = dict(\n",
    "    n_d = 32,\n",
    "    n_a = 32,\n",
    "    n_steps = 1,\n",
    "    gamma = 1.3,\n",
    "    lambda_sparse = 0,\n",
    "    optimizer_fn = optim.Adam,\n",
    "    optimizer_params = dict(lr = 2e-2, weight_decay = 1e-5),\n",
    "    mask_type = \"entmax\",\n",
    "    scheduler_params = dict(\n",
    "        mode = \"min\", patience = 5, min_lr = 1e-5, factor = 0.9),\n",
    "    scheduler_fn = ReduceLROnPlateau,\n",
    "    seed = seed,\n",
    "    verbose = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:02:00.279241Z",
     "iopub.status.busy": "2020-11-29T08:02:00.278520Z",
     "iopub.status.idle": "2020-11-29T08:02:00.282500Z",
     "shell.execute_reply": "2020-11-29T08:02:00.282025Z"
    },
    "papermill": {
     "duration": 0.688634,
     "end_time": "2020-11-29T08:02:00.282625",
     "exception": false,
     "start_time": "2020-11-29T08:01:59.593991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogitsLogLoss(Metric):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        aux = (1 - y_true) * np.log(1 - logits + 1e-15) + y_true * np.log(logits + 1e-15)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.667505,
     "end_time": "2020-11-29T08:02:01.616409",
     "exception": false,
     "start_time": "2020-11-29T08:02:00.948904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:02:02.986173Z",
     "iopub.status.busy": "2020-11-29T08:02:02.985178Z",
     "iopub.status.idle": "2020-11-29T08:50:25.138932Z",
     "shell.execute_reply": "2020-11-29T08:50:25.138360Z"
    },
    "papermill": {
     "duration": 2902.843659,
     "end_time": "2020-11-29T08:50:25.139075",
     "exception": false,
     "start_time": "2020-11-29T08:02:02.295416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLDS:  1\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.28992 | val_logits_ll: 0.02772 |  0:00:02s\n",
      "epoch 10 | loss: 0.01872 | val_logits_ll: 0.01846 |  0:00:19s\n",
      "epoch 20 | loss: 0.0175  | val_logits_ll: 0.02018 |  0:00:38s\n",
      "epoch 30 | loss: 0.01704 | val_logits_ll: 0.01711 |  0:00:57s\n",
      "epoch 40 | loss: 0.01666 | val_logits_ll: 0.01697 |  0:01:14s\n",
      "epoch 50 | loss: 0.0164  | val_logits_ll: 0.01654 |  0:01:33s\n",
      "epoch 60 | loss: 0.01627 | val_logits_ll: 0.01675 |  0:01:52s\n",
      "epoch 70 | loss: 0.01605 | val_logits_ll: 0.01652 |  0:02:09s\n",
      "epoch 80 | loss: 0.01591 | val_logits_ll: 0.0166  |  0:02:28s\n",
      "epoch 90 | loss: 0.01565 | val_logits_ll: 0.01658 |  0:02:46s\n",
      "epoch 100| loss: 0.01553 | val_logits_ll: 0.01643 |  0:03:04s\n",
      "epoch 110| loss: 0.0154  | val_logits_ll: 0.01637 |  0:03:23s\n",
      "epoch 120| loss: 0.01512 | val_logits_ll: 0.01635 |  0:03:40s\n",
      "\n",
      "Early stopping occured at epoch 128 with best_epoch = 108 and best_val_logits_ll = 0.01626\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n",
      "FOLDS:  2\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.28832 | val_logits_ll: 0.02773 |  0:00:01s\n",
      "epoch 10 | loss: 0.01845 | val_logits_ll: 0.01879 |  0:00:20s\n",
      "epoch 20 | loss: 0.01743 | val_logits_ll: 0.01765 |  0:00:38s\n",
      "epoch 30 | loss: 0.01692 | val_logits_ll: 0.01715 |  0:00:57s\n",
      "epoch 40 | loss: 0.0167  | val_logits_ll: 0.01686 |  0:01:15s\n",
      "epoch 50 | loss: 0.01637 | val_logits_ll: 0.01668 |  0:01:33s\n",
      "epoch 60 | loss: 0.01606 | val_logits_ll: 0.01667 |  0:01:52s\n",
      "epoch 70 | loss: 0.01607 | val_logits_ll: 0.01698 |  0:02:10s\n",
      "epoch 80 | loss: 0.01572 | val_logits_ll: 0.01684 |  0:02:28s\n",
      "epoch 90 | loss: 0.01539 | val_logits_ll: 0.01681 |  0:02:46s\n",
      "\n",
      "Early stopping occured at epoch 95 with best_epoch = 75 and best_val_logits_ll = 0.01652\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n",
      "FOLDS:  3\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.28708 | val_logits_ll: 0.02763 |  0:00:01s\n",
      "epoch 10 | loss: 0.01879 | val_logits_ll: 0.01897 |  0:00:19s\n",
      "epoch 20 | loss: 0.01737 | val_logits_ll: 0.02155 |  0:00:37s\n",
      "epoch 30 | loss: 0.01698 | val_logits_ll: 0.01762 |  0:00:56s\n",
      "epoch 40 | loss: 0.01654 | val_logits_ll: 0.01701 |  0:01:13s\n",
      "epoch 50 | loss: 0.01645 | val_logits_ll: 0.01709 |  0:01:32s\n",
      "epoch 60 | loss: 0.01613 | val_logits_ll: 0.01679 |  0:01:50s\n",
      "epoch 70 | loss: 0.01592 | val_logits_ll: 0.01687 |  0:02:08s\n",
      "epoch 80 | loss: 0.0157  | val_logits_ll: 0.01664 |  0:02:27s\n",
      "epoch 90 | loss: 0.01547 | val_logits_ll: 0.0168  |  0:02:45s\n",
      "epoch 100| loss: 0.01511 | val_logits_ll: 0.01669 |  0:03:04s\n",
      "epoch 110| loss: 0.01499 | val_logits_ll: 0.01667 |  0:03:22s\n",
      "\n",
      "Early stopping occured at epoch 113 with best_epoch = 93 and best_val_logits_ll = 0.0166\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n",
      "FOLDS:  4\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29119 | val_logits_ll: 0.0281  |  0:00:01s\n",
      "epoch 10 | loss: 0.01892 | val_logits_ll: 0.01868 |  0:00:19s\n",
      "epoch 20 | loss: 0.0174  | val_logits_ll: 0.01771 |  0:00:39s\n",
      "epoch 30 | loss: 0.01701 | val_logits_ll: 0.01726 |  0:00:56s\n",
      "epoch 40 | loss: 0.01681 | val_logits_ll: 0.017   |  0:01:14s\n",
      "epoch 50 | loss: 0.01658 | val_logits_ll: 0.01676 |  0:01:33s\n",
      "epoch 60 | loss: 0.01636 | val_logits_ll: 0.01673 |  0:01:51s\n",
      "epoch 70 | loss: 0.01624 | val_logits_ll: 0.01662 |  0:02:09s\n",
      "epoch 80 | loss: 0.01609 | val_logits_ll: 0.01659 |  0:02:28s\n",
      "epoch 90 | loss: 0.01594 | val_logits_ll: 0.0166  |  0:02:46s\n",
      "epoch 100| loss: 0.0158  | val_logits_ll: 0.01652 |  0:03:04s\n",
      "epoch 110| loss: 0.01556 | val_logits_ll: 0.01655 |  0:03:22s\n",
      "epoch 120| loss: 0.01539 | val_logits_ll: 0.01657 |  0:03:40s\n",
      "\n",
      "Early stopping occured at epoch 122 with best_epoch = 102 and best_val_logits_ll = 0.01636\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n",
      "FOLDS:  5\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.28677 | val_logits_ll: 0.02869 |  0:00:01s\n",
      "epoch 10 | loss: 0.01909 | val_logits_ll: 0.0186  |  0:00:19s\n",
      "epoch 20 | loss: 0.01756 | val_logits_ll: 0.0179  |  0:00:38s\n",
      "epoch 30 | loss: 0.01722 | val_logits_ll: 0.01704 |  0:00:55s\n",
      "epoch 40 | loss: 0.01679 | val_logits_ll: 0.01679 |  0:01:14s\n",
      "epoch 50 | loss: 0.0166  | val_logits_ll: 0.01658 |  0:01:31s\n",
      "epoch 60 | loss: 0.01645 | val_logits_ll: 0.01651 |  0:01:50s\n",
      "epoch 70 | loss: 0.01637 | val_logits_ll: 0.01654 |  0:02:08s\n",
      "epoch 80 | loss: 0.01609 | val_logits_ll: 0.01629 |  0:02:26s\n",
      "epoch 90 | loss: 0.01581 | val_logits_ll: 0.01631 |  0:02:45s\n",
      "epoch 100| loss: 0.01569 | val_logits_ll: 0.01635 |  0:03:02s\n",
      "epoch 110| loss: 0.01536 | val_logits_ll: 0.01646 |  0:03:20s\n",
      "epoch 120| loss: 0.01523 | val_logits_ll: 0.01627 |  0:03:39s\n",
      "\n",
      "Early stopping occured at epoch 129 with best_epoch = 109 and best_val_logits_ll = 0.01612\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n",
      "FOLDS:  6\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29269 | val_logits_ll: 0.02786 |  0:00:01s\n",
      "epoch 10 | loss: 0.01903 | val_logits_ll: 0.01887 |  0:00:19s\n",
      "epoch 20 | loss: 0.01765 | val_logits_ll: 0.01788 |  0:00:37s\n",
      "epoch 30 | loss: 0.01713 | val_logits_ll: 0.01733 |  0:00:56s\n",
      "epoch 40 | loss: 0.01693 | val_logits_ll: 0.01712 |  0:01:14s\n",
      "epoch 50 | loss: 0.01654 | val_logits_ll: 0.01694 |  0:01:32s\n",
      "epoch 60 | loss: 0.01643 | val_logits_ll: 0.01689 |  0:01:50s\n",
      "epoch 70 | loss: 0.01608 | val_logits_ll: 0.01677 |  0:02:09s\n",
      "epoch 80 | loss: 0.01603 | val_logits_ll: 0.01661 |  0:02:27s\n",
      "epoch 90 | loss: 0.01574 | val_logits_ll: 0.01671 |  0:02:46s\n",
      "epoch 100| loss: 0.01588 | val_logits_ll: 0.01701 |  0:03:03s\n",
      "epoch 110| loss: 0.01528 | val_logits_ll: 0.01691 |  0:03:22s\n",
      "\n",
      "Early stopping occured at epoch 114 with best_epoch = 94 and best_val_logits_ll = 0.01657\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n",
      "FOLDS:  7\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.28931 | val_logits_ll: 0.02854 |  0:00:01s\n",
      "epoch 10 | loss: 0.01848 | val_logits_ll: 0.01855 |  0:00:20s\n",
      "epoch 20 | loss: 0.01743 | val_logits_ll: 0.02039 |  0:00:39s\n",
      "epoch 30 | loss: 0.01686 | val_logits_ll: 0.01724 |  0:00:56s\n",
      "epoch 40 | loss: 0.01667 | val_logits_ll: 0.01686 |  0:01:16s\n",
      "epoch 50 | loss: 0.01649 | val_logits_ll: 0.01719 |  0:01:33s\n",
      "epoch 60 | loss: 0.01624 | val_logits_ll: 0.01673 |  0:01:52s\n",
      "epoch 70 | loss: 0.01603 | val_logits_ll: 0.01658 |  0:02:09s\n",
      "epoch 80 | loss: 0.01589 | val_logits_ll: 0.01664 |  0:02:28s\n",
      "epoch 90 | loss: 0.01576 | val_logits_ll: 0.01653 |  0:02:46s\n",
      "\n",
      "Early stopping occured at epoch 99 with best_epoch = 79 and best_val_logits_ll = 0.01645\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n",
      "FOLDS:  8\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.28955 | val_logits_ll: 0.02915 |  0:00:02s\n",
      "epoch 10 | loss: 0.01862 | val_logits_ll: 0.01844 |  0:00:21s\n",
      "epoch 20 | loss: 0.01733 | val_logits_ll: 0.01839 |  0:00:39s\n",
      "epoch 30 | loss: 0.01694 | val_logits_ll: 0.01709 |  0:00:56s\n",
      "epoch 40 | loss: 0.01673 | val_logits_ll: 0.01705 |  0:01:15s\n",
      "epoch 50 | loss: 0.01642 | val_logits_ll: 0.01696 |  0:01:34s\n",
      "epoch 60 | loss: 0.01623 | val_logits_ll: 0.01725 |  0:01:52s\n",
      "epoch 70 | loss: 0.01611 | val_logits_ll: 0.01677 |  0:02:10s\n",
      "epoch 80 | loss: 0.01587 | val_logits_ll: 0.01705 |  0:02:29s\n",
      "epoch 90 | loss: 0.01562 | val_logits_ll: 0.01672 |  0:02:46s\n",
      "epoch 100| loss: 0.01528 | val_logits_ll: 0.01656 |  0:03:05s\n",
      "epoch 110| loss: 0.01516 | val_logits_ll: 0.01675 |  0:03:23s\n",
      "epoch 120| loss: 0.01478 | val_logits_ll: 0.01665 |  0:03:41s\n",
      "\n",
      "Early stopping occured at epoch 124 with best_epoch = 104 and best_val_logits_ll = 0.01645\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n",
      "FOLDS:  9\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.28901 | val_logits_ll: 0.0283  |  0:00:01s\n",
      "epoch 10 | loss: 0.01887 | val_logits_ll: 0.01869 |  0:00:20s\n",
      "epoch 20 | loss: 0.01736 | val_logits_ll: 0.01753 |  0:00:38s\n",
      "epoch 30 | loss: 0.017   | val_logits_ll: 0.01746 |  0:00:56s\n",
      "epoch 40 | loss: 0.01672 | val_logits_ll: 0.01707 |  0:01:15s\n",
      "epoch 50 | loss: 0.01646 | val_logits_ll: 0.01688 |  0:01:33s\n",
      "epoch 60 | loss: 0.01621 | val_logits_ll: 0.01666 |  0:01:51s\n",
      "epoch 70 | loss: 0.01603 | val_logits_ll: 0.01675 |  0:02:08s\n",
      "epoch 80 | loss: 0.01573 | val_logits_ll: 0.01662 |  0:02:28s\n",
      "epoch 90 | loss: 0.0156  | val_logits_ll: 0.01659 |  0:02:45s\n",
      "epoch 100| loss: 0.01528 | val_logits_ll: 0.01658 |  0:03:03s\n",
      "epoch 110| loss: 0.01521 | val_logits_ll: 0.01653 |  0:03:22s\n",
      "epoch 120| loss: 0.01487 | val_logits_ll: 0.01633 |  0:03:40s\n",
      "epoch 130| loss: 0.01454 | val_logits_ll: 0.01674 |  0:03:58s\n",
      "epoch 140| loss: 0.01415 | val_logits_ll: 0.01672 |  0:04:16s\n",
      "\n",
      "Early stopping occured at epoch 140 with best_epoch = 120 and best_val_logits_ll = 0.01633\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n",
      "FOLDS:  10\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29121 | val_logits_ll: 0.02838 |  0:00:01s\n",
      "epoch 10 | loss: 0.01908 | val_logits_ll: 0.01897 |  0:00:19s\n",
      "epoch 20 | loss: 0.01737 | val_logits_ll: 0.02103 |  0:00:37s\n",
      "epoch 30 | loss: 0.01672 | val_logits_ll: 0.01712 |  0:00:56s\n",
      "epoch 40 | loss: 0.01669 | val_logits_ll: 0.01714 |  0:01:14s\n",
      "epoch 50 | loss: 0.01628 | val_logits_ll: 0.01714 |  0:01:32s\n",
      "epoch 60 | loss: 0.01602 | val_logits_ll: 0.01684 |  0:01:50s\n",
      "epoch 70 | loss: 0.01574 | val_logits_ll: 0.01703 |  0:02:08s\n",
      "epoch 80 | loss: 0.01538 | val_logits_ll: 0.01681 |  0:02:27s\n",
      "epoch 90 | loss: 0.01514 | val_logits_ll: 0.01696 |  0:02:44s\n",
      "epoch 100| loss: 0.01478 | val_logits_ll: 0.01715 |  0:03:03s\n",
      "\n",
      "Early stopping occured at epoch 101 with best_epoch = 81 and best_val_logits_ll = 0.01681\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n",
      "FOLDS:  11\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.2886  | val_logits_ll: 0.02906 |  0:00:01s\n",
      "epoch 10 | loss: 0.01907 | val_logits_ll: 0.01881 |  0:00:19s\n",
      "epoch 20 | loss: 0.01755 | val_logits_ll: 0.02087 |  0:00:37s\n",
      "epoch 30 | loss: 0.01698 | val_logits_ll: 0.01707 |  0:00:56s\n",
      "epoch 40 | loss: 0.01659 | val_logits_ll: 0.01682 |  0:01:14s\n",
      "epoch 50 | loss: 0.01647 | val_logits_ll: 0.01667 |  0:01:31s\n",
      "epoch 60 | loss: 0.01614 | val_logits_ll: 0.01649 |  0:01:50s\n",
      "epoch 70 | loss: 0.01577 | val_logits_ll: 0.01659 |  0:02:08s\n",
      "epoch 80 | loss: 0.01553 | val_logits_ll: 0.01655 |  0:02:27s\n",
      "epoch 90 | loss: 0.01533 | val_logits_ll: 0.01663 |  0:02:44s\n",
      "\n",
      "Early stopping occured at epoch 99 with best_epoch = 79 and best_val_logits_ll = 0.0163\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n",
      "FOLDS:  12\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.28917 | val_logits_ll: 0.02871 |  0:00:01s\n",
      "epoch 10 | loss: 0.01873 | val_logits_ll: 0.0188  |  0:00:19s\n",
      "epoch 20 | loss: 0.01734 | val_logits_ll: 0.01786 |  0:00:37s\n",
      "epoch 30 | loss: 0.01686 | val_logits_ll: 0.01726 |  0:00:55s\n",
      "epoch 40 | loss: 0.01649 | val_logits_ll: 0.01713 |  0:01:13s\n",
      "epoch 50 | loss: 0.01621 | val_logits_ll: 0.01699 |  0:01:32s\n",
      "epoch 60 | loss: 0.01591 | val_logits_ll: 0.01686 |  0:01:50s\n",
      "epoch 70 | loss: 0.01578 | val_logits_ll: 0.01691 |  0:02:08s\n",
      "epoch 80 | loss: 0.01557 | val_logits_ll: 0.01678 |  0:02:26s\n",
      "epoch 90 | loss: 0.01522 | val_logits_ll: 0.01701 |  0:02:44s\n",
      "epoch 100| loss: 0.01478 | val_logits_ll: 0.01713 |  0:03:03s\n",
      "\n",
      "Early stopping occured at epoch 100 with best_epoch = 80 and best_val_logits_ll = 0.01678\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n",
      "FOLDS:  13\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.28976 | val_logits_ll: 0.02759 |  0:00:01s\n",
      "epoch 10 | loss: 0.01878 | val_logits_ll: 0.01835 |  0:00:19s\n",
      "epoch 20 | loss: 0.01748 | val_logits_ll: 0.01708 |  0:00:38s\n",
      "epoch 30 | loss: 0.0171  | val_logits_ll: 0.01684 |  0:00:56s\n",
      "epoch 40 | loss: 0.01667 | val_logits_ll: 0.01664 |  0:01:14s\n",
      "epoch 50 | loss: 0.0163  | val_logits_ll: 0.01652 |  0:01:32s\n",
      "epoch 60 | loss: 0.01618 | val_logits_ll: 0.01637 |  0:01:51s\n",
      "epoch 70 | loss: 0.01589 | val_logits_ll: 0.01638 |  0:02:10s\n",
      "epoch 80 | loss: 0.01586 | val_logits_ll: 0.01639 |  0:02:28s\n",
      "epoch 90 | loss: 0.01555 | val_logits_ll: 0.01633 |  0:02:47s\n",
      "epoch 100| loss: 0.01524 | val_logits_ll: 0.01633 |  0:03:05s\n",
      "epoch 110| loss: 0.01491 | val_logits_ll: 0.01622 |  0:03:22s\n",
      "\n",
      "Early stopping occured at epoch 114 with best_epoch = 94 and best_val_logits_ll = 0.01611\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n",
      "FOLDS:  14\n",
      "************************************************************\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.28618 | val_logits_ll: 0.02799 |  0:00:02s\n",
      "epoch 10 | loss: 0.0187  | val_logits_ll: 0.0195  |  0:00:21s\n",
      "epoch 20 | loss: 0.01747 | val_logits_ll: 0.01976 |  0:00:38s\n",
      "epoch 30 | loss: 0.01695 | val_logits_ll: 0.01741 |  0:00:56s\n",
      "epoch 40 | loss: 0.01668 | val_logits_ll: 0.01712 |  0:01:15s\n",
      "epoch 50 | loss: 0.01642 | val_logits_ll: 0.017   |  0:01:33s\n",
      "epoch 60 | loss: 0.01631 | val_logits_ll: 0.01702 |  0:01:51s\n",
      "epoch 70 | loss: 0.01604 | val_logits_ll: 0.01698 |  0:02:09s\n",
      "epoch 80 | loss: 0.01577 | val_logits_ll: 0.01682 |  0:02:28s\n",
      "\n",
      "Early stopping occured at epoch 87 with best_epoch = 67 and best_val_logits_ll = 0.01671\n",
      "Best weights from best epoch are automatically used!\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "scores_auc_all = []\n",
    "test_cv_preds = []\n",
    "\n",
    "NB_SPLITS = 14 ########################################################################10 # 7\n",
    "mskf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, random_state = 0, shuffle = True)\n",
    "\n",
    "oof_preds = []\n",
    "oof_targets = []\n",
    "scores = []\n",
    "scores_auc = []\n",
    "for fold_nb, (train_idx, val_idx) in enumerate(mskf.split(train_df, targets)):\n",
    "    print( \"FOLDS: \", fold_nb + 1)\n",
    "    print( '*' * 60)\n",
    "    \n",
    "    X_train, y_train = train_df.values[train_idx, :], targets.values[train_idx, :]\n",
    "    X_val, y_val = train_df.values[val_idx, :], targets.values[val_idx, :]\n",
    "    ### Model ###\n",
    "    model = TabNetRegressor(**tabnet_params)\n",
    "        \n",
    "    ### Fit ###\n",
    "    # Another change to the original code\n",
    "    # virtual_batch_size of 32 instead of 128\n",
    "    model.fit(\n",
    "        X_train = X_train,\n",
    "        y_train = y_train,\n",
    "        eval_set = [(X_val, y_val)],\n",
    "        eval_name = [\"val\"],\n",
    "        eval_metric = [\"logits_ll\"],\n",
    "        max_epochs = MAX_EPOCH,\n",
    "        patience = 20,\n",
    "        batch_size = 1024, \n",
    "        virtual_batch_size = 32,\n",
    "        num_workers = 1,\n",
    "        drop_last = False,\n",
    "        # To use binary cross entropy because this is not a regression problem\n",
    "        loss_fn = F.binary_cross_entropy_with_logits\n",
    "    )\n",
    "    print('-' * 60)\n",
    "    \n",
    "    ### Predict on validation ###\n",
    "    preds_val = model.predict(X_val)\n",
    "    # Apply sigmoid to the predictions\n",
    "    preds = 1 / (1 + np.exp(-preds_val))\n",
    "    score = np.min(model.history[\"val_logits_ll\"])\n",
    "    \n",
    "    ### Save OOF for CV ###\n",
    "    oof_preds.append(preds_val)\n",
    "    oof_targets.append(y_val)\n",
    "    scores.append(score)\n",
    "    \n",
    "    ### Predict on test ###\n",
    "    preds_test = model.predict(X_test)\n",
    "    test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n",
    "\n",
    "oof_preds_all = np.concatenate(oof_preds)\n",
    "oof_targets_all = np.concatenate(oof_targets)\n",
    "test_preds_all = np.stack(test_cv_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:50:26.635140Z",
     "iopub.status.busy": "2020-11-29T08:50:26.634260Z",
     "iopub.status.idle": "2020-11-29T08:50:27.360156Z",
     "shell.execute_reply": "2020-11-29T08:50:27.359566Z"
    },
    "papermill": {
     "duration": 1.477265,
     "end_time": "2020-11-29T08:50:27.360266",
     "exception": false,
     "start_time": "2020-11-29T08:50:25.883001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_feat = [col for col in submission.columns if col not in [\"sig_id\"]]\n",
    "# To obtain the same lenght of test_preds_all and submission\n",
    "test = pd.read_csv(data_path + \"test_features.csv\")\n",
    "sig_id = test[test[\"cp_type\"] != \"ctl_vehicle\"].sig_id.reset_index(drop = True)\n",
    "tmp = pd.DataFrame(test_preds_all.mean(axis = 0), columns = all_feat)\n",
    "tmp[\"sig_id\"] = sig_id\n",
    "\n",
    "sub_6 = pd.merge(test[[\"sig_id\"]], tmp, on = \"sig_id\", how = \"left\")\n",
    "sub_6.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:50:28.932198Z",
     "iopub.status.busy": "2020-11-29T08:50:28.930376Z",
     "iopub.status.idle": "2020-11-29T08:50:28.932878Z",
     "shell.execute_reply": "2020-11-29T08:50:28.933347Z"
    },
    "papermill": {
     "duration": 0.781679,
     "end_time": "2020-11-29T08:50:28.933470",
     "exception": false,
     "start_time": "2020-11-29T08:50:28.151791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del data_all\n",
    "del pca_cells\n",
    "del pca_genes\n",
    "del submission\n",
    "del targets\n",
    "del test\n",
    "del test_df\n",
    "del tmp\n",
    "del train\n",
    "del train_df\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:50:30.671723Z",
     "iopub.status.busy": "2020-11-29T08:50:30.669758Z",
     "iopub.status.idle": "2020-11-29T08:50:30.672371Z",
     "shell.execute_reply": "2020-11-29T08:50:30.672875Z"
    },
    "papermill": {
     "duration": 0.74708,
     "end_time": "2020-11-29T08:50:30.673009",
     "exception": false,
     "start_time": "2020-11-29T08:50:29.925929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alldfs = ['del '+var for var in dir() if isinstance(eval(var), pd.core.frame.DataFrame)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.734492,
     "end_time": "2020-11-29T08:50:32.160043",
     "exception": false,
     "start_time": "2020-11-29T08:50:31.425551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:50:33.835921Z",
     "iopub.status.busy": "2020-11-29T08:50:33.835031Z",
     "iopub.status.idle": "2020-11-29T08:50:33.871686Z",
     "shell.execute_reply": "2020-11-29T08:50:33.870859Z"
    },
    "papermill": {
     "duration": 0.981311,
     "end_time": "2020-11-29T08:50:33.871837",
     "exception": false,
     "start_time": "2020-11-29T08:50:32.890526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def order_sub(sub) : \n",
    "    return sub.sort_values('sig_id').reset_index(drop=True)\n",
    "\n",
    "df1 = order_sub(sub_3)\n",
    "df2 = order_sub(sub_5)\n",
    "df3 = order_sub(sub_6)\n",
    "df13 = order_sub(sub13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:50:35.518575Z",
     "iopub.status.busy": "2020-11-29T08:50:35.517469Z",
     "iopub.status.idle": "2020-11-29T08:50:35.578045Z",
     "shell.execute_reply": "2020-11-29T08:50:35.577187Z"
    },
    "papermill": {
     "duration": 0.810405,
     "end_time": "2020-11-29T08:50:35.578159",
     "exception": false,
     "start_time": "2020-11-29T08:50:34.767754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BLEND=df1.copy()\n",
    "BLEND.iloc[:,1:] = 0.25*df1.iloc[:,1:]+0.175*df2.iloc[:,1:]+0.175*df3.iloc[:,1:]+0.4*df13.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:50:37.057778Z",
     "iopub.status.busy": "2020-11-29T08:50:37.057006Z",
     "iopub.status.idle": "2020-11-29T08:50:37.060347Z",
     "shell.execute_reply": "2020-11-29T08:50:37.059853Z"
    },
    "papermill": {
     "duration": 0.75143,
     "end_time": "2020-11-29T08:50:37.060466",
     "exception": false,
     "start_time": "2020-11-29T08:50:36.309036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET_COL = ['5-alpha_reductase_inhibitor', '11-beta-hsd1_inhibitor', 'acat_inhibitor', 'acetylcholine_receptor_agonist', 'acetylcholine_receptor_antagonist', \n",
    "              'acetylcholinesterase_inhibitor', 'adenosine_receptor_agonist', 'adenosine_receptor_antagonist', 'adenylyl_cyclase_activator', 'adrenergic_receptor_agonist', \n",
    "              'adrenergic_receptor_antagonist', 'akt_inhibitor', 'aldehyde_dehydrogenase_inhibitor', 'alk_inhibitor', 'ampk_activator', 'analgesic', 'androgen_receptor_agonist',\n",
    "              'androgen_receptor_antagonist', 'anesthetic_-_local', 'angiogenesis_inhibitor', 'angiotensin_receptor_antagonist', 'anti-inflammatory', 'antiarrhythmic',\n",
    "              'antibiotic', 'anticonvulsant', 'antifungal', 'antihistamine', 'antimalarial', 'antioxidant', 'antiprotozoal', 'antiviral', 'apoptosis_stimulant',\n",
    "              'aromatase_inhibitor', 'atm_kinase_inhibitor', 'atp-sensitive_potassium_channel_antagonist', 'atp_synthase_inhibitor', 'atpase_inhibitor', 'atr_kinase_inhibitor',\n",
    "              'aurora_kinase_inhibitor', 'autotaxin_inhibitor', 'bacterial_30s_ribosomal_subunit_inhibitor', 'bacterial_50s_ribosomal_subunit_inhibitor', 'bacterial_antifolate',\n",
    "              'bacterial_cell_wall_synthesis_inhibitor', 'bacterial_dna_gyrase_inhibitor', 'bacterial_dna_inhibitor', 'bacterial_membrane_integrity_inhibitor', 'bcl_inhibitor',\n",
    "              'bcr-abl_inhibitor', 'benzodiazepine_receptor_agonist', 'beta_amyloid_inhibitor', 'bromodomain_inhibitor', 'btk_inhibitor', 'calcineurin_inhibitor',\n",
    "              'calcium_channel_blocker', 'cannabinoid_receptor_agonist', 'cannabinoid_receptor_antagonist', 'carbonic_anhydrase_inhibitor', 'casein_kinase_inhibitor', \n",
    "              'caspase_activator', 'catechol_o_methyltransferase_inhibitor', 'cc_chemokine_receptor_antagonist', 'cck_receptor_antagonist', 'cdk_inhibitor', 'chelating_agent',\n",
    "              'chk_inhibitor', 'chloride_channel_blocker', 'cholesterol_inhibitor', 'cholinergic_receptor_antagonist', 'coagulation_factor_inhibitor', 'corticosteroid_agonist',\n",
    "              'cyclooxygenase_inhibitor', 'cytochrome_p450_inhibitor', 'dihydrofolate_reductase_inhibitor', 'dipeptidyl_peptidase_inhibitor', 'diuretic', 'dna_alkylating_agent',\n",
    "              'dna_inhibitor', 'dopamine_receptor_agonist', 'dopamine_receptor_antagonist', 'egfr_inhibitor', 'elastase_inhibitor', 'erbb2_inhibitor', 'estrogen_receptor_agonist',\n",
    "              'estrogen_receptor_antagonist', 'faah_inhibitor', 'farnesyltransferase_inhibitor', 'fatty_acid_receptor_agonist', 'fgfr_inhibitor', 'flt3_inhibitor',\n",
    "              'focal_adhesion_kinase_inhibitor', 'free_radical_scavenger', 'fungal_squalene_epoxidase_inhibitor', 'gaba_receptor_agonist', 'gaba_receptor_antagonist',\n",
    "              'gamma_secretase_inhibitor', 'glucocorticoid_receptor_agonist', 'glutamate_inhibitor', 'glutamate_receptor_agonist', 'glutamate_receptor_antagonist',\n",
    "              'gonadotropin_receptor_agonist', 'gsk_inhibitor', 'hcv_inhibitor', 'hdac_inhibitor', 'histamine_receptor_agonist', 'histamine_receptor_antagonist',\n",
    "              'histone_lysine_demethylase_inhibitor', 'histone_lysine_methyltransferase_inhibitor', 'hiv_inhibitor', 'hmgcr_inhibitor', 'hsp_inhibitor', 'igf-1_inhibitor',\n",
    "              'ikk_inhibitor', 'imidazoline_receptor_agonist', 'immunosuppressant', 'insulin_secretagogue', 'insulin_sensitizer', 'integrin_inhibitor', 'jak_inhibitor',\n",
    "              'kit_inhibitor', 'laxative', 'leukotriene_inhibitor', 'leukotriene_receptor_antagonist', 'lipase_inhibitor', 'lipoxygenase_inhibitor', 'lxr_agonist', 'mdm_inhibitor',\n",
    "              'mek_inhibitor', 'membrane_integrity_inhibitor', 'mineralocorticoid_receptor_antagonist', 'monoacylglycerol_lipase_inhibitor', 'monoamine_oxidase_inhibitor',\n",
    "              'monopolar_spindle_1_kinase_inhibitor', 'mtor_inhibitor', 'mucolytic_agent', 'neuropeptide_receptor_antagonist', 'nfkb_inhibitor', 'nicotinic_receptor_agonist',\n",
    "              'nitric_oxide_donor', 'nitric_oxide_production_inhibitor', 'nitric_oxide_synthase_inhibitor', 'norepinephrine_reuptake_inhibitor', 'nrf2_activator',\n",
    "              'opioid_receptor_agonist', 'opioid_receptor_antagonist', 'orexin_receptor_antagonist', 'p38_mapk_inhibitor', 'p-glycoprotein_inhibitor', 'parp_inhibitor',\n",
    "              'pdgfr_inhibitor', 'pdk_inhibitor', 'phosphodiesterase_inhibitor', 'phospholipase_inhibitor', 'pi3k_inhibitor', 'pkc_inhibitor', 'potassium_channel_activator',\n",
    "              'potassium_channel_antagonist', 'ppar_receptor_agonist', 'ppar_receptor_antagonist', 'progesterone_receptor_agonist', 'progesterone_receptor_antagonist',\n",
    "              'prostaglandin_inhibitor', 'prostanoid_receptor_antagonist', 'proteasome_inhibitor', 'protein_kinase_inhibitor', 'protein_phosphatase_inhibitor',\n",
    "              'protein_synthesis_inhibitor', 'protein_tyrosine_kinase_inhibitor', 'radiopaque_medium', 'raf_inhibitor', 'ras_gtpase_inhibitor', 'retinoid_receptor_agonist',\n",
    "              'retinoid_receptor_antagonist', 'rho_associated_kinase_inhibitor', 'ribonucleoside_reductase_inhibitor', 'rna_polymerase_inhibitor', 'serotonin_receptor_agonist',\n",
    "              'serotonin_receptor_antagonist', 'serotonin_reuptake_inhibitor', 'sigma_receptor_agonist', 'sigma_receptor_antagonist', 'smoothened_receptor_antagonist',\n",
    "              'sodium_channel_inhibitor', 'sphingosine_receptor_agonist', 'src_inhibitor', 'steroid', 'syk_inhibitor', 'tachykinin_antagonist', 'tgf-beta_receptor_inhibitor',\n",
    "              'thrombin_inhibitor', 'thymidylate_synthase_inhibitor', 'tlr_agonist', 'tlr_antagonist', 'tnf_inhibitor', 'topoisomerase_inhibitor',\n",
    "              'transient_receptor_potential_channel_antagonist', 'tropomyosin_receptor_kinase_inhibitor', 'trpv_agonist', 'trpv_antagonist', 'tubulin_inhibitor',\n",
    "              'tyrosine_kinase_inhibitor', 'ubiquitin_specific_protease_inhibitor', 'vegfr_inhibitor', 'vitamin_b', 'vitamin_d_receptor_agonist', 'wnt_inhibitor']\n",
    "NUM_TARGET = len(TARGET_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-29T08:50:38.531980Z",
     "iopub.status.busy": "2020-11-29T08:50:38.531100Z",
     "iopub.status.idle": "2020-11-29T08:50:41.852087Z",
     "shell.execute_reply": "2020-11-29T08:50:41.850951Z"
    },
    "papermill": {
     "duration": 4.061233,
     "end_time": "2020-11-29T08:50:41.852217",
     "exception": false,
     "start_time": "2020-11-29T08:50:37.790984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\n",
    "df = pd.read_csv(\"/kaggle/input/lish-moa/sample_submission.csv\")\n",
    "\n",
    "public_id = list(df['sig_id'].values)\n",
    "\n",
    "df_test = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\n",
    "test_id = list(df_test['sig_id'].values)\n",
    "\n",
    "private_id = list(set(test_id)-set(public_id))\n",
    "\n",
    "df_submit = pd.DataFrame(index = public_id+private_id, columns=TARGET_COL)\n",
    "df_submit.index.name = 'sig_id'\n",
    "df_submit[:] = 0\n",
    "df_predict = BLEND.copy()\n",
    "df_submit.loc[df_predict.sig_id,:] = df_predict[TARGET_COL].values\n",
    "df_submit.loc[df_test[df_test.cp_type=='ctl_vehicle'].sig_id]= 0\n",
    "df_submit.to_csv('submission.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.733919,
     "end_time": "2020-11-29T08:50:43.337964",
     "exception": false,
     "start_time": "2020-11-29T08:50:42.604045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 7231.066351,
   "end_time": "2020-11-29T08:50:46.081459",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-29T06:50:15.015108",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
